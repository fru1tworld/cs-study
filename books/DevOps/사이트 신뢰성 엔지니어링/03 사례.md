# 사례

서비스 신뢰성 계층 구조

1. 제품
2. 개발
3. 수용 계획
4. 테스트 및 릴리즈 절차
5. 포스트모텀/주요 원인 분석
6. 장애 대응
7. 모니터링

## 모니터링

모니티링이 없다면 서비스가 동작하는지 알 수 있는 방법이 없다.
견고하게 디자인된 모니터링 인프라가 없다면 그저 눈 먼 장님일 뿐이다.

## 장애 대응

SRE가 순전히 긴급 대응으만으로 목적으로 대기하는 경우는 드물다.

긴급 대응 지원은 좀 더 큰 미션을 달성하고 분산 시스템이 실제로 어떻게 동작하는지를 살펴보기 위한 도구다.

서류 뭉치를 들고 다닐 필요가 없는 방법이 있다면 당연히 그래야 하지 않겠는가 ?

## 포스트모텀과 주요 원인 분석

우리는 서비스에서 발생하는 문제들중 새롭고 관심이 있는 것들에 대해서만 알림을 받고 이를 직접 해결하는 것을 목적으로 한다.

계속해서 반복되는 똑같은 이슈를 해결하는 것은 미칠 듯이 지겨운 일이다.

포스트모텀(회고) 문화는 어떤 부분에 문제가 있었는지를 파악하는 첫 걸음이다.

## 테스트

어느 부분에서 오동작이 발생했는지를 이해했다면 그 다음 단계는 같은 현상이 재현되는 것을 방지하는 것이다.

그 이유는 잘못된 동작을 고치는 것보다는 그 동작을 미연에 방지하는 것이 훨씬 가치 있는 일이기 때문이다.

테트트 도구들을 이용하면 제품을 프로덕션 환경에 릴리즈하기 전에, 소프트웨어에서 어떤 종류의 오류들이 발생할 수 있는지를 먼저 확인할 수 있다.

## 수용 계획

SRE 조직의 소프트웨어 엔지니어링에는 SRE의 소프트웨어 엔지니링링어리에 대한 사례로서 자동화된 수용 계획 도구인 Auxon을 개발했던 이야기를 한다

## 개발

구글의 사이트 신뢰성 엔지니어링의 핵심 가치는 조직 내에서 타의 추종을 불허하는 대용량 시스템 디자인과 소프트웨어 엔지니어링을 수행하고 있다는 점이다.
제 23장 신뢰성을 위한 분산에 대한 합의에서는 구글이 다양한 분산 시스템의 핵심을 이루는 조화로운 분산에 대해 설명한다.
전 세계에 걸쳐 분산된 크론 시스템에 대해서도 함께 소개한다.
제 24장 Cron을 활용한 분산된 주기적 스케줄링

## 제품

마지막으로 신뢰성 계층 구조의 피라미드의 정점에는 실제로 동작하는 제품이 동작한다.
27장 스케일링을 지원하는 신뢰성 있는 제품 출시에서는 사용자에게 최상의 경험을 제공하기 위해 스케일링을 지원하는 신뢰성 있는 제품을 출시하기 위해 구글이 어떤 노력을 기울이는지 처음부터 끝까지 소개한다.

# 10 시계열 데이터에 대한 실용적인 알림

구글의 모니터링 시스템은 부하가 크지 않은 유럽 웹 서버의 평균 응답 시간 따위의 지표를 측정하는 시스템이 아니다.
한 지역의 전체 웹 서버에 대한 응답 시간이 어떻게 분산되는지를 이해해야 하기 때문에 지연응답의 증가를 유발하는 요인들을 정확히 파악할 수 있다.

보그몬의 탄생
애플리케이션의 조작
내보낸 데이터의 수집
시계열 데이터를 위한 저장소
규칙의 평가
알림
모니터링 토폴리지의 샤딩
블랙박스 모니터링
설정의 유지보수

# 11 비상 대기

온콜은 많은 운영팀 및 엔지니어링팀이 서비스의 신뢰성과 가용성을 위해 반드시 수행해야 할 중요한 임무다.

소개
구글은 성능과 신뢰성을 책임지는 전담 SRE가 있다.

그래서 SRE들은 서비스를 위한 비상 대기 업무를 수행한다.

SRE 팀은 순수한 운영팀과는 사뭇 달라서 문제를 해결하기 위한 엔지니어링 접근법을 강조한다.

이 문제들은 대부분 운영과 관련있지만 스케일링과 관련해서 소프트웨어 엔지니어링 솔루션 없니는 다루기 어려운 것들이다.

## 비상 대기 엔지니어의 삶

이 절에서는 통상 비상 대기 엔지니어가 어떤 활동을 하는지에 대한 설명과 더불어 이 장의 나머지 부분에 대한 약간의 배경지식을 제공하고자 한다.

비상 대기 엔지니어는 프로덕션 시스템의 보호자로서 팀에 영향을 미치는 장애를 관리하고 프로뎍선 환경의 변경을 추진 및 진단하는 등 할애된 운영 업무를 수행한다.

장애에 대한 대응 시간은 서비스의 가용성에 따라 다르지만 규칙은 간단하다 사용자에게 노출되는 서비스의 경우에는 분기별로 99.99%의 가용성을 반드시 확보해야 한다.

SLO가 비교적 낮은 시스템의 경우에는 대응 시간을 10분 단위로 정의할 수 있다.

## 비상 대기 업무의 균형 맞추기

SRE팀에는 비상 대기 업무에 편성될 경우 업무의 양과 품질에 대한 상세한 제약이 있다.

비상 대기 업무의 양은 엔지니어가 비상 대기 업무에 할애한 시간의 백분율로 계산한다.

그리고 비상 대기 품질은 비상 대기 업무 기간 동안 발생한 장애의 수로 계산될 수 있다.

### 업무 양의 균형

우리는 SRE의 E가 조직의 특성을 정의한다고 믿고 있으므로 최소 50%를 투자해야한다.
그래서 25% 정도를 비상 대기에 사용하고 나머지는 프로젝트가 아닌 다른 운영 업무에 할애한다.
25%의 비상 대기 규칙 덕분에 최소한 SRE의 인력으로 24/7 대기할 수 있다.

### 품질의 균형

포스트 모텀 작성, 버그 수정과 같은 후속

## 안전에 대해 고려하기

최근 연구결과에 따르면 사람은 자신이 직면한 도전에 대해 크게 두 가지 방향으로 생각하는 것으로 밝혀졌다.

- 직관적 자동화적 그리고 신속한 대응
- 합리적, 집중적, 그리고 계획적이며 경험에 기반한 행위

복잡한 시스템의 장애는 두 번째 방법이 더 나은 결과를 도출해내며 계획에 따른 장애 조치가 가능하다.

그래서 후자의 마음으로 적절하게 제어할 수 있도록 하기 위해서는 비상 대기와 관련된 스트레스를 줄여주는 것이 중요하다.

직감에 의한 대응은 미덕이지만 단점도 존재한다. 감이 틀렸을 수 있을 뿐 아니라 명확한 데이터에 근거한 지원이 제대로 이루어지지 않을 수 있기 때문이다.

장애를 처리 한후에는 반드시 포스트모텀 문서에 사건에 집중해서 작성된 포스트모텀 문서는 큰 가치를 제공한다.

이 문서는 누군가를 비난하는 것이 아니라, 프로덕션 환경의 장애를 시스템적으로 분석함으로써 그 가치를 이끌어낸다. 실수는 일어나게 마련이다.

## 부적절한 운영 부하에서 벗어나기

### 운영부하

큰 팀에 경력 있는 SRE를 임시로 보내면 팀의 숨통이 트이고 이슈를 해결하는 데 속도를 낼 수 있게 된다.

이상적으로는 운영 업무 부담의 증가에 대한 증상을 측정할 수 있어서 그 목표치가 정량화될 수 있어야 한다.

구글은 연간 장애 복구 대회를 열어 이론과 실전 지식을 모두 투입하여 며칠에 걸쳐 인프라스트럭처 시스템과 개별 시스템에 대한 테스트를 수행하곤 한다.

# 12 효과적인 장애 조치

장애 조치에 대한 연습은 크게 두 가지 요소와 관련 있는데 하나는 범용적으로 수행하는 방법에 대한 이해고 두 번째는 시스템에 대한 탄탄한 이해다. 시스템에 대한 지식은 해당 시스템에 익숙하지 않은 SRE의 효율성에 제한을 가하는 경향이 있다.

시스템이 어떻게 디자인되고 만들어졌는지에 대해 그다지 많이 알지 못하는 상태이기 때문이다.

## 이론

통상 애플리케이션의 장애 조치 방법은 가설 연역 방법이라고 생각하면 된다.
즉, 시스템을 관찰한 결과와 시스템의 행동에 대한 이해를 바탕으로 한 이론적 기반을 토대로 장애의 잠재적 원인에 대해 계속해서 가설을 세워나가고 이 가설을 시험하는 방법이다.

장애 조치 과정
문제 보고 -> 장애 등급 선정 -> 장애 분석 -> 장애 진단 -> 테스트 및 조치 -> 장애 처리

그런 다음 두 가지 방법으로 테스트를 해볼 수 있다.

관찰한 시스템의 상태를 이론과 비교하여 정황들이 들어맞는지 그렇지 않은지 판단하거나, 아니면 적극적으로 시스템을 고쳐보고 그 결과를 다시 관찰할 수 있다.
아니면 시스템의 상태에 대한 이해도와 보고된 문제에 대한 가능한 원인들을 다시 한번 되돌아볼 수 있는 계기가 되기도 한다.

어떤 방법을 사용하든 근본 원인이 발견될 때까지는 계속해서 테스트를 수행하고 원인이 발견되면 장애 재발을 방지하기 위해 그에 대한 조치를 수행한 후 포스트모텀 문서를 작성한다.

통상적인 문제
비효율적인 장애 조치 세션은 장애 등급 선정, 분석 및 진단 단계에 영향을 미친다.
이들 중 대부분은 시스템에 대한 깊은 이해가 부족한 데서 발생한다.

- 관련이 없는 증상을 들여보거나 시스템의 지표의 의미를 잘못 이해하는 경우 멍청하게 결과만 쫓는 행동일 뿐이다.
- 시스템의 변경이나 입력 값 혹은 환경에 대한 잘못된 이해는 안전하고 효과적인 가설의 검증에 방해가 된다.
- 장애 원인에 대한 가능성이 희박한 가설을 세우거나 과거에 발생한 문제의 원인과 결부시켜 한 번 발생한 문제는 다시 발행할 것이라고 결부해버리는 행위

연관 현상은 원인이 아니다.

## 실전에 들어가보자

모든 문제 해결은 문제에 대한 보고에서부터 시작한다.

효과적인 문제 보고는 실제로 기대한 동작은 무엇인지, 그리고 현재 어떻게 동작하고 있는지, 더불어 가능하다면 문제가 되는 동작을 어떻게 재현할 수 있는지를 설명하고 있어야 한다.

### 문제의 우선순위 판단

서비스의 전체적인 장애를 유발하면 모두가 참여해야겠지만 한 사람의 사용자에게만 발생한 문제인 경우 그럴 필요가 없을 수 있다.

숙련된 파일럿은 긴급 상황에서 자신의 최우선 과제는 비행기를 계속 비행하게 하는 것이고, 그 후 비행기와 그 외 모든 것들을 안전하게 지상에 착륙시키는 것이다.

### 단순화하기와 범위를 좁히기

시스템을 각 계층별로 분할정복 기법을 활용하여 문제를 해결한다.

반대로 너무 거대한 경우 시스템을 반으로 나누어 각 컴포넌트 사이의 통신 경로를 활용한다

### '무엇이', '어디서', '왜'를 고민하기

오동작 중인 시스템은 원하는 동작 이외의 어떤 다른 동작을 계속해서 실행하고 있을 가능성이 크다.

### 가장 마지막으로 수정된 부분에 주목하기

시스템은 관성이 있다.
그래서 무엇이 잘못되고 있는지 파악하기 위한 가장 좋은 시작 지점은 가장 최근에 변경된 부분이다.

## 테스트와 조치

가능한 원인들을 파악했다면 이들 중 어떤게 근본 원인인지 파악한다

- 이상적인 테스트는 상호 배타적이어서 가설의 어느 한 집합을 검증함으로써 다른 가설의 가능성이 없음을 밝혀낼 수 있어야 한다. 실제로는 이런 테스트를 구성하기란 굉장히 어렵다.
- 가장 명확한 것은 최우선으로 고려해야 한다. 가능성이 큰 테스트부터 순차적으로 진행하면서 테스트로 인해 시스템이 발생할 수 있는 위험에 대해서도 고려해야 한다.
- 혼란 요소로 인해 특정 실험이 잘못된 결과를 도출하게 될 수 있다. 예를 들어 방화벽 정책에 의해 특정 IP 주소로부터의 요청에만 응답하도록 적용되어 있어 애플리케이션 로직 서버 머신에서는 데이터베이스 서버에 성공적으로 핑을 할 수 있는 반면, 독자의 머신에서는 실패하는 상황이 발생할 수도 있다.
- 적극적인 테스트가 나중에 실행할 테스트의 결과에 부작용을 초래할 수도 있다. 예를 들어 프로세스가 더 많은 CPU를 사용할 수 있게 설정하면 작업은 더 빨리 끝낼 수 있지만 데이터가 경쟁 상태에 놓이게 될 가능성 역시 커진다.
- 일부 테스트는 설득력이 떨어질 수 있다. 정기적이면서 반복 가능한 형태로 경쟁 상태나 데드락이 발생한 상황을 인위적으로 만들어내기란 매우 어려우므로 이들이 문제의 원인임을 증명하기에는 비교적 불확실한 증거임에도 그것에 만족해야 할 수도 있다.

## 부정적인 결과의 마법

부정적인 결과는 기대한 효과가 나타나지 않은 경우를 의미하는 경험의 산물이다.
즉 계획한 대로 되지 않은 모든 실험을 의미한다. 새로운 디자인, 경험에 의한 학습 등을 통해 시스템을 개선하고자 했으나, 의도대로 되지 않은 경우가 이에 해당한다.

부정적인 결과로 끝난 실험 역시 결론이다.
이런 결과들을 통해 프로덕션 환경이나 디자인 공간 혹은 기존 시스템의 성능 한계 등을 확실히 알 수 있다.

또한 다른 사람들이 자신의 실험이나 디자인이 가치가 있는 것인지를 확인할 수 있는 계기가 되기도 한다.

예를 들어 어떤 개발팀이 특정 웹 서버가 8,000개의 연결을 처리해야 하는데, 잠금 현상 때문에 800개 연결밖에 못 한다면 800개 이하도 충분한지, 아니면 잠금 문제가 해결되었는지를 빠르게 살펴보고 결정을 내릴 수 있다.

도구와 방법은 실험의 결과와는 무관하며 향후의 작업에 대한 단서가 된다.

부정적인 결과를 공표하는 것은 업계의 데이터 주도 성향을 증진시킨다.

# 13 긴급 대응

## 시스템에 문제가 생기면 어떻게 해야 할까 ?

## 테스트로 인한 장애

## 변경으로 인한 장애

## 절차에 의한 장애

## 모든 문제가 해결되었다

## 지난 일로부터 배우기 그리고 본박하지 않기

## 결론

# 14 장애 관리하기

## 미흡한 장애 관리

## 미흡한 장애 처리에 대한 자세한 분석

## 장애 관리 절차의 기본 요소들

## 적절하게 관리한 장애 조치

## 언제 장애를 선언할 것인가?

# 15 포스트모텀 문화: 실패로부터 배우기

## 구글의 포스트모텀 철학

## 협업과 지식의 공유

## 포스트모텀 문화 도입하기

## 결론 및 지속적인 개선

# 16 시스템 중단 추적하기

## 에스컬레이터

## 아우터레이터

# 17 신뢰성을 위한 테스트

## 소프트웨어 테스트의 종류

## 테스트 및 빌드 환경 구성하기

## 대규모 환경에서의 테스트

## 결론

# 18 SRE 조직의 소프트웨어 엔지니어링

## SRE 조직의 소프트웨어 엔지니어링 역량이 중요한 이유

## Auxon 사례 연구: 프로젝트 배경 및 문제가 발생한 부분

## 의도 기반 수용량 계획

## SRE 조직에서 소프트웨어 엔지니어링을 육성하는 방법

## 결론

# 19 프런트엔드의 로드밸런싱

## 모든 일을 힘으로만 해결할 수는 없는 법

## DNS를 이용한 로드밸런싱

## 가상 IP 주소를 이용한 로드밸런싱

# 20 데이터센터의 로드밸런싱

# 21 과부하 처리하기

## 초당 쿼리 수의 함정

## 사용자별 제한

## 클라이언트 측에서 사용량 제한

## 중요도

## 활용도에 대한 신호들

## 과부하 오류 처리하기

## 연결에 대한 부하

## 결론

# 22 연속적 장애 다루기

## 연속적 장애의 원인과 그 대책

## 서버 과부하 방지하기

## 느긋한 시작과 콜드 캐싱

## 연속적 장애의 발생 요인

## 연속적 장애 테스트하기

## 연속적 장애를 처리하기 위한 즉각적인 대처

## 마무리하며

# 23 치명적인 상태 관리하기: 신뢰성을 위한 분산에 대한 합의

## 합의는 왜 필요할까: 분산 시스템 간 협업의 실패

## 분산에 대한 합의가 동작하는 방식

## 분산 합의를 위한 시스템 아키턱체 패턴

## 분산 합의의 성능

## 분산 합의 기반 시스템의 배포

## 분산 합의 시스템 모니터링

## 결론

# 24 크론을 이용한 분산된 주기적 스케줄링

## 크론

## 크론 작업과 멱등성

## 대용량 시스템 내에서의 크론

## 구글에서 구현한 크론 서비스

## 요약

# 25 데이터 처리 파이프라인

## 파이프라인 디자인 패턴의 기원

## 단순한 파이프라인의 패턴을 적용한 빅데이터의 기본적인 효과

## 정기적인 파이프라인 패턴의 과제

## 작업의 불균형 분산으로 인해 발생하는 문제

## 분산 환경에서 정기적 파이프라인의 단점

## 구글 워크플로우 소개

## 워크플로우의 실행 단계들

## 비즈니스의 지속성 보장하기

## 요약

# 26 데이터 무결성: 내가 기록한 그대로 읽을 수 있어야 한다

## 데이터 무결성의 중요한 조건

## 데이터 무결성과 가용성을 유지하기 위한 구글 SRE의 목표

## 구글이 데이터 무결성의 문제를 해결하는 방법

## 사례 연구

## 데이터 무결성과 관련된 SRE의 일반 원리들

## 결론

# 27 대용량 환경에서의 신뢰할 수 있는 제품 출시

## 출시 조율 엔지니얼
