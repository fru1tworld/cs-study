목차

1. 컴퓨터 구조 시작하기
2. 데이터
3. 명령어
4. CPU
5. 빠른 CPU를 위한 설계 기법
6. 메모리와 캐시 메모리
7. 보조기억장치
8. 입출력장치

# **Chapter 1 컴퓨터 구조 시작하기**

## **컴퓨터 구조의 큰 그림**

메모리

프로그램이 실행되기 위해서는 반드시 메모리에 저장되어 있어야 한다.

메모리는 현재 실행되는 프로그램의 명령어와 데이터를 저장한다.

메모리에 저장된 값의 위치는 주소로 알 수 있다.

## **CPU**

메모리에 저장된 명령어를 읽고 해석하고 실행한다.

ALU, 레지스터, 제어장치로 구성된다.

레지스터 : 임시 저장 장치.

제어장치 : 제어 신호라는 전기 신호를 내보내고 명령어를 해석하는 장치

CPU가 메모리에 저장된 값을 읽고 싶을 땐 메모리를 향해 메모리 읽기라는 제어 신호를 보낸다.

CPU가 메모리에 어떤 값을 저장하고 싶을 땐 메모리를 향해 메모리 쓰기라는 제어 신호를 보낸다.

보조기억장치 :

메모리는 가격이 비싸 저장 용량이 적음 , 전원이 꺼지면 저장된 내용을 잃음

전원이 꺼지면 작업한 내용이 기억을 잃는 이유 : 프로그램들은 메모리에 저장되는데 메모리는 전원이 꺼지면 저장된 내용이 날아감

입출력 장치 : 컴퓨터 외부에 연결되어 컴퓨터 내부와 정보를 교환하는 장치이지만 보조기억장치도 마찬가지 이므로 주변장치로 통칭함. 하지만 일반적으로는 구분됨

메인보드와 CPU , 메모리 등은 메인보드라는 판에 연결되는데 메인보드에 연결된 부품들은 버스라는 통로를 통해 정보를 주고 받음 그중 가장 중요한 장치는 네 가지(메모리 , 입출력장치, 보조기억장치, CPU) 연결하는 시스템 버스

시스템 버스는 주소 버스, ㄷ이터 버스 ,제어 버스로 구성되어있다.

CPU의 작동 예시

제어 버스로 메모리 읽기 제어 신호를 보내고

주소 보스로 읽고자 하는 주소를 내보내면

메모리는 데이터 버스로 CPU가 요청한 주소에 있는 내용을 보냄

# **Chapter 2 데이터**

워드란 ?

CPU가 한 번에 처리할 수 있는 데이터 크기를 의미 한번에 16비트를 처리할 수 있다면 1워드는 16비트 한번에 32비트를 처리할 수 있으면 1워드는 32비트

워드의 절반을 하프워드 1배를 풀 워드 2배를 더블 워드로 부름.

인텔의 x86 CPU는 32비트 워드 x64 CPUSMS 64비트 워드이다.

컴퓨터가 인식하고 표현할 수 있는 문자의 모음을 **문자 집합**이라고 한다.

**UFT-8 유니코드 문자 집합**

# **Chapter 3 명령어**

소스코드와 명령어

목적 파일과 실행 파일

목적 코드는 컴퓨터가 이해하는 저급 언어

목적 코드가 실행 파일이 되기 위해서는 링킹이라는 작업이 필요

컴파일하면 소스 코드로부터 목적 코드가 생성

연산 코드 , 오퍼랜드 , 주소 지정 방식

연산 코드 : 명령어가 수행할 연산 =(연산자)

오퍼 랜드 : 연산에 사용할 데이터, 연산에 사용할 데이터가 저장된 위치 =(피연산자)

연산 코드 필드 / 오퍼랜드 필드

오퍼랜드가 없는 경우 (0주소 명령어)

오퍼랜드가 1,2,3개인 경우 (1,2,3 주소 명령어)

연산 코드의 기본 종류

데이터 전송 , 산술/논리 연산 , 제어 흐름 변경, 입출력 제어

유효 주소 : 연산 코드에 사용할 데이터가 저장된 위치 즉 연산의 대상이 되는 데이터가 저장된 위치

주소 지정 방식 : 오퍼랜드 필드에 데이터가 저장된 위치를 명시할 때 연산에 사용할 데이터 위치를 찾는 방법

즉시 주소 지정 방식 : 연산에 사용할 데이터

집적 주소 지정 방식 : 유효 주소(메모리 주소)

간접 주소 지정 방식 : 유효 주소의 주소

레지스터 주소 지정 방식 : 유효 주소(레지스터 이름)

레지스터 간접 주소 지정 방식 : 유효주소를 저장한 레지스터

# **Chapter 4 cpu**

ALU는 계산결과와 플래그를 내보냄

ALU가 내보내는 대표적인 플래그

부호 플래그 / 제로 플래그 / 캐리 플래그 / 오버플로우 플래그

인터럽트 플래그 : 인터럽트 플래그가 1일 경우 인터럽트가 가능함을 의미

슈퍼바이저 플래그 : 1일 경우 커널 모드로 실행 중임을 의미하고 0일 경우 사용자 모드로 실행 중임을 의미

이러한 플래그는 플래그 레지스터에 저장

**제어장치**

제어장치는 제어신호를 보내고 명령어를 해석하는 부품

제어 신호는 컴퓨터 부품들을 관리하고 작동시키기 위한 일종의 전기 신호

**제어 장치는 클럭신호를 받아들인다**

클럭이란 컴퓨터의 모든 부품을 움직일 수 있게 하는 시간의 단위

클럭 주기에 맞춰 레지스터에서 다른 레지스터로 데이터가 이동되거나 ALU에서 연산이 수행되거나 CPU가 메모리에 저장된 명령어를 읽어 들임

그러나 컴퓨터 부품들은 한 클럭마다 작동하진 않음

**제어장치는 ‘해석해야 할 명령어’를 받아들인다**

CPU가 해석해야할 명령어는 명령어 레지스터에 저장된다.

제어장치는 명령어 레지스터로부터 해석할 명령어를 받아들이고 해석하고, 제어 신호를 발생시킴

**제어장치는 플래그 레지스터 속 플래그 값을 받아들인다.**

**제어장치는 시스템 버스, 그중에서 제어 버스로 전달된 제어 신호를 받아들인다**

제어 신호는 cpu뿐만 아니라 입출력장치를 비롯한 cpu 외부 장치도 발생시킬 수 있다.

제어 장치가 내보내는 정보 : CPU 외부에 전달하는 제어신호와 내부에 전달하는 제어 신호

외부에 전달하는 제어신호는 곧 제어 버스로 보낸다와 같음

메모리에 전달하는 제어신호와 입출력장치에 전달하는 제어 신호가 있음

**레지스터**

CPU 내부에는 다양한 레지스터가 존재

**프로그램 카운터**

메모리에서 가져올 명령어의 주소 메모리에서 읽어 들일 명령어의 주소를 저장

명령어 포인터라고도 부름

**명령어 레지스터**

해석할 명령어, 메모리에서 읽어 들인 명령어를 저장하는 레지스터

**메모리 주소 레지스터**

메모리의 주소를 저장하는 레지스터

CPU가 읽어 들이고자 하는 주소 값을 주소 버스로 보낼 때 메모리 주소 레지스터를 거침

**메모리 버퍼 레지스터**

메모리와 주고받을 값(데이터와 명령어)을 저장하는 레지스터

MDR(Memory Data Register) 라고도 부름

메모리에 저장된 프로그램을 실행하는 과정 (간략화)

1. CPU로 실행할 프로그램이 1000 ~ 1500 번지까지 있다고 가정하자.
2. 프로그램을 처음 실행하기 위해 **프로그램 카운터**에는 1000이 저장 / 이는 메모리에서 가져올 명령어가 1000번지에 있다는 것을 의미
3. 1000번지를 읽어 들이기 위해 **주소 버스**로 1000번지를 내보냄 이를 위해 **메모리 주소 레지스터**에 1000이 저장
4. ‘메모리 읽기’ 제어 신호와 메모리 주소 레지스터 값이 각각 제어 버스와 주소 버스를 통해 메모리로 보내짐
5. 메모리 1000번지에 저장된 값은 데이터 버스를 통해 **메모리 버퍼 레지스터**로 전달되고 **프로그램 카운터는 증가**되어 다음 명령어를 읽어 들일 준비를 함
6. 메모리 버퍼 레지스터에 저장된 값은 **명령어 레지스터**로 이동
7. 제어 장치는 명령어 레지스터의 명령어를 해석하고 **제어 신호를 발생**

결국 cpu가 프로그램을 순차적으로 읽어 들이고 실행해 나갈 수 있는 이유는 CPU 속 프로그램 카운터가 꾸준히 증가하기 때문

추가정보 : 순차적인 실행 흐름이 끊기는 경우

프로그램 카운터가 실행 중인 명령어의 다음 번지 주소가 아닌 다른 값으로 업데이트되는 경우가 있음 이러한 상황은 JUMP, CALL, RET과 같은 특정 메모리 주소로 실행 흐름을 이동하는 명령어가 있기 때문 또한 인터럽트가 발생해도 프로그램의 순차적인 실행흐름이 끊김

**범용 레지스터**

다양하고 일반적인 상황에서 자유롭게 사용할 수 있는 레지스터

데이터와 주소를 모두 저장할 수 있음

현대 대다수 cpu는 모두 범용 레지스터를 가지고 있음

**플래그 레지스터**

ALU 연산 결과에 따른 플래그를 플래그 레지스터에 저장함

**특정 레지스터를 이용한 주소 지정 방식 : 스택 주소 지정 방식**

**스택 포인터**

스택과 스택 포인터를 이용한 주소 지정 방식

스택은 메모리 안에 있으며 메모리 안에 **스택처럼 사용할 영역**을 **스택 영역**이라고 함

이 영역은 다른 주소 공간과 다르게 **스택처럼 사용하기로 암묵적으로 약속된 영역**

**베이스 레지스터**

**특정 레지스터를 이용한 주소 지정 방식 : 변위 주소 지정 방식**

오퍼랜드 필드에는 메모리의 주소가 담길 때도 있는데 변위 주소 지정 방식이란 오퍼랜드 필드의 값과 특정 레지스터의 값을 더하여 유효 주소를 얻어내는 주소 지정 방식

이때 변위 주소 지정 방식은 오퍼랜드 필드의 주소와 어던 레지스터를 더하는지에 따라 **상대주소 지정 방식과 베이스 레지스터 주소 지정 방식**으로 나뉨

**상대 주소 지정 방식**

오퍼랜드와 프로그램 카운터의 값을 더하여 유효주소를 얻음

상대 주소 지정 방식은 프로그래밍 언어의 if문과 유사하게 모든 코드를 실행하는 것이 아닌 **분기하여 특정 주소의 코드를 실행**할 때 사용됨

**베이스 레지스터 주소 지정 방식**

오퍼랜드와 베이스 레지스터의 값을 더하여 유효 주소를 얻는 방식

여기서 **베이스 레지스터는 ‘기준 주소’**

**오퍼랜드는 ‘기준 주소로부터 떨어진 거리’로서의 역할**

**추가 정보 : 상용화된 CPU 속 레지스터 및 주소 지정 방식**

실제 CPU의 작동법을 자세히 관찰해야하는 임베디드 개발자, 게임 엔진 개발자 , 보안 솔루션 개발자 를 지망한다면 CPU는 전공서와 실제 모습이 가장 다른 부품이므로 예를 들어 ‘범용 레지스터’로 소개된 레지스터는 R1,R2,R3 혹은 EAX, EBX 등 다양하게 불리며 자세하게 관찰하고 분석을 해야한다면 상용화된 CPU 속 레지스터를 관찰해야할 필요가 있음

**명령어 사이클과 인터럽트**

CPU가 하나의 명령어를 처리하는 과정에서 어떤 정해진 흐름이 있고 그 흐름을 반복하며 명령어를 처리하는 것을 **명령어 사이클**이라 한다.

CPU는 정해진 흐름에 따라 명령어를 처리해 나가지만, 간혹 이 흐름이 끊어지는 상황이 발생

이를 **인터럽트라 한다.**

**명령어 사이클**

**인출 사이클**

메모리에 있는 명령어를 CPU로 가져오는 단계

**실행 사이클**

CPU로 가져온 명령어를 실행하는 단계

프로그램을 이루는 수많은 명령어는 일반적으로 인출과 실행을 반복함

하지만 곧바로 실행할 수 없는 경우도 존재예를 들어 간접 주소 지정 방식의 경우 메모리를 2번 접근함 이 단계를 **간접 사이클이라 함**

**인터럽트**

CPU의 작업을 방해하는 신호를 의미

인터럽트가 발생하는 상황은 동기 / 비동기 인터럽트로 나뉨

**동기 인터럽트**

CPU에 의해서 발생하는 인터럽트 가령 프로그래밍 상의 오류와 같은 예외적인 경구 이런 점에서 예**외(exeception)**이라고 부름

**비동기 인터럽트**

주로 입출력 장치에서 발생하는 인터럽트

예시

- 프린터기 같은 입출력 장치에 입출력 작업을 요청하면 CPU에 완료 알림을 보냄
- 키보드 마우스와 같은 입출력 장치에 어떠한 입력을 받아들였을 때 이를 처리하기 위해 CPU에 입력 알림을 보냄

일반적으로 비동기 인터럽트를 인터럽트라고 함 / 이하 **하드웨어 인터럽트**로 설명

**하드웨어 인터럽트**

하드웨어 인터럽트는 알림과 같은 인터럽트 CPU는 입출력 작업 도중에도 효율적으로 명령어를 처리하기 위해 알림과 같은 하드웨어 인터럽트를 사용함

**명령어를 효율적으로 처리하는 것과 하드웨어 인터럽트의 상관관계**

예를 들어 CPU가 프린터에 출력을 명령했을 때 입출력장치는 CPU보다 현저히 느리므로 입출력 장치의 결과를 바로 받을 수 없다 따라서 하드웨어 인터럽트를 사용하지 않으면 언제 끝낼지 모르므로 **주기적으로 확인해야하며 이는 명령어 사이클의 낭비**

**하드웨어 인터럽트 처리 순서**

1. 입출력 장치는 CPU에 **인터럽트 요청 신호**를 보냄
2. CPU는 실행 사이클이 끝나고 명령어를 인출하기 전 항상 인터럽트 여부를 확인함
3. CPU는 인터럽트 요청을 확인하고 **인터럽트 플래그**를 통해 현재 인터럽트를 받아들일 수 있는지 여부를 확인
4. 인터럽트를 받아들일 수 있다면 CPU는 지금까지의 작업을 백업함
5. CPU는 인터럽트 벡터를 참조하여 **인터럽트 서비스 루틴**을 실행
6. **인터럽트 서비스 루틴**이 끝나면 4에서 백업해 둔 작업을 복구하여 실행을 재개함

CPU가 인터럽트 요청을 수용하기 위해서는 플래그 레지스터의 **인터럽트 플래그**가 활성화되어 있어야함 이는 하드웨어 인터럽트를 무시할지 받아들일지 결정 왜냐면 CPU가 중요한 일을 해야할 수도 있기 때문 따라서 가능 / 불가능을 정해둠

다만 모든 하든웨어 인터럽트를 인터럽트 플래그로 막을 수 있는 것은 아닌데 **무시할 수 없는 인터럽트**는 가장 우선순위가 높으므로 가장 먼저 처리해야함 예를 들어 **정전이나 하드웨어 고장이 이에 해당함**

인터럽트 요청을 받아들이기로 했다면 **인터럽트 서비스 루틴**이라는 **프로그램**을 실행

인터럽트 서비스 루틴은 인터럽트 요청이 왔을 때 어떻게 처리하고 동작할지에 대한 정보로 이루어진 프로그램

요약 : CPU가 인터럽트를 처리한다는 말은 인터럽트 서비스 루틴을 실행하고 본래 수행하던 작업으로 다시 되돌아온다와 같다

인터럽트 처리하는 방법은 입출력장치마다 다르므로 각기 다른 인터럽트 서비스 루틴을 가지고 있으며 따라서 구분을 해야할 필요가 있음 이를 위해 **인터럽트 벡터**라는 **인터럽트 서비스 루틴을 식별**하기 위한 정보가 있음

인터럽트 서비스 루틴은 여느 프로그램과 마찬가지로 명령어와 데이터로 이루어져 있는데 따라서 프로그램 카운터를 비롯한 레지스터들을 사용하며 실행함

다만 프로그램 카운터에 1500이 저장되어 있다고 했을 때 이 CPU에 **하드웨어 인터럽트가 발생**하면 10번지에 있는 인터럽트 서비스 루틴을 실행해야 한다고 가정했을 때 기존에 프로그램 카운터에 저장되어 있던 1500은 그냥 10으로 덮는 것이 아닌 **다시 수행해야하므로** 어딘가에 백업을 해야함 따라서 현재 프로그램 재개를 위해 필요한 모든 내용을 **스택**에 백업함

**예외의 종류**

**폴트 fault**

예외를 처리한 직후 **예외가 발생한 명령어부터** 실행을 재개

CPU가 한 명령어를 실행하려 하는데 보조기억장치에 있을 경우 폴트를 발생시키고 보조기억장치로부터 필요한 데이터를 메모리로 가져와 저장함

**트랩 trap**

예외를 처리한 직후 **예외가 발생한 명령어의 다음 명령어부터** 실행을 재개하는 예외

디버깅을 할 때 특정 코드가 실행되는 순간 프로그램의 실행을 멈추게 할 수 있음 이 트랩을 처리하고 나면 중단 시키고 디버깅이 끝나면 프로그램은 **다음 명령어부터 실행**을 이어 나가면 됨

**중단 abort**

CPU가 실행 중인 프로그램을 강제로 중단시킬 수 밖에 없는 심각한 오류를 발견했을 때

**소프트웨어 인터럽트**

시스템호출이 발생했을 때

# **Chapter 5 빠른 CPU를 위한 설계 기법**

**클럭**

컴퓨터 부품들은 클럭 신호에 맞춰 일사불란하게 움직인다.

CPU는 명령어 사이클이라는 정해진 흐름에 맞춰 명령어들을 실행한다.

그렇다면 클럭 속도가 올라가면 명령어 사이클이 빨리 반복될 것이고 따라서 일반적으로 클럭 속도가 높은 CPU가 성능이 좋음

**클럭 속도**는 **헤르츠** 단위로 측정되며 이는 **1초**에 클럭이 몇 번 반복되는지 나타냄

클럭은 일정하게 유지되는 것이 아님 고성능을 요하는 순간 순간적으로 클럭 속도를 높이고 그렇지 않으면 낮추는데 최대 클럭 속도를 강제로 끌어올리는 것을 **오버클럭킹**이라고 함

클럭을 올리면 발열 문제 등으로 인해 CPU의 성능을 올리는 것에는 한계가 있음

**코어와 멀티코어**

코어 : 명령어를 실행하는 부품을 CPU 내부에 여러가지 만들 수 있음 코어를 여러개로 늘리면 성능이 향상하지만 비례하지않음 따라서 코어마다 처리할 명령어들이 얼마나 적절하게 분배되는지에 따라 연산속도가 크게 달라짐

**스레드와 멀티스레드**

스레드의 사전적 의미는 실행 흐름의 단위이지만 엄밀하게 이해해야할 필요가 있다.

스레드에는 CPU에 사용되는 **하드웨어적인 스레드**가 있고 **소프트웨어적 스레드**가 있음

**하드웨어적 스레드**

하나의 코어가 동시에 처리하는 명령어 단위

지금까지 배운 내용은 CPU는 1코어 1스레드이지만 스레드는 하나의 코어로도 여러 개의 명령어를 동시에 실행할 수 있다.

이처럼 하나의 코어로 여러 명령어를 동시에 처리하는 CPU를 **멀티스레드 프로세서** 또는 **멀티스레드 CPU**라고 함

**하이퍼 스레딩**(인텔의 멀티스레드 기술을 의미)

**소프트웨어적 스레드**

하나의 프로그램에서 독립적으로 실행되는 단위

프로그래밍 언어나 운영체제를 학습할 때 접하는 스레드를 의미

하나의 프로그램은 실행되는 과정에서 한 부분만 실행될 수 있지만 프로그램의 여러 부분이 동시에 실행될 수 있음

**멀티스레드 프로세서**

하나의 코어로 여러 명령어를 동시에 처리하도록 만들려면 프로그램 카운터, 스택 포인터, 메모리 버퍼 레지스터, 메모리 주소 레지스터와 같이 하나의 명령어를 처리하기 위해 꼭 필요한 레지스터를 여러 개 가지고 있으면 된다

가령 2코어 4스레드 CPU는 한번에 네 개의 명령어를 처리할 수 있는데 프로그램 입장에서 봤을 때 한 번에 하나의 명령어를 처리하는 CPU가 네 개 있는 것처럼 보여서 **논리 프로세서**라고도 부름

**명령어 병렬 처리 기법**

명령어 파이프 라인

명령어 처리 과정을 클럭 단위로 나누면 일반적으로

명령어 인출 , 명령어 해석, 명령어 실행, 결과 저장으로 나눌 수 있는데 중요한 점은 **같은 단계가 겹치지 않는다면 CPU는 각 단계를 동시에 실행할 수 있다.**

이 처럼 마치 공장 생산 라인과 같이 명령어들을 **명령어 파이프라인**에 넣고 동시에 처리하는 기법을 **명령어 파이프라이닝**이라고 한다.

하지만 특정 상황에서는 성능 향상에 실패하는 경우가 있다. 이러한 상황을 **파이프라인 위험**이라고 부른다.

파이프라인 위험의 종류

**데이터 위험**

**명령어 간 데이터 의존 성에 의해 발생됨**

**제어 위험**

주로 분기 등으로 인한 **프로그램 카운터의 갑작스러운 변화**에 의해 발생

그런 경우 미리 가져와서 처리 중이던 명령어들은 쓸모가 없어짐

이를 위해 사용하는 기술 중 하나가 **분기 예측**

**구조적 위험**

명령어들을 겹쳐 실행하는 과정에서 서로 다른 명령어가 동시에 ALU, 레지스터 등과 같은 CPU 부품을 사용하려고 할 때 발생 이를 **자원 위험**이라고도 부름

**슈퍼스칼라**

파이프라이닝은 단일 파이프라인으로도 구현이 가능하지만 오늘날 대부분의 CPU에서는 여러 개의 파이프라인을 이용 이처럼 CPU 내부에 여러 개의 명령어 파이프라인을 포함한 구조를 **슈퍼 스칼라**라고 한다.

**비순차적 명령어 처리 OoOE**

**데이터 의존성이 전혀 없는** 순서를 바꿔 처리해도 상관없는 명령어들이 있는데 그런 경우 바꿔 실행해서 보다 효율적으로 처리를 할 수 있음 따라서 **바꿔 실행해도 무방한** **명령어**를 먼저 실행하여 명령어 파이프라인이 멈추는 것을 방지하는 기법을 **비순차적 명령어 처리 기법**이라고 한다.

**CISC와 RISC**

**명령어 집합**

명령어로 할 수 있는 연산, 주소 지정 방식은 CPU 마다 조금씩 차이가 있다 CPU가 이해할 수 있는 명령어의 모음을 **명령어 집합** 또는 **명령어 집합 구조(Instruction Set Architecture ISA)** 라고 한다

ISA가 다르다는 것은 어셈블리어도 달라지는 것을 의미함 어셈블리어는 컴파일러에 따라 달라질 수 있는데 CPU에 따라서도 달라질 수 있음

ISA에 따라 명령어 파이프라인, 슈퍼스칼라, 비순차적 명령어 처리를 사용하기 유리한 명령어 집합이 있고 그렇지 못한 집합이 있음 크게 CISC와 RISC로 나뉨

**CISC**

복잡한 명령어 집합을 활용하는 컴퓨터(Complex Instruction Set Computer)

여기서 컴퓨터를 CPU로 생각해도 좋음

CISC는 다양하고 강력한 기능의 명령어 집합을 활용하므로 명령어의 형태와 크기가 **다양한 가변 길이 명령어**를 활용 메모리에 접근하는 주소 지정 방식도 다양해서 아주 특별한 상황에서만 사용되는 독특한 주소 지정 방식들도 있음

이러한 장점으로 적은 수의 명령어만으로 프로그램을 동작시킬 수 있어서 메모리 공간을 절약할 수 있음 그러나 명령어의 크기와 실행되기까지의 시간이 일정하지 않아 하나의 명령어를 실행하는데 **여러 클럭 주기**를 필요로 할 수 있음 따라서 **파이프라인이 효율적으로 명령어를 처리할 수** 없다

이러한 이유로 CISC 기반 CPU는 성장에 한계가 존재

**RISC**

Reduced Instruction Set Computer

는 짧고 규격화된 명령어 되도록 1클럭 내외로 실행되는 명령어를 지향함 즉 RISC를 **고정 길이 명령어를 활용**

따라서 파이프라이닝에 최적화되어있다.

그리고 메모리를 직접 접근하는 명령어를 load, store로 제한하여 **load- store 구조**라고 부르기도 한다.

메모리 접근을 단순화, 최소화하는 대신 레지스터를 적극적으로 활용한다. 그렇기에 레지스터를 이용한 연산이 많고 일반적인 경우보다 범용 레지스터의 개수도 더 많다. 다만 사용 가능 명령어 개수 CISC 보다 적기 때문에 보다 많은 명령으로 프로그램을 작동시킴

# **Chapter 6 메모리와 캐시 메모리**

**RAM의 특징**

RAM은 실행할 프로그램의 명령어와 데이터가 저장

중요한 점은 전원을 끄면 RAM에 저장된 명령어와 데이터가 모두 날아감

이러한 저장 장치를 휘발성 저장 장치라고 함 ↔ 비휘발성 저장 장치

**RAM의 용량과 성능**

RAM 용량이 충분히 크다면 보조기억장치에서 많은 데이터를 가져와 미리 RAM에 저장할 수 있어 많은 프로그램을 동시에 실행하는 데 유리

**DRAM**

Dynamic RAM : 저장된 데이터가 동적으로 변함 (사라짐)

DRAM은 시간이 지나면 저장된 데이터가 사라지며 이를 막기 위해 일정 주기로 데이터를 재활성화(다시 저장)해야 함

이러한 단점이 있지만 소비 전력이 비교적 낮고 집적도가 높아 대용량으로 설계하기가 용이함

**SRAM**

Static RAM DRAM과 달리 소멸되지 않음 일반적으로 속도도 빠름

그러나 가겨도 더 비싸고 소비 전력도 크고 집적도도 낮음 대용량으로 만들어질 필요는 없지만 속도가 빨라야하는 **캐시 메모리**에서 사용됨

**SDRAM**

Synchronous Dynamic 클럭 신호와 동기화된 발전된 형태의 DRAM

클럭 타이밍에 CPU와 정보를 주고받을 수 있음

**DDR SDRAM**

Double Data Rate SDRAM 대역폭을 넓혀 속도를 빠르게 만듦

한 클럭당 하나씩 데이터를 주고 받을 수 있는 SDRAM을 SDR SDRAM이라고도 부름

DDR2 SDRAM은 DDR SDRAM보다 대역폭이 2배 넓음 (4배)

DDR3 SDRAM은 DDR2 SDRAM보다 대역폭이 2배 넓음 (8배)

DDR4 SDRAM은 DDR3 SDRAM보다 대역폭이 2배 넓음 (16배)

**메모리의 주소 공간**

**물리 주소와 논리 주소**

**물리 주소**는 메모리 하드웨어가 사용하는 주소

**논리 주소**는 CPU와 실행 중인 프로그램이 사용하는 주소

메모리가 사용하는 주소는 **하드웨어 상의 실제 주소**인 **물리 주소**이고 **CPU와 실행 중인 프로그램이 사용하는 주소**는 각각의 프로그램에 부여된 **논리 주소**

따라서 CPU와 메모리가 상호작용을 위해 논**리 주소와 물리 주소** 간의 변환이 필요

논리 주소와 물리 주소 간의 변환은 CPU와 주소 버스 사이에 위치한 **메모리 관리 장치(Memory Management Unit MMU)** 라는 하드 웨어에 의해 수행

MMU는 CPU가 발생 시킨 논리 주소에 베이스 레지스터 값을 더하여 논리 주소를 물리 주소로 변환

**베이스 레지스터**는 프로그램의 가장 작은 물리 주소, 즉 **프로그램의 첫 물리주소를 저장**하는 셈이고, **논리 주소**는 프로그램의 **시작점으로부터 떨어진 거리**인셈

**메모리 보호기법**

프로그램의 논리 주소 영역을 벗어나는 명령어가 실행되는 경우 논리 주소 범위를 벗어나는 명령어 실행을 방지하고 실행 중인 프로그램이 다른 프로그램에 영향을 받지 않도록 보호할 방법을 **한계 레지스터(Limit register)**가 담당 함

**베이스 레지스터**가 **가장 작은 물리 주소를 저장**한다면 **한계 레지스터**는 **논리 주소의 최대 크기를 저장**

CPU는 메모리에 접근하기 전에 접근하고자 하는 논리 주소가 한계 레지스터보다 작은지를 검사함

만약 그렇지 않을 경우 인터럽트(트랩)을 발생시켜 실행을 중단함

**캐시 메모리**

CPU는 메모리에 저장된 데이터를 빈번하게 사용하지만 서로의 속도가 차이가 나서 **캐시 메모리**를 사용

**저장 장치 계층 구조**

CPU와 가까운 저장 장치는 빠르고 멀리 있는 저장 장치는 느리다.

속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.

레지스터 - 메모리 - 보조기억 장치

← 빠름 용량 →

**캐시 메모리**

케시 메모리는 CPU와 메모리 사이에 위치한 레지스터보다 용량이 크고 메모리 보다 빠른 SRAM 기반의 저장 장치

레지스터 - 캐시 메모리 - 메모리 - 보조기억 장치

컴퓨터 내부에는 CPU와 가까운 순서대로 계층을 구성하며 코어와 가장 가까운 캐시 메모리를 **L1 캐시, L2 캐시, L3 캐시**라고 부름

일반적으로 **L1 캐시와 L2 캐시는 코어 내부**에 **L3 캐시는 코어 외부**에 위치해있음

멀티 코어 프로세서에서 L1 L2 L3 캐시는 일반적으로 **L1, L2 캐시는 코어마다 고유한 캐시 메모리**로 할당되고 **L3 캐시는 여러 코어가 공유하는 형태**로 사용됨

**추가 정보 : 분리형 캐시**

코어와 가장 가까운 L1 캐시는 조금이라도 접근 속도를 빠르게 만들기 위해 명령어만을 저장하는 L1 캐시인 L1 I 캐시와 L1 D 캐시로 구분하는 경우도 있는데 이를 **분리형 캐시**라 한다.

**참조 지역성 원리**

캐시 메모리는 모든 내용을 저장할 수 없으므로 예측해서 저장해야한다. 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용될 경우를 **캐시 히트**라고 한다.

예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우를 **캐시 미스**라고 한다.

캐시 적중률 : **캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)**

사용하는 컴퓨터의 캐시 적중률은 대략 85 ~ 95% 이상이다. 캐시 메모리는 참조 지역성의 원리로 가져올 데이터를 결정한다.

- CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다. (시간 지역성)
- CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다. (공간 지역성)

# **Chapter 7 보조기억장치**

**하드 디스크**

자기적인 방식으로 데이터를 저장하는 보조기억 장치

동그란 원판에 데이터를 저장하고 그것을 회전시켜 데이터를 읽음

하드 디스크에서 실질적으로 **데이터가 저장되는 곳**을 **플래터**라고 한다.

수 많은 N극과 S극을 저장하는데 이것이 0과 1의 역할을 수행한다.

회전시키는 구성 요소를 **스핀들이라 한다.** 스핀들이 플래터를 돌리는 속도는 분당 회전수를 나타내는 **RPM** 플래터**를** 대상으로 데이터를 읽고 쓰는 구성 요소는 **헤드**이고 헤드는 원하는 위치로 헤드를 이동 시키는 **디스크 암**에 부착되어있다

플래터는 **트랙**과 **섹터**라는 단위로 데이터를 저장

플래터를 동심원으로 나눴을 때 그중 **하나의 원을 트랙**이라고 한다.

하나의 섹터는 일반적으로 512바이트 정도의 크기를 가지고 있지만 하드디스크에 따라 다르다.

여러 겹의 플래터가 사용될 수 있는데 여러 겹의 플래터 상에서 같은 트랙이 위치한 곳을 모아 연결한 논리적 단위를 실린더라 한다.

연속된 정보는 보통 한 실린더에 기록된다.

하드 디스크가 저장된 데이터에 접근하는 시간은 탐색 시간, 회전 지연, 전송 시간으로 나뉜다.

탐색 시간 : 접근하려는 데이터가 저장된 트랙까지 헤드를 이동시키는 시간을 의미한다.

회전 지연 : 헤드가 있는 곳으로 플래터를 회전시키는 시간을 의미한다.

전송 시간 : 하드 디스크와 컴퓨터 간에 데이터를 전송하는 시간을 의미한다.

구글의 AI를 주도하는 제프 딘은 프로그래머가 꼭 알아야할 컴퓨터 시간들을 공개했는데 그 중 일부는 다음과 같다.

0.5 ns : L1 캐시 참조 시간

5ns : L2 캐시 참조 시간

7ns : 메모리 참조 시간

250,000ns : 메모리에서 1MB를 순차적으로 읽는 시간

10,000,000ns : 하드 디스크 탐색 시간

30,000,000ns : 하드 디스크에서 1MB를 순차적으로 읽는 시간

150,000,000ns :한 패킷이 캘리포니아에서 네덜란드까지 왕복하는 시간

2011년 공개 이후 많이 향상되었지만 그럼에도 하드 디스크에서 다량의 데이터를 탐색하고 읽어 들이는 시간은 어마어마하다.

**추가 정보: 다중 헤드 디스크와 고정 헤드 디스크**

플래터의 한 면당 헤드가 하나씩 달려 있는 하드 디스크를 단**일 헤드 디스크**라고 부른다.

헤드가 여러 개 달려 있는 하드 디스크를 **다중 헤드 디스크**라고 한다.

헤드를 움직일 필요가 없는 다중 헤드 디스크를 **고정 헤드 디스크**라고 부른다.

반대로 헤드를 데이터가 있는 곳까지 움직여야 하는 단일 헤드 디스크를 **이동 헤드 디스크**라고 부른다.

**플래시 메모리**

USB, SD, SSD 모두 플래시 메모리 기반의 보조기억 장치이다.

플래시 메모리는 전기적으로 데이터를 읽고 쓸 수 있는 반도체 기반의 저장 장치이다

플래시 메모리는 보조기억장치 범주 외에도 여러 곳에서 사용하는 저장 장치이다.

**플래시 메모리의 종류**

NAND 플래시 메모리와 NOR 플래시 메모리가 있다.

NAND 연산을 수행하는 회로와 NOR 연산을 수행하는 회로를 기반으로 만들어진 메모리를 의미 \

대용량으로 사용되는 플래시 메모리는 NAND 플래시 메모리이다.

플래시 메모리에는 셀이라는 단위가 있는데 셀은 데이터를 저장하는 가장 작은 단위가 된다.

한 셀에 1비트를 저장할 수 있는 플래시 메모리를 SCL(Single Level Cell)이라 하고. 2비트는 MLC (Multiple Level Cell) 3비트는 TLC(Triple-Level-Cell)이라 한다.

4비트를 저장하는 QLC도 존재

이러한 차이는 플래시 메모리의 수명, 속도, 가격에 큰 영향을 끼침

SLC 은 MLC나 TLC에 비해 빠르며, 수명이 길다. 하지만 용량 대비 가격이 높다.

MLC 는 속도와 수명이 떨어지지만 대용화하기 유용하다.

시중에 많은 플래시 메모리 저장 장치들이 MLC 혹은 TLC 타입으로 만들어진다.

TLC 타입은 MLC 타입보다 수명과 속도가 떨어지지만 가격이 저렴

이러한 셀들이 모여 만들어진 단위를 페이지 그리고 페이지가 모여 만들어진 단위를 블록이라고 하고 블록이 모여 플레인 플레인이 모여 다이가 된다.

page < block < plane < die

플래시 메모리에서 **읽기와 쓰기는** **페이지 단위**. 하지만 삭제는 **블록 단위**

이때 페이지는 Free Valid Invalid 상태를 가진다.

Free는 데이터를 저장하고 있지 않아 새로운 데이터를 저장할 수 있는 상태를 의미하고

Vaild는 유효한 데이터를 저장하고 있는 상태를 의미

InVaild는 쓰레기값이라 부르는 유효하지 않은 데이터를 저장하고 있는 상태를 의미한다.

플래시 메모리는 하드 디스크와 달리 **덮어쓰기가 불가**하여 Valid인 상태인 페이지에서 새 데이터를 저장할 수 없다

따라서 기존 데이터를 덮어쓰기 위해서는 새로운 페이지에 값을 저장하고 **기존 값에 Invalid 상태**를 만든다.

그러나 쓰레기값을 저장하고 있음 **삭제는 블록 단위**이기 때문에 해당 값만 삭제할 수 없으므로 최근 SSD는 이러한 값을 정리하기 위한 **가비지 컬렉션** 기능을 제공한다.

**가비지 컬렉션**이란 유효 페이지들만을 새로운 블록으로 복사한 뒤 기존의 블록을 삭제하는 기능이다.

**RAID의 정의와 종류**

1TB 하드 디스크 네 개와 4TB 하드 디스크 한개중 1TB 하드 디스크 네 개로 RAID를 만들어 구성하면 성능과 안정성을 능가한다.

**RAID(Redundant Araay of Independent Disks)의 정의**

보조기억장치에는 수명이 있으므로 이를 안전하게 관리할 수 있는 방법이 필요 따라서 이를 위한 기법 중 하나로 RAID가 있다. 하드 디스크와 SSD를 사용하는 기술로 데이터의 안정성 혹은 높은 성능을 위해 여러 개의 물리 보조기억 장치를 마치 하나의 논리적 보조기억장치처럼 사용하는 기술을 의미한다.

**RAID의 종류**

RAID의 구성 방법을 RAID의 레벨이라 표현하는데 대표적으로

RAID0, RAID1, RAID2, RAID3, RAID4, RAID5, RAID6이 있고 그로 파생된 RAID 10,RAID 50등이 있다

**RAID0**

여러 개의 보조기억장치에 데이터를 단순히 나누어 저장하는 구성 방식

하드 디스크1,2,3,4 에서 A1~ D4 의 데이터를 저장하려고 할 때

하드디스크1 A1 B1 C1 D1

하드디스크2 A2 B2 C2 D2

하드디스크3 A3 B3 C3 D3

하드디스크4 A4 B4 C4 D4

와 같이 저장된다.

이렇게 줄무늬처럼 분산되어 저장된 데이터를 스트립이라고 하고 분산하여 저장하는 것을 스트라이핑이라고 한다.

stripe : 줄무늬

이렇게 스트라이핑되면 저장된 데이터를 읽고 쓰는 속도가 빨라짐 이론상 한 개를 읽고 쓰는 속도보다 네 배 빨라짐

그러나 이러한 RAID 0 에는 단점이 있는데 만약 RAID0 으로 구성된 하드디스크 중 하나가 문제가 생긴다면 다른 모든 하드 디스크의 정보를 읽는데 문제가 생길 수 있다 따라서 등장한 것이 RAID 1이다.

**RAID1**

RAID 1은 복사본을 만드는 방식이다. 완전한 복사본을 만드는 구성이기에 미러링이라고 부른다.

스트라이핑을 원본과 백업으로 나눠서 저장한다.

이러한 경우 하드 디스크 개수가 한정되어있을 때 사용 가능한 용량이 적어지는 단점이 있다.

**RAID4**

RAID 1 처럼 완전한 복사본을 만드는 대신 오류를 검출하고 복구하기 위한 정보를 저장하는 장치를 두는 구성 방식 이때 오류를 검출하고 복구하기 위한 정보를 **패리티 비트**라고 한다.

**추가 정보 : 패리티 비트**

원래 패리티 비트는 오류 검출만 가능할뿐 오류 복구는 불가하다. 하지만 RAID에는 패리티 값으로 오류 수정도 가능하다.

**RAID 5**

RAID 4 에서는 어떤 새로운 데이터가 저장될 때마다 패리티를 저장하는 디스크에도 데이터를 쓰게 되므로 저장하는 장치에 병목 현상이 발생한다는 문제가 있다.

RAID4는 패리티비트를 저장하는 하드 디스크를 두지만 RAID5는 패리티 정보를 분산하여 저장하여 RAID 4의 문제인 병목 현상을 해소한다.

**RAID 6**

기본적으로 RAID 5와 같으나 서로 다른 두 개의 패리티를 두는 방식이다. 이는 오류를 검출하고 복구할 수 있는 수단이 두 개가 생긴 셈이다.

따라서 RAID 6은 4와 5보다 안전한 구성이라 볼 수 있다. 다만 새로운 정보를 저장할 때마다 함께 저장할 패리티가 두 개이므로 쓰기 속도는 느리다.

RAID 0과 1을 혼합한 RAID10과 0과 5를 혼합한 RAID 50이 있고 이렇게 여러 RAID 레벨을 혼합한 방식을 Nested RAID라고 한다.

# **Chapter 8 입출력장치**

**장치 컨트롤러**

입출력장치는 CPU 메모리보다 다르기 더 까다롭다.

1. 입출력장치에는 종류가 너무나도 많다.
2. 일반적으로 CPU와 메모리의 데이터 전송률은 높지만 입출력장치의 데이터 전송률은 낮다.

전송률이란 데이터를 얼마나 빨리 교환할 수 있는지를 나타내는 지표이다.

- 어떠한 입출력 장치는 CPU나 메모리보다 높은 전송률을 보여주는 경우가 있지만 그렇다 하더라도 결국 비슷하지 않아 같은 어려움이 있음

이러한 이유로 입출력장치는 직접 연결되지 않고 장치 컨트롤러라는 하드웨어를 통해 연결된다.

장치 컨트롤러(device controller)는 입출력 제어기(I/O Controller) 와 입출력 모듈 (I/O module) 등으로 다양하게 불린다.

장치 컨트롤러은 대표적으로 다음과 같은 역할을 통해 앞에서 언급한 문제를 해결한다.

1. CPU와 입출력 장치 간의 통신 중개
2. 오류 검출
3. 데이터 버퍼링

데이터 버퍼링은 먼저 버퍼링이란 전송률이 차이 나는 경우 주고 받는 데이터를 버퍼라는 임시 저장 공간에 저장하여 전송률을 비슷하게 맞추는 방법이다.

장치 컨트롤러의 내부 구성은 복잡하지만 크게 데이터 레지스터와 상태 레지스터, 제어 레지스터로 3 가지의 레지스터로 볼 수 있다.

**데이터 레지스터**는 CPU와 입출력 장치 사이에 주고받을 데이터가 담기는 레지스터로 버퍼 역할을 수행 최근 주고 받는 데이터가 많은 경우 레지스터 대신 RAM을 사용하기도 한다.

**상태 레지스터**는 입출력 작업을 할 준비가 되었는지 입출력 작업이 완료되었는지 입출력장치에 오류는 없는지 등의 상태 정보가 저장된다.

**제어 레지스터**는 입출력장치가 수행할 내용에 대한 제어 정보와 명령을 저장한다.

이 레지스터들에 담긴 값들은 버스를 타고 CPU나 입출력장치로 전달되기도 하고 장치 컨트롤러에 연결된 입출력 장치로 전달된다.

**장치 드라이버**

장치 드라이버란 장치 컨트롤러의 동작을 감지하고 제어함으로써 장치 컨트롤러가 컴퓨터 내부와 정보를 주고 받을 수 있게 하는 프로그램이다.

프로그램이므로 당연히 메모리에 저장

컴퓨터가 장치의 드라이버를 인식하고 실행할 수 있다면 그 장치는 어떠한 제품이든 상관없이 컴퓨터 내부와 정보를 주고받을 수 있다.

**추가정보 : 장치 드라이버를 인식하고 실행하는 주체**

장치 드라이버를 인식하고 실행하는 주체는 운영체제이다. 즉 운영체제가 장치 드라이버를 인식하고 실행할 수 있다면 그 장치는 컴퓨터 내부와 정보를 주고받을 수 있다.

장치 드라이버는 운영체제가 기본적으로 제공할 수 있지만 장치 제작자가 따로 제공할 수 있다.

**다양한 입출력방법**

프로그램 입출력, 인터럽트 기반 입출력, DMA 입출력으로 크게 3가지 방법이 있다.

**프로그램 입출력**

프로그램 속 명령어로 입출력 장치를 제어하는 방법

CPU가 장치 컨트롤러의 레지스터 값을 읽고 씀으로써 이루어진다. CPU는 장치 컨트롤러의 레지스터를 아는 방법은 크게 **메모리 맵 입출력과 고립형 입출력**이 있다.

**메모리 맵 입출력**

메모리 맵 입출력(memory-mapped I/O) 은 메모리에 접근하기 위한 주소 공간과 입출력장치에 접근하기 위한 주소 공간을 하나의 주소 공간으로 간주하는 방법

메모리 맵 입출력 방식에서 CPU는 메모리의 주소들이나 장치 컨트롤러의 레지스터들이나 모두 똑같이 메모리 주소를 대하듯 하면 된다는 점이다. 그래서 메모리에 접근하는 명령어가 굳이 다를 필요가 없다.

**고립형 입출력**

고립형 입출력은(isolated I/O) 은 메모리를 위한 주소 공간과 입출력장치를 위한 주소 공간을 분리하는 방법이다. 위와 다르게 메모리에 접근하는 명령어와 입출력 장치에 접근하는 명령어가 다르다.

**인터럽트 기반 입출력**

입출력장치에 의한 하드웨어 인터럽트는 정확히 입출력장치가 아닌 장치 컨트롤러에 의해 발생된다.

장치 컨트롤러가 입출력 작업을 끝낸 뒤 CPU에게 인터럽트 요청 신호를 보내면 CPU는 하던 일을 잠시 백업하고 인터럽트 서비스 루틴을 실행한다.

이렇게 인터럽트 기반으로 하는 입출력을 인터럽트 기반 입출력이라고 한다.

**추가 정보 : 폴링**

인터럽트와 비교되는 개념으로 폴링(polling)은 입출력장치의 상태는 어떤지 처리할 데이터가 있는지 주기적으로 확인하는 방법이다. 폴링은 당연하게도 CPU에 더 부담이 된다.

여러 인터럽트가 동시에 발생된 경우 현실적으로 모든 인터럽트를 순차적으로 해결할 수 없다. 따라서 CPU는 우선순위를 고려하여 처리를 한다.

플래그 레지스터 속 인터럽트 비트가 활성화되어 있는 경우 혹은 인터럽트 비트를 비활성화해도 무시할 수 없는 인터럽트인 **NMI(Non-Maskable Interupt)**가 발생한 경우 CPU는 높은 우선순위의 인터럽트 부터 처리한다.

우선순위를 반영하여 다중 인터럽트를 처리하는 다양한 방법이 있으나 많은 컴퓨터에서는 **프로그래머블 인터럽트 컨트롤러 PIC(Programmable Interupt Controller)**라는 하드웨어를 사용한다.

PIC는 여러 장치 컨트롤러에 연결되어 장치 컨트롤러에서 보낸 하드웨어 인터럽트 요청들의 우선순의를 판별한 뒤 CPU에 지금처리해야할 하드웨어 인터럽트는 무엇인지 알려주는 장치이다.

PIC의 다중 인터럽트를 처리하는 과정

1. PIC가 장치 컨트롤러에서 인터럽트 요청 신호들을 받아들인다.
2. PIC는 인터럽트 우선순위를 판단한 뒤 CPU에서 처리해야 할 인터럽트 요청 신호를 보낸다.
3. CPU는 PIC에 인터럽트 확인 신호를 보낸다.
4. PIC는 데이터 버스를 통해 CPU에 인터럽트 벡터를 보낸다.
5. CPU는 인터럽트 벡터를 통해 인터럽트 요청의 주체를 알게 되고, 해당 장치의 인터럽트 서비스 루틴을 실행한다.

**DMA 입출력**

위 두가지는 공통적으로 CPU가 주도하고 이동하는 데이터도 반드시 CPU를 거친다는 점이 있다.

이러한 CPU의 부담을 낮추기 위해 상호작용할 수 있는 입출력 방식인 **DMA(Direct Memory Access)**가 등장했다.

**DMA 입출력**을 하기 위해서는 시스템 버스에 연결된 **DMA 컨트롤러**라는 하드웨어가 필요하다.

**DMA 입출력 과정**

일반적으로 아래와 같은 과정으로 이루어진다.

1. CPU는 DMA 컨트롤러에 입출력장치의 주소, 수행할 연산(읽기/쓰기), 읽거나 쓸 메모리의 주소 등과 같은 정보로 입출력 작업을 명령한다.
2. DMA 컨트롤러는 CPU 대신 장치 컨트롤러와 상호작용하여 입출력 작업을 수행한다 이때 DMA 컨트롤러는 필요한 경우 메모리에 직접 접근하여 정보를 읽거나 쓴다.
3. 입출력 작업이 끝나면 DMA 컨트롤러는 CPU에 인터럽트를 걸어 작업이 끝났음을 알린다.

그러나 DMA 컨트롤러는 시스템 버스로 메모리에 직접 접근이 가능하지만 시스템 버스는 동시에 사용이 불가하다.

CPU 입장에서 버스에 접근하는 주기를 도둑 맞은 것과 같아 이러한 이용 방법은 **사이클 스탈링**이라고 부른다.

**입출력버스**

CPU, 메모리, DMA 컨트롤러, 장치 컨트롤러가 모두 같은 버스를 공유하는 구성에서는 DMA를 위해 한 번 메모리에 접근할 때마다 두번 시스템 버스를 이용하는 부작용이 존재한다.

DMA를 위해 시스템 버스를 너무 자주 사용하면 그만큼 CPU가 시스템 버스를 이용할 수 없다. 따라서 이러한 문제를 입**출력 버스라는 별도의 버스에 연결하여** 해결 할 수 있다.

현대 대부분 컴퓨터에는 입출력 버스가 존재.

입출력 버스에는 PCI 버스 , PCI Express 버스 등 여러 종류가 존재한다.

**추가 정보: 더욱 발전한 DMA, 입출력 채널**

여전히 입출력 명령어를 인출하고 해석하고 실행하는 역할은 CPU가 하기 때문에 입출력 전용 CPU가 만들어졌는데 이를 입출력 프로세서 (I/O Processor) 혹은 입출력 채널(I/O Channel)이라고 부른다. 이러한 입출력 채널이 있는 컴퓨터에서는 CPU가 입출력 명령어를 실행하지 않는다.
