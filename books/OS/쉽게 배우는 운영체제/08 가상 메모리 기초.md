# 8 가상 메모리의 기초

컴퓨터마다 물리 메모리, 즉 실제 메모리의 크기가 다르다. 가상 메모리는 크기가 다른 물리 메모리에서 일관되게 프로세스를 실행할 수 있는 기술이다.

## 8.1 가상 메모리의 개요

### 8.1.1 가상 메모리 시스템

가상 메모리 시스템에서 모든 프로세스는 메모리의 어느 위치에 있는지 상관없이 0번부터 시작하는 연속된 메모리 공간을 가진다.

7 장에서 소개한 논리 주소의 크기는 물리 메모리의 주소 공간에 비례하지만, 가상 주소는 물리 메모리 공간이 아닌 가상의 주소 공간을 가진다.

이론적으로 가상 메모리의 크기는 무한하지만 실제로 최대 크기는 컴퓨터 시스템이 가진 물리 메모리의 최대 크기로 한정되며, CPU의 비트에 따라 결정됩니다.

가상 메모리에서 메모리 관리자가 사용할 수 있는 메모리의 전체 크기는 물리 메모리와 스왑 영역의 합한 크기다.

가상 메모리 시스템에서 메모리 관리자는 물리 메모리와 스왑 영역을 합쳐서 프로세스가 사용하는 가상 주소를 실제 메모리의 물리 주소로 변환 한다.

이러한 변환을 동적 주소 변환이라고 한다.

동적 주소 변환을 거치면 프로세스가 아무 제약 없이 사용자 데이터를 물리 메모리에 배치할 수 있다.

이 과정에서 메모리 관리자는 물리 메모리를 어떤 방법으로 나눌지, 사용자 프로세스를 어디에 배치할지, 부족한 물리 메모리를 어떻게 처리할지 등의 복잡한 문제를 처리한다.

### 8.1.2 매핑 테이블의 필요성과 역할

메모리는 매핑 테이블을 작성하여 관리한다.

가상 메모리 시스템에서 가상 주소는 실제로 물리 주소나 스왑 영역 중 한 곳에 위치한다.

메모리 관리자는 가상 주소와 물리 주소를 일대일로 매핑한 테이블로 관리한다.

가상 주소가 물리 메모리의 어느 위치에 있는지 나타낸다.

메모리 분할 방식은 가변 분할 방식과 고정 분할 방식으로 나뉜다고 했는데

가상 메모리 시스템도 마찬가지다.

가상 메모리 시스템에서 가변 분할 방식을 이용한 기법은 세그먼테이션, 고정 분할 방식을 이용한 메모리 관리 기법은 페이징이라고 한다.

그래서 페이지 매핑 테이블, 세그먼테이션 매핑 테이블이라 한다.

### 8.1.3 지역성

지역성 이론이 있다.
접근하는 패턴이 고루 분포되는 것이 아니라 특정 영역에 집중되는 성질을 말한다.

- **공간의 지역성**: 가까운 데이터에 접근할 확률이 먼 거리에 있는 데이터에 접근할 확률보다 높음을 의미한다.
- **시간의 지역성**: 현재 시간 기준으로 가까운 시간에 접근한 데이터가 먼 시간에 접근한 데이터보다 사용될 확률이 높음을 의미한다.
- **순차적 지역성**: 일반적인 프로그래밍은 앞에서부터 순차적으로 진행된다. 순차적 지역성은 작업이 순서대로 진행되는 것을 의미한다.

## 8.2 페이징 기법

### 8.2.1 페이징 기법의 구현

페이징 기법은 고정 분할 방식을 이용한 가상 메모리 관리 기법으로, 물리 주소 공간을 같은 크기로 나누어 사용한다.

가상 메모리는 페이지, 물리 메모리는 프레임

0, 1,2,3 번호를 매김

페이지와 프레임의 크기는 같다.

크기가 같기 때문에 페이지는 어떤 프레임에도 배치될 수 있다.

페이지 테이블은 하나의 열로 구성된다.

페이지의 정보를 순서대로 가지고 있으므로 0부터 인덱싱되어있다.

물리 메모리가 없으면 테이블에 invalid라고 표시하는데 스왑 영역에 있다는 의미다.

### 8.2.2 페이징 기법의 주소 변환

#### **주소 변환 과정**

예를 들어 프로세스가 30번의 내용을 읽으려고 할 때 줏 변환 과정은 다음과 같다.

1. 가상 주소 30번이 어느 페이지에 있는지 찾는다. 30번은 페이지 3의 0번 위치에 있다.
2. 페이지 테이블의 페이지 3으로 가서 해당 페이지가 프레임1에 있다는 것을 알아낸다.
3. 최종적으로 물리 메모리 프레임 1의 0번 위치에 접근한다. 이 주소가 가상 주소 30번의 물리 주소다.

#### **정형화된 주소 변환**

주소 변환 과정을 정형화해보자 페이징 기법에서는 가상 주소를 VA<P,D>로 표현한다.

VA는 가상 주소 P는 페이지 D는 페이지의 처음 위치에서 해당 주소까지의 거리를 의미한다.

페이징 기법의 주소 변환은 가상 주소 VA<P,D>를 물리 주소 PA<F,D>로 변환하는 것이다.

PA는 물리주소의 주소를 가리키는 용어로 물리 주소 혹은 실제 주소라고 한다.

> Virtual Address, Physical Address
> PA<F,D>에서 F는 프레임, D는 프레임의 처음 위치에서 해당 주소까지의 거리

페이지 테이블을 이용하면 간단하게 가상 주소를 물리 주소로 변환할 수 있다.

페이지 테이블에서 페이지 번호를 찾아 해당 프레임 번호를 쫓아가면 된다.

페이지 테이블은 페이지 번호와 프레임 번호로 구성되며, 각각의 한 줄을 페이지 테이블 엔트리라고 부른다.

페이지 테이블은 페이지 번호와 프레임 번호로 구성된 페이지 테이블 엔트리의 집합이다.

페이징 기법에서 페이지 테이블 엔트리는 프레임 번호만 가진다.

페이지 테이블에 페이지 번호가 0부터 순서대로 정리되어 있기 때문에 굳이 페이지 번호를 표시할 필요가 없다.

페이지 테이블 엔트리에 페이지 번호와 프레임 번호가 함께 표시되어 있다면 페이지 번호가 순서대로 저장되지 않은 경우다.

#### **16bit CPU의 주소 변환 예**

한 페이지를 10B로 나누면 주소 변환 과정은 그리 어렵지 않다.

에를 들면 가상 주소 30번은 VA=<3,0>로 나눌 수 있다.

그러나 컴퓨터는 2진법을 사용하므로 페이지의 크기는 2^N 승이 된다.

그래서 페이지의의 크기가 다양할 경우 다음과 같은 공식을 사용한다.

P=나눗셈(가상 주소/ 한 페이지의 크기)의 몫

D=나눗셈(가상 주소/ 한 페이지의 크기)의 나머지

### 8.2.3 페이징 테이블 관리

#### **메모리 공유**

시스템에 여러 개의 프로세스가 존재하고 프로세스마다 페이지 테이블이 하나씩 있기 때문에 페이지 테이블 관리가 복잡하다.

프로세스 A,B,C가 하나의 물리 메모리를 사용하는 경우 프로세스는 메모리에 올라와야 실행이 가능하므로 모든 프로세스의 일부 페이지가 물리 메모리의 프레임에 올라와 있고, 어떤 페이지가 어떤 프레임에 있는지 관리하기 위해 프로세스마다 페이지 테이블을 운영중이다.

페이지 테이블은 메모리 관리자가 자주 사용하는 자료구조이므로 필요시 빨리 접근할 수 있어야한다

따라서 페이지 테이블은 물리 메모리 영역 중 운영체제 영역의 일부분에 모아놓는다.

시스템 내에는 여러 개의 프로세스가 존재하고 프로세스마다 하나의 페이지 테이블이 있기 때문에 전체 페이지 테이블의 크기는 프로세스의 수에 비례해서 커진다.

한 번에 실행하는 프로세스의 수가 많으면 페이지 테이블의 크기가 같이 커지고, 그에 따라 프로세스가 실제로 사용할 수 있는 메모리 영역이 줄어진다.

페이지 테이블 관리의 가장 큰 문제는 테이블의 크기가 작지 않다는 것이다.

예를 들어 32bit CPU 한페이지에 512B인 페이징 시스템이 있다고 가정해보자.

이때 이 시스템에서 페이지 테이블의 최대 크기는 약 24.1ㅡMB인데 이게 페이지 테이블 하나의 크기 이므로 만약 프로세스가 40개라면 페이지 테이블의 최대 크기는 1GB에 육박한다.

최악의 경우 32bit CPU 시스템에서 페이지 테이블이 전체 4GB의 물리 메모리 중 25%를 차지할 수 있다는 말이다.

따라서 페이지 테이블의 크기를 적정하게 유지하는 것이 페이지 테이블 관리의 핵심이다.

물리 메모리 내 페이지 테이블의 구조를 나타낸다.

페이지 테이블 영역에 프로세스별로 페이지 테이블이 배열되어 있는데 프로세스 A의 페이지 테이블은 상단, 프로세스 B의 페이지 테이블은 하단에 있다.

페이지 테이블의 수나 크기가 늘어나면 운영체제 영역이 늘어나 그만큼 사용자 영역이 줄어든다.

물리 메모리의 크기가 작을 때는 프로세스만 스왑 영역으로 옮겨지는 것이 아니라 페이지 테이블의 일부도 스왑 영역으로 옮겨진다.

테이블에 빠르게 접근하기 위해 레지스터가 존재한다.

각 프로세스가 메모리에 접근하려고 하면 메모리 관리자는 페이지 테이블의 위치를 재빨리 파악할 필요가 있다

그래서 각 페이지 테이블의 시작 주소를 **페이지 테이블 기준 레지스터**에 보관한다.

페이지 테이블 기준 레지스터는 각 프로세스의 프로세스 제어 블록에 저장되는 데이터로, 물리 메모리 내에 페이지 테이블의 시작 주소를 가지고 있다.

#### **쓰기 시점 복사**

동시에 여러 개의 같은 크롬 브라우저를 메모리에 올려놓고 사용한다면 메모리가 낭비될 것이다.

낭비를 줄이는 방법은 메모리에 크롬 브라우저를 하나만 올려놓고 공유하는 것이다.

물리 메모리에서 하나의 크롬 브라우저가 3개의 프레임에 나뉘어 들어가 있는데 크롬 브라우저를 사용하려는 프로세스들은 이 3개의 프레임, 즉 프레임 0,1,3을 공유하여 메모리를 절약한다.

그런데 프로세스 A와 B의 브라우저는 서로 다른 홈페이지를 보고 있으므로 데이ㅓ를 공유할 수 없다.

프로세스를 fork()로 복사하면 공유할 수 있는 프레임도 있지만 공유할 수 없는 프레임도 있다.

그림에서 크롬 브라우저의 메인 코드는 공유할 수 있지만, 변수는 공유할 수 없다.
그렇다면 데이터를 저장하기 위한 메모리 공간은 언제 확보해야 할까? 프로세스가 복사되는 시점에 미리 확보하는 경우를 생각해보면

프로세스 B의 변수 Home을 저장할 새 프레임을 미리 확보하는 경우, 이 변수를 사용하면 다행이지만 사용하지 않으면 낭비이므로

운영체제는 필요한 순간까지 새로운 프레임 확보를 미룬다.

그래서 데이터 변화가 있을 때까지 복사를 미루는 방식을 **쓰기 시점 복사**라고 한다.

#### **변환 색인버퍼**

가상 주소를 물리 주소로 변환하는 작업은 CPU 안에 있는 메모리 관리 유닛이 담당한다.

가상 주소를 물리 주소로 변환하려면 메모리에 두번 접근해야한다.

MMU -> 페이지 테이블 -> 물리 메모리

1. 메모리 관리 유닛이 가상 주소를 받아 물리 주소로 변환하려면 페이지 테이블이 필요하지만 페이지 테이블은 메모리에 있다. MMU는 메모리에 있는 페이지 테이블에 접근하여 물리 주소를 변환한다.

2. 변환된 물리 주소를 이용하여 필요한 데이터를 가져온다.

CPU 안에 있는 레지스터나 캐시에 접근할 때보다 물리 메모리에 접근할 때 시간이 몇 배 이상 더 걸려서 메모리에 두 번 접근하는 것은 성능을 떨어뜨린다.

따라서 이러한 문제를 개선하기 위해 페이지 테이블의 일부를 CPU 안쪽으로 가져오는데, 이를 변환 색인 버퍼(TLB)라고 한다.

변환 색인 버퍼는 캐시된 페이지 테이블 블럭이다. 지역성 이론에 근거하여 현재 사용 중이거나 사용이 예상되는 페이지 테이블의 일부를 CPU 안쪽에 가져온다.

TLB는 물리 메모리 접근 방식으로, 이 방식은 캐시 시스템과 유사하다.

먼저 주소 변환을 위해 변환 색인 버퍼를 찾는다.

원하는 페이지 번호가 없으면 TLB 미스라고 하며, 메모리에 있는 페이지 테이블을 사용하여 프레임 번호로 변환한다.

물리 주소로 변환하는 경우 변환 색인 버퍼를 검색해서 페이지 번호가 있는지 확인한다.

변환 색인 버퍼를 검삭할 때는 하드웨어적으로 병렬 검색이 가능하도록 구성된다.

즉 한 번에 모든 행의 페이지를 검색하여 원하는 데이터가 있는지 확인할 수 있다.

원하는 페이지가 없는 경우, 메모리에 있는 페이지 테이블에 접근하여 물리 주소로 변환하고, 변환된 물리 주소를 사용하여 메모리에 다시 접근한다.

#### **역 페이지 테이블**

역 페이지 테이블 방식은 물리 메모리의 프레임 번호를 기준으로 테이블을 구성하는 것으로 물리 메모리의 프레임에 어떤 프로세스의 어떤 페이지가 올라와 있는지를 표시한다.

역 페이지 테이블의 가장 큰 특징은 프로세스의 수와 상관없이 테이블이 하나만 존재한다는 것이다.

일반적인 페이징 메모리 관리 기법에서는 프로세스마다 페이지 테이블을 만들지만 역 페이지 테이블에서는 물리 메모리를 기준으로 프레임 테이블을 만들기 때문에 전체 시스템에서 테이블 수가 단 1개다.

따라서 테이블의 크기가 작다는 장점이 있다.

역 페이지 테이블의 구성을 나타낸다.

역 페이지 테이블은<프레임 번호, 프로세스 아이디, 페이지 번호>로 구성되고 페이지 테이블의 행 수는 실제 프레임의 수와 같다.

그러므로 프로세스의 수와 상관없이 항상 일정 크기의 페이지 테이블을 유지한다.

역 페이지 테이블 방식에서 주소 변환 시 메모리 관리자는 주소 변환을 해야하는 프로세스 아이디와 페이지 번호가 물리 메모리에 있는지를 역 페이지 테이블에서 검색한다.

원하는 프레임 번호가 있는 경우 역 페이지 테이블의 위치가 프레임 번호가 된다.

#### **다단계 페이지 테이블**

비트수가 16,32, 64 bit로 늘어남에 따라 사용할 수 있는 주소 공간이 기하급수적으로 늘어났다.

주소 공간이 늘어나 페이지 테이블의 크기가 늘어나면 한꺼번에 관리하기가 힘들다.

이러한 문제를 해결하기 위해 만든 방식이 다단계 페이지 테이블이다.

다단계 페이지 테이블의 기본 구조는 일정 크기로 자른 페이지 테이블의 바깥쪽에 이를 관리하는 새로운 테이블을 만드는 것이다.

다단계 페이지 테이블 방식은 **집합-연관 매핑**, **디렉터리 매핑**이라고 부른다.

새로 생성한 1차 테이블은 일정하게 자른 2차 페이지 테이블의 물리 메모리 시작 주소를 나타낸다.

1차 테이블에서 I 라고 표시된 것은 해당하는 2차 페이지 테이블이 아직 만들어지지 않았다는 의미다.

다단계 페이지 테이블 방식에서는 전체 페이지 테이블을 한꺼번에 만들지 않고 필요할 때마다 만든다.

필요할 때 2차 페이지 테이블을 만들고, 1차 페이지 테이블의 값을 업데이트한다.

3,4 단계로 나뉠수도있는데 이러한 특성으로 멀티페이지 매핑이라고 부른다.

## 8.3 세그먼테이션 기법

### 8.3.1 세그먼테이션 기법의 구현

세그먼테이션 기법은 가상 주소가 물리 주소로 변환된다.

페이징 기법과 마찬가지로 세그먼테이션 테이블을 사용한다.

세그먼트의 크기를 나타내는 limit과 물리 메모리의 시작 주소를 나타내는 address가 있다.

페이징 기법에는 메모리를 같은 크기의 페이지 단위로 분할하기 때문에 크기 정보를 포함한다.

각 세그먼트가 자신에게 주어진 메모리 영역을 넘어가면 안 되기 때문에 세그먼트의 크기 정보에는 크기를 뜻하는 size 대신 제한을 뜻하는 limit을 쓴다.

페이징과 마찬가지 물리 메모리가 부족할 땐 스왑 영역을 사용한다.

세그먼테이션 기법은 가변 분할 방식이 기본이므로 가변 분할 방식의 장단점을 모두 가진다.

외부 단편화로 인해 관리가 복잡하다는 것이다.

### 8.3.2 세그먼테이션 기법의 주소 변환

VA=<S,D>로 표현한다.

S는 세그먼트 번호

D는 세그먼트 시작 지점에서 해당 주소까지의 거리를 의미한다.

가상 메모리 시스템에서 사용자에게 보이는 메모리는 항상 0부터 시작하므로 페이징 기법이든 세그먼테이션 기법이든 D는 사용자가 지정한 주소 그자체이다.

1. 먼저 가상 주소를 구한다. 프로세스 A는 세그먼트 0으로 분할되었으므로 S는 0, D는 32다 따라서 가상 주소는 VA =<0,32>다

2. 세그먼테이션 테이블에서 세그먼트 0의 시작 주소 120을 알아낸 후 거리 32를 더하여 물리 주소 152번을 구한다. 이때 메모리 관리자는 거리가 세그먼트의 크기보다 큰지 점검한다. 크다면 메모리를 벗어나는 것이므로 메모리 오류를 출력하고 해당 프로세스를 강제 종료한다. 크지 않다면 물리 주소를 구한다.

3. 물리 주소에 접근하여 원하는 데이터를 읽거나 쓴다.

세그먼테이션 테이블의 limit은 메모리를 보호하는 역할을 하는데 만약 더 큰 주소에 접근하려고 한다면 트랩을 반환한다.

트랩은 주소를 벗어나는 접근 혹은 0으로 나눌 때 발생하는 인터럽트이다.

이때 세그먼테이션 오류를 발생한다.

## 8.4 캐시 매핑 기법

### 8.4.1 캐시 직접 매핑

캐시도 메모리를 일정 크기로 나누며 일정 크기로 나눈 덩어리를 페이지 P라 부르고 여기까지는 페이징 기법과 똑같다.

메모리는 N개의 페이지 캐시는 M개의 페이지 일떄 M < N 이다

캐시 직접 매핑에서는 메모리의 페이지 수를 N 캐시의 페이지 수를 M으로 나누고 이를 블록이라 부른다.

이것은 메모리를 캐시 크기인 블록으로 자른 다는 의미다.

메모리의 페이지 수 N은 M x 블록 수가 된다.

캐시 직접 매핑에서는 메모리 블록이 같은 위치의 캐시로 올라온다.

블록의 첫 번째 페이지는 캐시의 첫 번째 페이지로 블록의 두 번째 페이지는 블록의 두 번째 페이지로만 올라옵니다.

캐시에 명시하는 블록 번호를 태그라고 하고 캐시 직접 매핑에서 캐시 히트나 캐시 미스가 있는지 알기 위해서는 태그를 확인합니다..

캐시 직접 매핑의 가장 큰 특징은 메모리의 페이지가 캐시의 정해진 위치에만 들어갈 수 있다는 것이다.

캐시 00 위치에 A, B,C,D 중 어떤 데이터가 올라왔는지 확인하기 위해 캐시는 태그를 유지한다. 태그는 메모리 주소의 앞 2bit에 해당하는 값으로 어떤 블록에서 올라온 데이터인지 나타낸다.

캐시 직접 매핑의 장점은 캐시의 같은 위치가 올라오기 때문에 태그만 확인하면 캐시 히트나 캐시 미스를 빠르게 확인할 수 있다는 것이다.

그러나 같은 위치에만 올라오기 때문에 자리 다툼이 발생한다는 단점도 있다.

### 8.4.2 캐시 연관 매핑

연관 매핑은 캐시의 어느 위치에도 자유롭게 올라갈 수 있으므로 캐시가 메모리의 주소를 전부 가지고 있다.

CPU가 특정 주소를 필요로 할 때 캐시에서 검색하여 찾는 경우는 캐시 히트이지만, 찾지 못하면 캐시 미스가 발생하여 메모리에서 원하는 데이터를 가져온다.

캐시 연관 매핑은 캐시 메모리를 자유롭게 사용할 수 있는데 캐시 히트와 미스를 판별하기 위해서 캐시의 모든 주소를 검색해야 한다는 단점도 있다.

따라서 연관 매핑은 캐시 직접 매핑보다 느리다.

### 8.4.3 캐시 집합-연관 매핑

캐시 집합 연관 매핑은 캐시 직접 매핑과 캐시 연관 매핑의 장점만 취한 방식인데.

캐시를 K개의 집합으로 나누고 각 집합에 캐시 직접 매핑을 사용한다.

K개로 나눔으로써 같은 끝자리를 가진 캐시 메모리도 K개가 되어 자리다툼 문제가 완화된다.
