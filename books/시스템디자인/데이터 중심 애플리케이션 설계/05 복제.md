# 5 복제

**복제**란 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지한다는 의미다.

2부의 소개에서 설명한 것처럼 데이터 복제가 필요한 여러 이유가 있다.

- **지리적으로 사용자와 가깝게 데이터를 유지해 지연 시간을 줄인다.**:
- **시스템의 일부에 장애가 발생해도 지속적으로 동작할 수 있게 가용성을 높인다.**:
- **읽기 질의를 제공하는 장비의 수를 확장해 읽기 처리량을 늘린다.**:

복제 중인 데이터가 시간이 지나도 변경되지 않는다면 복제는 쉽다.

복제에서 모든 어려움은 복제된 데이터의 **변경** 처리에 있다. 이것이 이번 장의 내용이다.

노드 간 변경을 복제하기 위한 세 가지 인기 있는 알고리즘ㅇ니 단일 리더, 다중 리더, 리더 없는 복제를 살펴본다.

## 5.1 리더와 팔로워

복제 서버 중 하나를 리더로 선출하고, 클라이언트가 쓰기를 하면 클라이언트는 요청을 리더에 보내야 한다.

리더는 먼저 로컬 저장소에 데이터를 기록한다.

다른 복제 서버는 팔로워, 슬레이브, 2차 등의 이름으로 불리는데, 리더가 로컬 저장소에 새로운 데이터를 기록할 때마다 데이터 변경은 복제 로그나 변경 스트림의 일부로 팔로워에게 전송한다.

클라이언트가 데이터베이스로부터 읽기를 할 때는 리더 또는 임의 팔로워에게 질의할 수 있다.

하지만 쓰기는 리더에게만 허용된다. (즉 팔로워는 클라이언트 입장에서 읽기 전용이다.)

### 5.1.1 동기식 대 비동기식 복제

- 동기 복제 팔로워의 ok를 수신 받는다.
- 비동기 복제 팔로워의 ok를 수신 받지 않는다.

그래서 팔로워에게 변경 내용을 적용하지만 얼마나 오래 걸릴지를 보장할 수 없다.

동기식은 일관성 있게 최신 데이터 복사본을 가지는 것을 보장한다.

단점은 동기 팔로워가 응답하지 않으면 처리가 불가하다. 그래서 리더는 모든 쓰기가 block되고 동기 복제 서버가 다시 사용할 수 있을 때까지 기다려야한다.

이런 이유로 모든 팔로워가 동기식인 상황은 비현실적이다.

보통 팔로워 하나는 동기식이고 그 외는 비동기로 한다. 동기식 팔로워가 사용할 수 없거나 느려지면 비동기 팔로워 중 하나가 동기식으로 변경된다.

이러한 설정을 반동기식이라고 한다.

보통 리더 기반 복제는 완전한 비동기로 구성되는데, 이런 경우 리더가 잘못되고 복구할 수 없으면 팔로워에 아직 복제되지 않은 모든 쓰기는 유실된다.

이것은 쓰기가 클라이언트에게 확인된 경우에 지속성을 보장할 수 없다는 의미다.

하지만 쓰기 처리를 계속 할 수 있다는 장점이 있다.

비동기 복제는 나쁜 트레이드 오프같지만 그럼에도 많은 팔로워가 있거나 지리적으로 분산됐다면 비동기 복제를 널리 사용한다.

### 5.1.2 새로운 팔로워 설정

때때로 복제 서버 수를 늘리거나 장애 노드의 대체를 위해 새로운 팔로워를 설정해야 한다.

새로운 팔로워가 리더의 데이터 복제본을 정확히 가지고 있는지 어떻게 보장할까 ?

- 1. 가능하다면 전체 데이터베이스를 잠그지 않고 리더의 데이터베이스 스냅숏을 일정 시점에 가져온다. 대부분의 데이터베이스는 백업이 필요하기 때문에 이 기능을 갖췄다.
- 2. 스냅숏을 새로운 팔로워 노드에 복사한다.
- 3. 팔로워는 리더에 연결해 스냅숏 이후 발생한 모든 데이터 변경을 요청한다. 이것은 스냅숏이 리더의 복제 로그의 정확한 위치와 연관돼야 한다. 이 위치의 명칭은 다양하다. 예를 들어 MySQL은 binlog conrdinate 라고 부른다.
- 4.  팔로워가 스냅숏 이후 데이터 변경의 미처리분을 모두 처리했을 때 따라잡았다고 한다. 이제부터 리더에 발생하는 데이터 변화를 이어 처리할 수 있다.

### 5.1.3 노드 중단 처리

시스템의 모든 노드는 장애로 인해 예기치 않게 중단될 수 있지만 계획된 유지보수에 의해 중단될 수 있다.

중단 시간 없이 개별 노드를 재부팅할 수 있다는 점은 운영과 유지보수에 큰 장점이다.

따라서 개별 노드의 장애에도 전체 시스템이 동작하게끔 유지하고 노드 중단의 영향을 최소화하는 것이 목표다.

리더 기반 복제에서 고가용성은 어떻게 달성될 수 있을까 ?

### 5.1.4 복제 로그 구현

#### 팔로워 장애: 따라잡기 복구

각 팔로워는 리더로부터 수신한 데이터 변경 로그를 로컬 디스크에 보관한다. 팔로워가 죽어 재시작하거나 리더와 팔로워 사이의 네트워크가 일시적으로 중단된다면 팔로워는 매우 쉽게 복구할 수 있다.

장애 발생 전에 처리한 마지막 트랜잭션을 알아내고 팔로워는 따라잡을 수 있다.

#### 리더 장애: 장애 복구

리더의 장애를 처리하는 일은 까다롭다.

팔로워 중 하나를 새로운 리더로 승격해야 하고 클라이언트는 새로운 리더로 쓰기를 전송하기 위해 재설정이 필요하며 다른 팔로워는 새로운 리더로부터 데이터 변경을 소비하기 시작해야 한다.

이 과정을 장애 복구라 한다.

장애 복구는 수동으로 진행하거나 자동으로 진행한다.

자동 장애 복구는 다음과 같은 과정을 따른다.

- **1. 리더가 장애인지 판단한다.**: 고장, 정전, 네트워크 문제 등 알 수 없어서 보통 타임 아웃을 사용한다.
- **2. 새로운 리더를 선택한다.**: 선출 과정을 통해 이뤄지거나 이전에 선출된 제어 노드에 의해 새로운 리더가 임명될 수 있다. 새로운 리더로 가장 적합한 후보는 보통 이전 리더의 최신 데이터 변경사항을 가진 복제 서버다. 모든 노드가 새 리더 추대에 동의를 구하는 합의 문제는 9장에 설명한다.
- **3. 새로운 리더 사용을 위해 시스템을 재설정한다.**: 클라이언트는 이제 새로운 쓰기 요청을 새로운 리더에게 보내야한다. 이전 리더가 돌아오면 여전히 자신이 리더라고 믿을 수 있으며, 다른 복제 서버들이 자신을 리더에서 물러나게 한 것을 알지 못한다. 그래서 시스템은 이를 인지시키는 과정이 필요하다.

장애 복구 과정은 잘못될 수 있는 것 투성이다.

- 비동기식 복제를 사용한다면 새로운 리더는 이전 리더가 실패하기 전에 이전 리더의 쓰기를 일부 수신하지 못할 수 있다. 그래서 일반적인 해결은 이전 리더의 복제되지 않은 쓰기를 단순히 폐끼하는 방법이다. 이 방법은 내구성에 대한 클라이언트의 기대를 저버리게 된다.
- 쓰기를 폐기하는 방법은 데이터베이스 외부의 다른 저장소 시스템이 데이터베이스 내용에 맞춰 조정돼야 한다면 특히 위험하다. 깃헙에서 발생한 사고 중 하나로 유효하지 않은(out-of-date) MySQL 팔로워가 리더로 승격된 사례가 있다. 데이터베이스는 새로운 로우의 기본키를 할당하기 위해 자동 증가 카운터를 사용했지만 이전 리더가 할당한 기본키를 재사용했었다. 이 기본키는 레디스 저장에도 사용했기 때문에 기본키의 재사용은 MySQL과 Redis의 불일치를 일으켰다. 결국 일부 개인 데이터가 잘못된 사용자에게 공개됐다.
- 특정 결함 시나리오에서 두 노드가 모두 자신이 리더라고 믿을 수 있다. 이런 상황을 스플릿 브레인이라고 한다. 이는 매우 위험한 상황이다. 이를 해소하지 않으면 데이터가 유실되거나 오염된다. 일부 시스템은 두 리더가 감지되면 한 노드를 종료하는 메커니즘이 있다.
- 리더가 분명히 죽었다고 판단 가능한 적절한 타임아웃이 얼마일까 ?너무 길면 복구가 오래 걸리고 너무 짧으면 불필요한 장애 복구가 발생할 수 있다.

이 문제에 대한 쉬운 해결은 없다.

이런 이유로 일부 운영팀은 소프트웨어가 자동 장애 복구를 지원하더라도 수동으로 장애 복구를 수행하는 방식을 선호한다.

## 5.2 복제 지연 문제

- 리더 기반 복제는 내부적으로 어떻게 작동할까 ?

실제로는 다양한 복제 방법을 사용한다.

#### 구문 기반 복제

statement를 기록하고 쓰기를 실행한다음 statement를 팔로워에게 전송한다.

- 비결정적 함수를 호출하는 모든 구문은 각 복제 서버마다 다른 값을 생성할 가능성이 있다.
- 자동증가 컬럼을 사용하는 구문이나 데이터베이스에 있는 데이터에 의존한다면 구문은 각 복제 서버에 정확히 같은 순서로 실행돼야 한다. 이 방식은 동시에 여러 트랜잭션이 수행되는 것을 발해한다.
- 부수 효과를 가진 구문은 부수 효과가 완벽하게 결정적이지 않으면 복제 서버에 다른 부수 효과가 발생할 수 있다.

이를 해결하기위해 모든 비결정적 함수를 고정 값을 반환하게 바꿀 수 있지만 여러가지 에지 케이스가 있기 때문에 일반적으로 다른 복제를 선호한다.

#### 쓰기 전 로그 배송

팔로워가 이 로그를 처리하면 리더에 있는 것과 정확히 동일한 데이터 구조의 복제본이 만들어진다.

이 복제 방식은 포스트그레스큐엘과 오라클 등에서 사용된다.

가장 큰 단점은 로그가 제일 저수준의 데이터를 기술한다는 것이다.

WAL은 어떤 디스크 블록에서 어떤 바이트를 변경했는지를 기록한다.

근데 이렇게하면 복제가 저장소 엔진과 밀접해진다.

#### 논리적 로그 복제

복제 로그를 저장소 엔진 내부와 분리하기 위한 대안 하나는 복제와 저장소 엔진을 위해 다른 로그 형식을 사용한다. 그래서 이를 논리적 로그라 부른다.

논리적 로그를 저장소 엔진 내부와 분리했기 때문에 하위 호환성을 더 쉽게 유지할 수 있고 리더와 팔로워에서 다른 버전의 데이터베이스 소프트웨어나 심지어 다른 저장소 엔진을 실행할 수 있다.

논리적 로그 복제는 CDC라고 부르는 기술에 유용하다. (외부 애플리케이션에 전송할 때)

#### 트리거 기반 복제

트리거나 스토어드 프로시저를 사용한다. 그런데 이 방식은 내장된 복제보다 버그나 제한 사항이 더 많지만 유연성때문에 유용하다.

### 복제 지연 문제

리더 기반 복제는 모든 쓰기가 단일 노드를 거쳐야 하지만 읽기 전용 질의는 어떤 복제 서버에서도 가능하다.

그래서 CQRS 등에 사용될 수 있다.
그래서 이런 읽기 확장 아키텍처에서는 간단히 팔로워를 더 추가함으로써 읽기 전용 요청을 처리하기 위한 용량을 늘릴 수 있다.

하지만 이 접근 방식은 실제로 비동기식 복제에서만 동작한다.

동기식으로 모든 팔로워에게 복제를 시도한다면 단일 노드 장애나 네트워크 중단으로 전체 시스템의 쓰기가 불가능해진다.

비동기 팔로워에서 데이터를 읽을 때 뒤처진다면 지난 정보를 볼 수 있다. 이 상황은 명백히 불일치가 발생한다.

이와 동시에 리더와 팔로워에 동일한 질의를 수행하면 모든 쓰기가 팔로워에 반영되지 않았기 때문에 서로 다른 결과를 얻을 수도 있다.

결국 따라잡기 때문이고 이를 최종적 일관성이라고 한다.

최종적이란 용어는 모호하다 얼마나 뒤처졌는지 대한 제한이 없다.

아주 짧거나 가용량 근처에서 동작하거나 네트워크의 문제가 있으면 수 초에서 수 분으로 증가할 수 있다.

### 5.2.1 자신이 쓴 내용 읽기

많은 애플리케이션은 사용자가 임의 데이터를 제출하고 해당 사용자에게 제출한 데이터를 볼 수 있게 한다.

비동기식 복제에서는 다음과 같은 문제가 있을 수 있다.

쓰기 직후 데이터를 본다면 새로운 데이터는 복제 서버에 반영되지 않았을 수 있다.

이것은 사용자에게 제출된 데이터가 유실된 것처럼 보이기 때문에 당연히 불만족스러울 동작이다.

이런 상황에서는 "쓰기 후 읽기 일관성"이 필요하다.

이것은 사용자가 페이지를 재로딩했을 때 항상 자신이 제출한 모든 갱신을 볼 수 있음을 보장하며 다른 사용자에게 대해서는 보장하지 않는다.

어떻게 리더 기반 복제 시스템에서 쓰기 후 읽기 일관성을 구현할까?

1. 사용자가 수정한 내용을 읽을 때는 리더에서 읽는다.

이를 위해서는 실제로 질의하지 않고 무엇이 수정됐는지 알 수 있는 방법이 필요하다.

예를 들어 사용자 정보는 프로필 소유자만 편집할 수 있다.

따라서 항상 소유자 피로필은 리더에서 읽고 다른 사용자의 프로필은 팔로워에서 읽는 간단한 규칙을 사용한다. 2. 애플리케이션 내 대부분 사용자가 편집할 가능성이 있다면 대부분 리더에서 읽기 때문에 효율적이지 않다.

이런 경우에는 리더에서 읽을지 말지 결정하기 위해 다른 기준을 사용해야 한다.

예를 들어 마지막 갱신 시간을 찾아서 마지막 갱신 후 1분 동안 리더에서 모든 읽기를 수행한다.

또한 팔로워에서 복제 지연을 모니터링해 1분 이상 늦은 모든 팔로워에 대한 질의를 금할 수 있다.

3. 클라이언트는 가장 최근 쓰기의 타임스탬프를 기억할 수 있고, 그러면 시스템은 사용자 읽기를 위한 복제 서버가 최소한 해당 타임스탬프까지 갱신을 반영할 수 있게 한다.

그러면 시스템은 사용자 읽기를 위한 복제 서버가 최소한 해당 타임스탬프까지 갱신을 반영할 수 있다.

복제 서버가 아직 최신 내용이 아닌 경우에는 다른 복제 서버가 읽기를 처리하거나 복제 서버가 따라잡을 때까지 질의를 대기 시킬 수 있다.

타임스탬프는 논리적 타임스탬프거나 실제 시스템 시간일 수 있다.

4.  복제 서버가 여러 데이터센터에 분산됐다면 복잡도가 증가한다.

리더가 제공해야 하는 모든 요청은 리더가 포함된 데이터센터로 라우팅돼야 한다.

동일한 사용자가 여러 디바이스에 접근할 때 또 다른 문제가 발생한다. 이 경우 디바이스 간 쓰기 후 읽기 일관성이 제공돼야 한다.

### 5.2.2 단조 읽기

비동기식 팔로워에게 읽을 때 발생할 수 있는 두 번째 이상 현상은 사용자가 시간이 거꾸로 흐르는 현상을 복격할 수 있다.

여러 팔로워를 가지고 있을 때 새로 고침을 반복하면 웹 서버가 각기 다르게 라우팅 될 수 있을 때 시간이 거꾸로 갈 수 있다.

단조 읽기는 이런 종류의 이상 현상이 발생하지 않음을 보장한다.

단조 읽기는 강한 일관성보다는 덜한 보장이지만 최종적 일관성보다는 더 강한 보장이다.

데이터를 읽을 때 이전 값을 볼 수 있다.

한 사용자가 여러 번 걸쳐 여러 번 읽어도 시간이 되돌아가는 현상을 보지 않는다는 의미다.

이를 달성하게 하는 방법은 각 사용자가 읽기가 항상 동일한 복제 서버에서 수행되게끔 하는 것이다.

예를 들어 임의 선택보다는 사용자 ID의 해시를 기반으로 복제 서버를 선택한다.

하지만 복제 서버가 고장나면 재라우팅할 필요가 있다.

### 5.2.3 일관된 순서로 읽기

세 번째 복제 지연 이상 현상은 인과성의 위반 우려다.

이러한 종류의 이상 현상을 방지하려면 일관된 순서로 읽기 같은 또 다른 유형의 보장이 필요하다.

일관된 순서로 읽기는 일련의 쓰기가 특정 순서로 발생한다면 이 쓰기를 읽는 모든 사용자는 같은 순서로 쓰여진 내용을 보게됨을 보장한다.

이는 파티셔닝된 데이터베이스에서 발생하는 특징이다.

한 가지 해결책은 서로 인과성이 있는 쓰기가 동일한 파티션에 기록되게끔 하는 방법이다.

하지만 일부 애플리케이션에서는 효율적이지 않다.

### 5.2.4 복제 지연을 위한 해결책

최종적 일관성 시스템으로 작업할 때 복제 지연이 몇 분이나 몇 시간으로 증가하면 애플리케이션에서 어떻게 동작할지 생각해볼 가치가 있다.

대답이 문제 없음이면 아주 좋지만 결과가 사용자에게 좋지 않은 경험이라면 쓰기 후 읽기와 같은 강한 보장을 제공하게끔 시스템을 설계해야 한다.

사실은 복제가 비동기식으로 동작하지만 동기식으로 동작하는 척 하는 것이 문제 해결 방안이다.

## 5.3 다중 리더 복제

단일 리더의 문제는 리더가 고장나면 데이터베이스에 쓰기를 할 수 없다.

그래서 리더 기반 복제 모델은 쓰기를 허용하는 노드를 하나 이상 두는 것으로 자연스럽게 확장된다.

복제는 여전히 같은 방식을 사용한다.

이를 다중 리더 설정이라 부른다.

### 5.3.1 다중 리더 복제의 사용 사례

#### 다중 데이터센터 운영

여러 다른 데이터센터에 데이터베이스 복제 서버가 있다고 상상해보자(전체 데이터 센터의 내결함성을 갖추기 위해서 또는 사용자에게 지리적으로 가까이 위치하기 위해). 일반적인 리더 기반 복제 설정은 리더가 하나의 데이터센터에 있고 모든 쓰기는 해당 데이터센터를 거쳐야 한다.

다중 리더 설정에서는 각 데이터센터마다 리더가 있을 수 있다.

- **성능**: 단일 리더 설정에서 모든 쓰기는 인터넷을 통해 리더가 있는 데이터 센터로 이동해야 한다. 이것은 쓰기에 지연 시간을 상당히 늘리는 원인이 된다. 그리고 처음에는 여러 데이터 센터를 갖추는 목적에도 위배될 수 있다.
- **데이터센터 중단 내성**: 데이터센터 중단 내성 단일리더 설정에서는 데이터센터가 고장나면 장애 복구를 위해 다른 데이터센터에서 한 팔로워를 리더로 승진시킨다. 다중 리더 설정에서는 각 데이터센터는 다른 데이터센터와 독립적으로 동작하고 고장난 데이터센터가 온라인으로 들어왔을 때 복제를 따라잡는다.
- **네트워크 문제 내성**: 데이터센터 간 트래픽은 보통 공개 인터넷을 통해 처리한다. 그래서 데이터센터 내의 로컬 네트워크보다 안정성이 떨어진다. 일시적인 네트워크 중단에도 쓰기 처리는 진행되기 때문이다.

일부 데이터베이스는 기본적으로 다중 리더 설정을 제공한다. 하지만 MySQL의 텅스텐 리플리케이터등 외부에서 구현한 도구를 사용하기도 한다.

이점이 있지만 큰 단점도 존재한다. 동일한 데이터를 다른 두 개의 데이터센터에서 동시에 변경할 수 있다.

이를 쓰기 충돌을 반드시 해소해야하는데, 이러한 문제를 이해해보자

#### 오프라인 작업을 하는 클라이언트

이 경우 모든 디바이스에는 리더처럼 동작하는 로컬 데이터베이스가 있다. (쓰기 요청을 받아야 함)

그리고 모든 디바이스 상에서 캘린더의 복제 서버 간 다중 리더 복제를 비동기 방식으로 수행하는 프로세스가 있다.

복제 지연은 사용자가 인터넷 접근이 가능해진 시점에 따라 몇 시간에서 며칠 이상도 걸릴 수 있다.

다중 리더 복제는 올바르게 동작하기 까다롭다.

#### 협업 편집

실시간 협업 편집 애플리케이션은 위 문제와 유사하다.

이 협업 모델은 리더에서 트랜잭션을 사용하는 단일 리더 복제와 동일하다.

#### 쓰기 충돌 다루기

어떤 데이터를 동시에 편집하면 서로 다른 결과가 발생할 수 있다.

#### 동기 대 비동기 충돌 감지

다중 리더에서는 두 쓰기가 모두 성공할 수 있으며, 충돌은 이후 특정 시점에서 비동기로만 감지한다.

이때 사용자에게 요청하면 너무 늦을 수 있다.

이론적으로 충돌 감지는 동기적으로 만들 수 있다.

하지만 다중 리더 복제의 주요 장점을 잃는다.

#### 충돌 회피

가장 간단한 방법이다. 특정 레코드의 모든 쓰기가 동일한 레코드를 거치도록 애플리케이션이 보장한다면 충돌은 발생하지 않는다.

이것은 자주 권장되는 방식이다.

하지만 때떄로 데이터 센터가 고장나서 트래픽을 다른 데이터센터로 다시 라우팅해야 하거나 사용자가 다른 지역으로 이동해 현재는 다른 데이터센터가 가깝다면 레코드를 위해 지정된 리더로 변경하고 싶을 수도 있다. 이런 상황에서는 충돌 회피가 실패한다.

#### 일관된 상태 수렴

단일 리더 데이터베이스는 순차적으로 쓰기를 적용한다. 동일한 필드를 여러 번 갱신한다면 마지막 쓰기가 필드의 최종값으로 결정된다.

다중 리더 설정에서는 쓰기 순서가 정해지지 않아 최종 값이 무엇인지 명확하지 않다.

데이터베이스는 수렴 방식으로 충돌을 해소해야한다. 이는 모든 변경이 복제돼 모든 복제 서버에 동일한 최종값이 전달되게 해야 한다는 의미다.

- 각 쓰기에 고유 ID를 부여하고 가장 높은 ID를 가진 쓰기를 고른다 타임스탬프를 쓰면 LWW라고 한다. 그러나 이 방식은 데이터 유실 위험이 있다.
- 각 복제 서버에 고유 ID를 부여하고 높은 숫자의 복제서버보다 항상 우선적으로 적용되게 한다 마찬가지로 데이터 유실이 발생할 수 있다.
- 어떻게든 값을 병합한다 사전순으로 병합해보면 된다.
- 명시적 데이터 구조에 충돌을 기록해 모든 정보를 보존한다. 나중에 사용자에게 메시지를 보여준다. 충돌을 해소하는 애플리케이션 코드를 작성한다.

#### 사용자 정의 충돌 해소 로직

충돌을 해소하는 적합한 방식은 애플리케이션에 따라 다르다. 대부분의 다중 리더 복제 도구는 애플리케이션 코드를 사용해 충돌을 해소하려고 한다.

- 쓰기 수행 중: 복제된 변경 사항 로그에서 데이터베이스 시스템이 충돌을 감지하자마자 충돌 핸들러를 호출한다. 예를 들어 부카르도에서는 이런 목적으로 펄코드를 작성할 수 있다.
- 읽기 수행 중: 충돌을 감지하면 모든 충돌 쓰기를 저장한다. 다음 번 데이터를 읽을 때 이런 여러 버전의 데이터가 애플리케이션에 반환된다. 카우치 DB가 이런 방식으로 작동한다.

충돌 해소는 보통 전체 트랜잭션이 아니라 개별 로우나 문서 수준에서 적용된다.

### 5.3.2 쓰기 충돌 다루기

### 5.3.3 다중 리더 복제 토폴로지

## 5.4 리더 없는 복제

### 5.4.1 노드가 다운됐을 때 데이터베이스에 쓰기

### 5.4.2 정족수 일관성의 한계

### 5.4.3 느슨한 정족수와 암시된 핸드오프

### 5.4.4 동시 쓰기 감지
