# 3. 회귀 알고리즘과 모델 규제

## 3.1 k-최근접 이웃 회귀

### k-최근접 이웃 회귀

k-최근접 이웃 회귀는 예측하려는 샘플에 가장 가까운 샘플 k개를 선택하고, 이 샘플들의 타깃의 평균을 예측값으로 사용한다.

```python
from sklearn.neighbors import KNeighborsRegressor

knr = KNeighborsRegressor()
knr.fit(train_input, train_target)
```

### 결정계수

회귀 모델의 성능을 측정하는 대표적인 도구는 **결정계수(R²)**다.

R² = 1 - (타깃 - 예측)² 의 합 / (타깃 - 평균)²의 합

```python
print(knr.score(test_input, test_target))
```

### 과대적합 vs 과소적합

- 과대적합: 훈련 세트에서 점수가 굉장히 좋았는데 테스트 세트에서는 점수가 굉장히 나쁜 경우
- 과소적합: 훈련 세트보다 테스트 세트의 점수가 높거나, 두 점수 모두 너무 낮은 경우

과소적합이 일어나면 모델을 조금 더 복잡하게 만들어야 한다. k-최근접 이웃의 경우 k 값을 줄여서 모델을 더 복잡하게 만든다.

## 3.2 선형 회귀

### 선형 회귀

**선형 회귀(linear regression)**는 특성이 하나인 경우 어떤 직선을 학습하는 알고리즘이다.

y = a x + b

여기서 x는 특성, y는 타깃이다. a와 b는 선형 회귀 모델이 찾은 값이다.

```python
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(train_input, train_target)

# 기울기와 절편
print(lr.coef_, lr.intercept_)
```

### 다항 회귀

**다항 회귀(polynomial regression)**는 다항식을 사용하여 특성과 타깃 사이의 관계를 나타낸다.

y = a x² + b x + c

```python
# 특성 공학: 2차항 추가
train_poly = np.column_stack((train_input ** 2, train_input))
test_poly = np.column_stack((test_input ** 2, test_input))

lr = LinearRegression()
lr.fit(train_poly, train_target)
```

## 3.3 특성 공학과 규제

### 다중 회귀

**다중 회귀(multiple regression)**는 여러 개의 특성을 사용한 선형 회귀를 말한다.

y = a₁x₁ + a₂x₂ + ... + aₙxₙ + b

```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2, include_bias=False)
poly.fit(train_input)

train_poly = poly.transform(train_input)
test_poly = poly.transform(test_input)
```

PolynomialFeatures 클래스는 각 특성을 제곱한 항과 특성끼리 서로 곱한 항을 추가한다.

### 규제

**규제(regularization)**는 모델이 과대적합되지 않도록 하는 방법이다.

선형 회귀 모델의 경우 특성에 곱해지는 계수(또는 기울기)의 크기를 작게 만드는 일이다.

### 릿지 회귀

**릿지 회귀(ridge regression)**는 계수를 제곱한 값을 기준으로 규제를 적용한다.

```python
from sklearn.linear_model import Ridge

ridge = Ridge()
ridge.fit(train_scaled, train_target)

print(ridge.score(train_scaled, train_target))
print(ridge.score(test_scaled, test_target))
```

alpha 매개변수로 규제의 강도를 조절한다. alpha 값이 크면 규제 강도가 세지므로 계수 값을 더 줄이고 조금 더 과소적합되도록 유도한다.

### 라쏘 회귀

**라쏘 회귀(lasso regression)**는 계수의 절댓값을 기준으로 규제를 적용한다.

```python
from sklearn.linear_model import Lasso

lasso = Lasso()
lasso.fit(train_scaled, train_target)

print(lasso.score(train_scaled, train_target))
print(lasso.score(test_scaled, test_target))
```

라쏘 회귀는 계수 값을 아예 0으로 만들 수 있다. 즉, 일부 특성을 모델에서 완전히 제거할 수 있다.

### 하이퍼파라미터

**하이퍼파라미터(hyperparameter)**는 모델이 학습할 수 없어서 사용자가 지정해야 하는 파라미터다.

사이킷런과 같은 머신러닝 라이브러리에서 하이퍼파라미터는 클래스와 메서드의 매개변수로 표현된다.

## 핵심 키워드

- **선형 회귀**: 특성과 타깃 사이의 관계를 선형 방정식으로 나타낸다
- **계수(coefficient)** 또는 **가중치(weight)**: 선형 방정식의 기울기
- **다항 회귀**: 다항식을 사용하여 특성과 타깃 사이의 관계를 나타낸다
- **특성 공학(feature engineering)**: 기존의 특성을 사용해 새로운 특성을 만드는 작업
- **규제(regularization)**: 모델이 훈련 세트를 과도하게 학습하지 못하도록 방해하는 것
- **릿지(ridge)**: 계수를 제곱한 값을 기준으로 규제를 적용
- **라쏘(lasso)**: 계수의 절댓값을 기준으로 규제를 적용
- **하이퍼파라미터(hyperparameter)**: 모델이 학습할 수 없어서 사용자가 지정해야 하는 파라미터
