# 7. 딥러닝을 시작합니다

## 7.1 인공 신경망

### 인공 신경망

**인공 신경망(artificial neural network)**은 생물학적 뉴런에서 영감을 받아 만든 머신러닝 알고리즘이다.

**딥러닝(deep learning)**은 여러 개의 층을 가진 인공 신경망을 사용하는 머신러닝이다.

### 텐서플로와 케라스

**텐서플로(TensorFlow)**는 구글이 만든 딥러닝 라이브러리다.

**케라스(Keras)**는 텐서플로의 고수준 API로, 신경망을 쉽게 만들고 훈련할 수 있게 도와준다.

```python
from tensorflow import keras

# 밀집층(완전 연결층)
dense = keras.layers.Dense(10, activation='sigmoid', input_shape=(784,))
```

### 인공 신경망 만들기

```python
from tensorflow import keras

# Sequential 모델
model = keras.Sequential()
model.add(keras.layers.Flatten(input_shape=(28, 28)))
model.add(keras.layers.Dense(100, activation='relu'))
model.add(keras.layers.Dense(10, activation='softmax'))
```

**밀집층(dense layer)** 또는 **완전 연결층(fully connected layer)**은 가장 기본적인 층이다.

### 컴파일과 훈련

```python
# 모델 설정
model.compile(loss='sparse_categorical_crossentropy',
              metrics='accuracy')

# 모델 훈련
model.fit(train_scaled, train_target, epochs=5)
```

**손실 함수(loss function)**는 모델이 얼마나 잘못 예측했는지를 측정하는 함수다.

**옵티마이저(optimizer)**는 손실 함수를 기반으로 모델을 업데이트하는 방법을 결정한다.

## 7.2 심층 신경망

### 층 추가하기

2개의 층을 추가한 모델을 **심층 신경망(deep neural network, DNN)**이라고 부른다.

```python
model = keras.Sequential()
model.add(keras.layers.Flatten(input_shape=(28, 28)))
model.add(keras.layers.Dense(100, activation='relu'))
model.add(keras.layers.Dense(100, activation='relu'))
model.add(keras.layers.Dense(10, activation='softmax'))
```

### 활성화 함수

**활성화 함수(activation function)**는 신경망 층의 선형 방정식 계산 값에 적용하는 함수다.

대표적인 활성화 함수:

- **시그모이드(sigmoid)**: 이진 분류에 사용
- **소프트맥스(softmax)**: 다중 분류에 사용
- **ReLU(Rectified Linear Unit)**: 은닉층에 주로 사용. max(0, z)

```python
model.add(keras.layers.Dense(100, activation='relu'))
```

### 옵티마이저

**옵티마이저(optimizer)**는 신경망의 가중치와 절편을 학습하기 위한 알고리즘 또는 방법이다.

대표적인 옵티마이저:

- **SGD**: 확률적 경사 하강법
- **모멘텀**: 이전의 그레이디언트를 가속도처럼 사용
- **네스테로프 모멘텀(Nesterov momentum)**: 모멘텀의 개선된 버전
- **Adagrad**: 그레이디언트 제곱을 누적한 값으로 나누어 학습률을 조정
- **RMSprop**: Adagrad의 단점을 개선
- **Adam**: RMSprop와 모멘텀을 합친 방법

```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
              metrics='accuracy')
```

## 7.3 신경망 모델 훈련

### 손실 곡선

**손실 곡선(loss curve)**은 에포크에 따른 손실 함수의 변화를 나타낸 그래프다.

```python
history = model.fit(train_scaled, train_target, epochs=20, verbose=0,
                    validation_data=(val_scaled, val_target))

# 손실 곡선 그리기
import matplotlib.pyplot as plt

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

### 검증 손실

**검증 손실(validation loss)**은 검증 세트에 대한 손실이다.

검증 손실이 다시 상승하기 시작하면 과대적합이 시작되는 신호다.

### 조기 종료

**조기 종료(early stopping)**는 과대적합이 시작하기 전에 훈련을 멈추는 기법이다.

```python
from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=5,
                               restore_best_weights=True)

history = model.fit(train_scaled, train_target, epochs=100,
                    validation_data=(val_scaled, val_target),
                    callbacks=[early_stopping])
```

## 핵심 키워드

- **인공 신경망**: 생물학적 뉴런에서 영감을 받아 만든 머신러닝 알고리즘
- **딥러닝**: 여러 개의 층을 가진 인공 신경망을 사용하는 머신러닝
- **밀집층**: 가장 기본적인 신경망 층
- **활성화 함수**: 신경망 층에서 계산한 값에 적용하는 함수
- **옵티마이저**: 신경망의 가중치와 절편을 학습하기 위한 알고리즘
- **조기 종료**: 과대적합이 시작하기 전에 훈련을 멈추는 기법
