# 6. 비지도 학습

## 6.1 군집 알고리즘

### 비지도 학습

**비지도 학습(unsupervised learning)**은 타깃이 없을 때 사용하는 머신러닝 알고리즘이다.

사람이 가르쳐 주지 않아도 데이터에 있는 무언가를 학습하는 문제다.

### 군집

**군집(clustering)**은 비슷한 샘플끼리 하나의 그룹으로 모으는 대표적인 비지도 학습 작업이다.

군집 알고리즘으로 모은 샘플 그룹을 **클러스터(cluster)**라고 부른다.

### k-평균

**k-평균(k-means)**은 가장 유명한 군집 알고리즘이다.

평균값이 클러스터의 중심에 위치한다는 의미에서 클러스터 중심을 **센트로이드(centroid)** 또는 **클러스터 중심(cluster center)**이라고 부른다.

```python
from sklearn.cluster import KMeans

km = KMeans(n_clusters=3, random_state=42)
km.fit(train_input)

# 클러스터 중심
print(km.cluster_centers_)

# 각 샘플이 어느 클러스터에 속하는지
print(km.labels_)
```

k-평균 알고리즘의 작동 방식:

1. 무작위로 k개의 클러스터 중심을 정한다
2. 각 샘플에서 가장 가까운 클러스터 중심을 찾아 해당 클러스터의 샘플로 지정한다
3. 클러스터에 속한 샘플의 평균값으로 클러스터 중심을 변경한다
4. 클러스터 중심에 변화가 없을 때까지 2번으로 돌아가 반복한다

### 엘보우 방법

**엘보우 방법(elbow method)**은 최적의 클러스터 개수를 정하는 방법이다.

**이너셔(inertia)**는 클러스터 중심과 클러스터에 속한 샘플 사이의 거리의 제곱 합이다.

```python
inertia = []
for k in range(2, 7):
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(train_input)
    inertia.append(km.inertia_)

# 그래프를 그려서 꺾이는 지점을 찾는다
```

## 6.2 주성분 분석

### 차원 축소

**차원(dimension)**은 데이터가 가진 속성을 말한다.

**차원 축소(dimensionality reduction)**는 데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터 크기를 줄이고 지도 학습 모델의 성능을 향상시킬 수 있는 비지도 학습 작업 중 하나다.

차원 축소는 줄어든 차원에서 원본 차원으로 손실을 최대한 줄이면서 복원할 수도 있다.

### 주성분 분석

**주성분 분석(PCA, Principal Component Analysis)**은 데이터에 있는 분산이 큰 방향을 찾는 것이다.

분산이 큰 방향이 데이터를 잘 표현하는 벡터다. 이 벡터를 **주성분(principal component)**이라고 한다.

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=50)
pca.fit(train_input)

# 주성분으로 변환
train_pca = pca.transform(train_input)
test_pca = pca.transform(test_input)
```

주성분은 원본 데이터에 있는 어떤 방향이다. **주성분 벡터**의 원소 개수는 원본 데이터셋의 특성 개수와 같다.

### 설명된 분산

**설명된 분산(explained variance)**은 주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지 기록한 값이다.

```python
print(np.sum(pca.explained_variance_ratio_))
```

## 6.3 차원 축소와 시각화 (선택 사항)

### t-SNE

**t-SNE(t-Distributed Stochastic Neighbor Embedding)**는 고차원 데이터를 2차원이나 3차원으로 축소하여 시각화하는 데 특화된 알고리즘이다.

주성분 분석은 선형적인 변환만 가능하지만, t-SNE는 비선형적인 변환이 가능하다.

```python
from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(data)
```

### LDA

**선형 판별 분석(LDA, Linear Discriminant Analysis)**은 지도 학습의 차원 축소 알고리즘이다.

클래스를 최대한 잘 구분하는 방향으로 데이터를 투영한다.

## 핵심 키워드

- **비지도 학습**: 타깃 데이터가 없을 때 사용하는 머신러닝 알고리즘
- **군집**: 비슷한 샘플끼리 하나의 그룹으로 모으는 작업
- **k-평균**: 평균값을 클러스터 중심으로 사용하는 군집 알고리즘
- **엘보우 방법**: 최적의 클러스터 개수를 정하는 방법
- **주성분 분석**: 데이터에서 가장 분산이 큰 방향을 찾아 차원을 축소하는 비지도 학습 알고리즘
- **설명된 분산**: 주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지를 기록한 값
