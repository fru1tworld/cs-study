# 9. 텍스트를 위한 인공 신경망

## 9.1 순환 신경망

### 순차 데이터

**순차 데이터(sequential data)**는 순서에 의미가 있는 데이터다.

텍스트, 시계열 데이터, 비디오 등이 순차 데이터에 해당한다.

### 순환 신경망

**순환 신경망(recurrent neural network, RNN)**은 순차 데이터를 다루는 데 특화된 인공 신경망이다.

순환 신경망의 층을 **순환층(recurrent layer)**이라고 부른다.

```python
from tensorflow import keras

model = keras.Sequential([
    keras.layers.SimpleRNN(8, input_shape=(None, 100)),
    keras.layers.Dense(1, activation='sigmoid')
])
```

### 셀

순환층의 한 단계를 **셀(cell)**이라고 부른다.

셀에는 두 가지 입력이 들어간다:

- 현재 단계의 입력
- 이전 단계의 은닉 상태

### 은닉 상태

**은닉 상태(hidden state)**는 순환층이 학습한 정보를 기억하고 다음 단계로 전달하는 역할을 한다.

## 9.2 순환 신경망으로 IMDB 리뷰 분류하기

### 원-핫 인코딩

**원-핫 인코딩(one-hot encoding)**은 어휘 사전의 크기만큼 배열을 만들고 각 단어에 고유한 인덱스를 부여하는 방법이다.

하지만 원-핫 인코딩의 단점은 배열의 크기가 매우 크다는 것이다.

### 단어 임베딩

**단어 임베딩(word embedding)**은 각 단어를 고정된 크기의 실수 벡터로 바꾸어 표현하는 방법이다.

```python
model = keras.Sequential([
    keras.layers.Embedding(500, 16, input_length=100),
    keras.layers.SimpleRNN(8),
    keras.layers.Dense(1, activation='sigmoid')
])
```

### LSTM

**LSTM(Long Short-Term Memory)**은 단기 기억을 오래 기억하기 위해 고안된 순환 신경망이다.

LSTM은 셀 상태를 사용하여 멀리 떨어져 있는 단어 정보를 쉽게 전달할 수 있다.

```python
model = keras.Sequential([
    keras.layers.Embedding(500, 16, input_length=100),
    keras.layers.LSTM(8),
    keras.layers.Dense(1, activation='sigmoid')
])
```

### GRU

**GRU(Gated Recurrent Unit)**는 LSTM의 간소화 버전으로, LSTM과 비슷한 성능을 내면서 가중치가 적어 계산량이 적다.

```python
model = keras.Sequential([
    keras.layers.Embedding(500, 16, input_length=100),
    keras.layers.GRU(8),
    keras.layers.Dense(1, activation='sigmoid')
])
```

## 9.3 LSTM과 GRU 셀을 순환층에서 사용하기

### 양방향 순환층

**양방향 순환층(bidirectional recurrent layer)**은 입력 시퀀스를 정방향과 역방향으로 모두 처리하는 층이다.

```python
model = keras.Sequential([
    keras.layers.Embedding(500, 16, input_length=100),
    keras.layers.Bidirectional(keras.layers.LSTM(8)),
    keras.layers.Dense(1, activation='sigmoid')
])
```

### 순환층 쌓기

여러 개의 순환층을 쌓으려면 return_sequences 매개변수를 True로 설정해야 한다.

```python
model = keras.Sequential([
    keras.layers.Embedding(500, 16, input_length=100),
    keras.layers.LSTM(8, return_sequences=True),
    keras.layers.LSTM(8),
    keras.layers.Dense(1, activation='sigmoid')
])
```

## 핵심 키워드

- **순차 데이터**: 순서에 의미가 있는 데이터
- **순환 신경망**: 순차 데이터를 다루는 데 특화된 인공 신경망
- **셀**: 순환층의 한 단계
- **은닉 상태**: 순환층이 학습한 정보를 기억하고 다음 단계로 전달하는 역할
- **원-핫 인코딩**: 각 단어를 고유한 인덱스로 표현하는 방법
- **단어 임베딩**: 각 단어를 고정된 크기의 실수 벡터로 표현하는 방법
- **LSTM**: 장기 기억을 위해 고안된 순환 신경망
- **GRU**: LSTM의 간소화 버전
