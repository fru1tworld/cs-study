# 3.1 카프카 프로젝트 설계

## 3.1.3 내장 기능

카프카 커넥트의 용도는 자체 프로듀서와 컨슈머를 작성하지 않고 카프카 안팎으로 데이터의 이동을 돕는 것이다.

이러한 부품을 커넥터라고 하며, 다른 데이터 소스와 안정적으로 작동하도록 개발됐다.

## 3.2.2 카프카가 적합한 이유

## 3.2.3 우리 설계에 대한 생각의 시작점

메시지 유실 가능성, 그룹화 가능, 순서 보장, 최종값만 필요, 독립된 컨슈머 지원

- **시스템에서 메시지를 잃어도 괜찮은가?**:
- **어떤 방식으로든 데이터를 그룹화해야 하는가?**: 해당 이벤트가 들어오는 다른 이벤트와 상관관계가 있는가? 예를 들어, 계정 변경 사항을 고려할 것인가? 이 경우 다양한 계정 변경사항을 계정이 변경되는 고객과 연결하려고 한다. 이벤트를 미리 그룹화하면 애플리케이션이 토픽을 읽는 동안 여러 컨슈머의 메시지를 코디네티으할 필요가 없을 수 있다.

- **특정 순서로 데이터를 전달해야 하는가?**: 메시지가 발생한 시간이 아닌 다른 순서로 배달되면 어떻게 되는가 ?
- **특정 항목의 마지막 값만 필요한가? 아니면 해당 항목의 이력이 중요한가?**: 데이터가 어떻게 변경되어 왔는지 관심이 있는가 ? 이에 관한 하나의 방식은 기존 관계형 데이터베이스 테이블에서 데이터가 업데이트되는 방식을 살펴보면 되는데, 관계형 데이터베이스에서는 인플레이스 업데이트되며 그 값이 하루 전에 어떻게 생겼는지에 대한 기록은 손실된다.
- **얼마나 많은 컨슈머를 가질 것인가?**: 그것은 모두 서로 독립적인가? 아니면 메시지를 읽을 때 순서를 유지해야 하는가 ? 가능한 한 빨리 소비하려는

## 요약

- 카프카 솔루션을 설계하려면 먼저 데이터를 이해해야 한다. 이러한 세부 정보에는 데이터 손실, 메시지 순서, 사용 사례의 그룹화를 처리하는 방법이 포함된다.
- 데이터 그룹화 필요성에 따라 카프카에서 메시지를 키로 지정할지 여부가 결정된다.
- 스키마 정의를 활용하면 코드를 생성하는데 도움이 될 뿐만 아니라 향후 데이터 변경을 처리하는 데도 도움이 된다. 또한 이러한 스키마를 자체 커스텀 카프카 클라이언트와 함께 사용할 수 있다.
- 카프카 커넥트는 다양한 데이터 소스로부터 읽고 쓰기 위한 사전 제작된 커넥터를 제공한다.
