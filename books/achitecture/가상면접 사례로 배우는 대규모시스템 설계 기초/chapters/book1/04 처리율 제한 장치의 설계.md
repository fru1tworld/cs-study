# 4장 처리율 제한 장치의 설계

rate limiter는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다.

HTTP를 예로 들면 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다.

API 요청 횟수가 제한 장치에 정의된 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다.

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

## 1단계 문제 이해 및 설계 범위 확정

여러 가지 알고리즘을 사용할 수 있는데 각각 고유한 장단점을 갖고 있다.

지원자: 서버 / 클라이언트측 ?
지원자: IP 기준, ID 기준 ?
지원자: 시스템 규모 ?
지원자: 분산된 환경에서 작동하는지 ?
지원자: 독립된 서비스인지 애플리케이션 코드에 포함될 수 있는 건지
지원자: 걸러진 경우 알림을 보내야 하는지 ?

### 요구사항

설정된 처리율을 초과하는 요청은 정확하게 제한한다.
이 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주어서는 안된다.
가능한 적은 메모리를 써야한다.
분산형 처리율 제한: 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야한다.
예외 처리 : 그 사실을 사용자에게 분명하게 보여주어야 한다.
높은 결함 내성: 제한 장치에 장애가 생기더라도 시스템에 영향을 주어서는 안된다.

## 2단계 개략적 설계안 제시 및 동의 구하기

클라이언트 측에 둔다면: 일반적으로 클라이언트는 처리율 제한 장치를 안정적으로 걸 수 있는 장소가 못 된다.

서버 측에 두기

다른 방법은 미들웨어를 두는 방법도 있음

클라우드 마이크로 서비스의 경우 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구현된다.

처리율 제한, SSL 종단, IP 허용 목록 관리등을 지원하는 완전 위탁 관리형 서비스 즉
클라우드 업체가 유지 보수를 담당하는 서비스이다.
하지만 API 게이트 웨이가 처리율 제한을 지원하는 미들웨어라는 점만 기억하다.

### 처리율 제한 장치 알고리즘

#### 토큰 버킷

- 지정된 용량을 갖고 있는 컨테이너
- 각 요청은 처리될 때마다 하나의 토큰을 사용한다.
- 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사하게 된다.
- 충분한 토큰이 없으면 버려진다.
- 예를 들어 토큰 버킷의 크기는 4이고 공급률은 분당 4이다.

통상적으로 API 엔드포인트마다 별도의 버킷을 둔다.
예를 들어 사용자마다 하루에 한 번만 포스팅할 수 있고, 친구는 150명까지 추가할 수 있고 좋아요 버튼은 다섯번까지만 누를 수 있다면 사용자마다 3개의 버킷을 두어야 할 것이다.
IP 주소별로 처리율 제한 장치를 적용해야 한다면 IP주소마다 버킷을 하나씩 할당해야 한다.
시스템의 처리율은 초당 10,000개의 요청으로 제한하고 싶다면, 모든 요청이 하나의 버킷을 공유하도록 해야 할 것이다.

#### 누출 버킷

토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 점이 다르다.
누출 버킷 알고리즘은 보통 FIFO 큐로 구현한다.

- 요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우에는 큐에 요청을 추가한다.
- 큐가 가득 차 있는 경우에는 새 요청은 버린다.
- 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

장점

- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적이다.
- 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우에 적합하다.

단점

- 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고, 그 요청들을 제때 처리 못하면 최신 요청들은 버려지게 된다.
- 두 개 인자를 갖고 있는데, 이들을 오라르게 튜닝하기가 까다로울 수 있다.

#### 고정 윈도 카운터

- 타임라인을 고정된 간격의 윈도우로 나누고, 각 윈도우마다 카운터를 붙인다.
- 요청이 접수될 때마다 1 증가하고 threshold에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.

장점

- 메모리 효율이 좋다
- 이해하기 쉽다
- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.

단점

- 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.

#### 이동 윈도 로그

- 이 알고리즘은 요청의 타임스탬프를 추적하고 보통 Redis의 sorted set같은 캐시에 보관한다.
- 새 요청이 오면 만료된 타임스탬프는 제거한다. 만료된 타임스탬프는 그 값이 현재 윈도의 시작 시점보다 오래된 타임스탬프를 말한다.
- 새 요청의 타임스탬프를 로그에 추가한다.
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않으면 거부한다.

장점

- 아주 정교하다 어느 순간의 윈도를 보더라도 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
  단점
- 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문이다.

#### 이동 윈도 카운터

고정 윈도 알고리즘 + 이동 윈도 로깅 알고리즘의 결합 2가지 접근 방법이 있을 수 있음

장점

- 짧은 시간에 몰리는 트래픽에 잘 대응한다. 메모리 효율이 좋다
  단점
- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다. 이 문제는 근데 생각보다 심각하지 않음

## 3단계 상세 설계

분산 환경에서 처리율 제한 장치는 두 가지 문제를 해결해야 한다.

- 경쟁 조건
- 동기화

#### 경쟁 조건

경쟁 조건 문제를 해결하는 가장 널리 알려진 것은 Lock인데 Lock은 시스템의 성능을 떨어트린다. 그래서 루아 스크립트 혹은 정렬 집합이라고 불리는 기능을 활용해야 한다.

#### 동기화 이슈

처리율 제한 장치도 분산될 수 있는데, 웹은 state-less 하므로 처리율 제한을 올바르게 수행하지 못할 수 있다.

따라서 고정 세션을 활용하여 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하는 것이다.

그런데 이건 확장하기 어렵고 유연하지가 않다. 그래서 레디스같은 중앙 집중형 데이터 저장소를 쓰는 것이 좋다

동기화는 eventual consistency model을 사용하는 것이다.

이 일관성 모델은 6장 데이터 일관성 항목을 참조하자

## 4단계 마무리

- 경성 또는 연성 처리율 제한
- 다양한 계층에서 처리율 제한
- 처리율 제한을 회피하는 방법
