# 5 복제

**복제**란 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지한다는 의미다.

2부의 소개에서 설명한 것처럼 데이터 복제가 필요한 여러 이유가 있다.

- **지리적으로 사용자와 가깝게 데이터를 유지해 지연 시간을 줄인다.**:
- **시스템의 일부에 장애가 발생해도 지속적으로 동작할 수 있게 가용성을 높인다.**:
- **읽기 질의를 제공하는 장비의 수를 확장해 읽기 처리량을 늘린다.**:

복제 중인 데이터가 시간이 지나도 변경되지 않는다면 복제는 쉽다.

복제에서 모든 어려움은 복제된 데이터의 **변경** 처리에 있다. 이것이 이번 장의 내용이다.

노드 간 변경을 복제하기 위한 세 가지 인기 있는 알고리즘ㅇ니 단일 리더, 다중 리더, 리더 없는 복제를 살펴본다.

## 5.1 리더와 팔로워

복제 서버 중 하나를 리더로 선출하고, 클라이언트가 쓰기를 하면 클라이언트는 요청을 리더에 보내야 한다.

리더는 먼저 로컬 저장소에 데이터를 기록한다.

다른 복제 서버는 팔로워, 슬레이브, 2차 등의 이름으로 불리는데, 리더가 로컬 저장소에 새로운 데이터를 기록할 때마다 데이터 변경은 복제 로그나 변경 스트림의 일부로 팔로워에게 전송한다.

클라이언트가 데이터베이스로부터 읽기를 할 때는 리더 또는 임의 팔로워에게 질의할 수 있다.

하지만 쓰기는 리더에게만 허용된다. (즉 팔로워는 클라이언트 입장에서 읽기 전용이다.)

### 5.1.1 동기식 대 비동기식 복제

- 동기 복제 팔로워의 ok를 수신 받는다.
- 비동기 복제 팔로워의 ok를 수신 받지 않는다.

그래서 팔로워에게 변경 내용을 적용하지만 얼마나 오래 걸릴지를 보장할 수 없다.

동기식은 일관성 있게 최신 데이터 복사본을 가지는 것을 보장한다.

단점은 동기 팔로워가 응답하지 않으면 처리가 불가하다. 그래서 리더는 모든 쓰기가 block되고 동기 복제 서버가 다시 사용할 수 있을 때까지 기다려야한다.

이런 이유로 모든 팔로워가 동기식인 상황은 비현실적이다.

보통 팔로워 하나는 동기식이고 그 외는 비동기로 한다. 동기식 팔로워가 사용할 수 없거나 느려지면 비동기 팔로워 중 하나가 동기식으로 변경된다.

이러한 설정을 반동기식이라고 한다.

보통 리더 기반 복제는 완전한 비동기로 구성되는데, 이런 경우 리더가 잘못되고 복구할 수 없으면 팔로워에 아직 복제되지 않은 모든 쓰기는 유실된다.

이것은 쓰기가 클라이언트에게 확인된 경우에 지속성을 보장할 수 없다는 의미다.

하지만 쓰기 처리를 계속 할 수 있다는 장점이 있다.

비동기 복제는 나쁜 트레이드 오프같지만 그럼에도 많은 팔로워가 있거나 지리적으로 분산됐다면 비동기 복제를 널리 사용한다.

### 5.1.2 새로운 팔로워 설정

때때로 복제 서버 수를 늘리거나 장애 노드의 대체를 위해 새로운 팔로워를 설정해야 한다.

새로운 팔로워가 리더의 데이터 복제본을 정확히 가지고 있는지 어떻게 보장할까 ?

- 1. 가능하다면 전체 데이터베이스를 잠그지 않고 리더의 데이터베이스 스냅숏을 일정 시점에 가져온다. 대부분의 데이터베이스는 백업이 필요하기 때문에 이 기능을 갖췄다.
- 2. 스냅숏을 새로운 팔로워 노드에 복사한다.
- 3. 팔로워는 리더에 연결해 스냅숏 이후 발생한 모든 데이터 변경을 요청한다. 이것은 스냅숏이 리더의 복제 로그의 정확한 위치와 연관돼야 한다. 이 위치의 명칭은 다양하다. 예를 들어 MySQL은 binlog conrdinate 라고 부른다.
- 4.  팔로워가 스냅숏 이후 데이터 변경의 미처리분을 모두 처리했을 때 따라잡았다고 한다. 이제부터 리더에 발생하는 데이터 변화를 이어 처리할 수 있다.

### 5.1.3 노드 중단 처리

시스템의 모든 노드는 장애로 인해 예기치 않게 중단될 수 있지만 계획된 유지보수에 의해 중단될 수 있다.

중단 시간 없이 개별 노드를 재부팅할 수 있다는 점은 운영과 유지보수에 큰 장점이다.

따라서 개별 노드의 장애에도 전체 시스템이 동작하게끔 유지하고 노드 중단의 영향을 최소화하는 것이 목표다.

리더 기반 복제에서 고가용성은 어떻게 달성될 수 있을까 ?

### 5.1.4 복제 로그 구현

#### 팔로워 장애: 따라잡기 복구

각 팔로워는 리더로부터 수신한 데이터 변경 로그를 로컬 디스크에 보관한다. 팔로워가 죽어 재시작하거나 리더와 팔로워 사이의 네트워크가 일시적으로 중단된다면 팔로워는 매우 쉽게 복구할 수 있다.

장애 발생 전에 처리한 마지막 트랜잭션을 알아내고 팔로워는 따라잡을 수 있다.

#### 리더 장애: 장애 복구

리더의 장애를 처리하는 일은 까다롭다.

팔로워 중 하나를 새로운 리더로 승격해야 하고 클라이언트는 새로운 리더로 쓰기를 전송하기 위해 재설정이 필요하며 다른 팔로워는 새로운 리더로부터 데이터 변경을 소비하기 시작해야 한다.

이 과정을 장애 복구라 한다.

장애 복구는 수동으로 진행하거나 자동으로 진행한다.

자동 장애 복구는 다음과 같은 과정을 따른다.

- **1. 리더가 장애인지 판단한다.**: 고장, 정전, 네트워크 문제 등 알 수 없어서 보통 타임 아웃을 사용한다.
- **2. 새로운 리더를 선택한다.**: 선출 과정을 통해 이뤄지거나 이전에 선출된 제어 노드에 의해 새로운 리더가 임명될 수 있다. 새로운 리더로 가장 적합한 후보는 보통 이전 리더의 최신 데이터 변경사항을 가진 복제 서버다. 모든 노드가 새 리더 추대에 동의를 구하는 합의 문제는 9장에 설명한다.
- **3. 새로운 리더 사용을 위해 시스템을 재설정한다.**: 클라이언트는 이제 새로운 쓰기 요청을 새로운 리더에게 보내야한다. 이전 리더가 돌아오면 여전히 자신이 리더라고 믿을 수 있으며, 다른 복제 서버들이 자신을 리더에서 물러나게 한 것을 알지 못한다. 그래서 시스템은 이를 인지시키는 과정이 필요하다.

장애 복구 과정은 잘못될 수 있는 것 투성이다.

- 비동기식 복제를 사용한다면 새로운 리더는 이전 리더가 실패하기 전에 이전 리더의 쓰기를 일부 수신하지 못할 수 있다. 그래서 일반적인 해결은 이전 리더의 복제되지 않은 쓰기를 단순히 폐끼하는 방법이다. 이 방법은 내구성에 대한 클라이언트의 기대를 저버리게 된다.
- 쓰기를 폐기하는 방법은 데이터베이스 외부의 다른 저장소 시스템이 데이터베이스 내용에 맞춰 조정돼야 한다면 특히 위험하다. 깃헙에서 발생한 사고 중 하나로 유효하지 않은(out-of-date) MySQL 팔로워가 리더로 승격된 사례가 있다. 데이터베이스는 새로운 로우의 기본키를 할당하기 위해 자동 증가 카운터를 사용했지만 이전 리더가 할당한 기본키를 재사용했었다. 이 기본키는 레디스 저장에도 사용했기 때문에 기본키의 재사용은 MySQL과 Redis의 불일치를 일으켰다. 결국 일부 개인 데이터가 잘못된 사용자에게 공개됐다.
- 특정 결함 시나리오에서 두 노드가 모두 자신이 리더라고 믿을 수 있다. 이런 상황을 스플릿 브레인이라고 한다. 이는 매우 위험한 상황이다. 이를 해소하지 않으면 데이터가 유실되거나 오염된다. 일부 시스템은 두 리더가 감지되면 한 노드를 종료하는 메커니즘이 있다.
- 리더가 분명히 죽었다고 판단 가능한 적절한 타임아웃이 얼마일까 ?너무 길면 복구가 오래 걸리고 너무 짧으면 불필요한 장애 복구가 발생할 수 있다.

이 문제에 대한 쉬운 해결은 없다.

이런 이유로 일부 운영팀은 소프트웨어가 자동 장애 복구를 지원하더라도 수동으로 장애 복구를 수행하는 방식을 선호한다.

## 5.2 복제 지연 문제

- 리더 기반 복제는 내부적으로 어떻게 작동할까 ?

실제로는 다양한 복제 방법을 사용한다.

#### 구문 기반 복제

statement를 기록하고 쓰기를 실행한다음 statement를 팔로워에게 전송한다.

- 비결정적 함수를 호출하는 모든 구문은 각 복제 서버마다 다른 값을 생성할 가능성이 있다.
- 자동증가 컬럼을 사용하는 구문이나 데이터베이스에 있는 데이터에 의존한다면 구문은 각 복제 서버에 정확히 같은 순서로 실행돼야 한다. 이 방식은 동시에 여러 트랜잭션이 수행되는 것을 발해한다.
- 부수 효과를 가진 구문은 부수 효과가 완벽하게 결정적이지 않으면 복제 서버에 다른 부수 효과가 발생할 수 있다.

이를 해결하기위해 모든 비결정적 함수를 고정 값을 반환하게 바꿀 수 있지만 여러가지 에지 케이스가 있기 때문에 일반적으로 다른 복제를 선호한다.

#### 쓰기 전 로그 배송

팔로워가 이 로그를 처리하면 리더에 있는 것과 정확히 동일한 데이터 구조의 복제본이 만들어진다.

이 복제 방식은 포스트그레스큐엘과 오라클 등에서 사용된다.

가장 큰 단점은 로그가 제일 저수준의 데이터를 기술한다는 것이다.

WAL은 어떤 디스크 블록에서 어떤 바이트를 변경했는지를 기록한다.

근데 이렇게하면 복제가 저장소 엔진과 밀접해진다.

#### 논리적 로그 복제

복제 로그를 저장소 엔진 내부와 분리하기 위한 대안 하나는 복제와 저장소 엔진을 위해 다른 로그 형식을 사용한다. 그래서 이를 논리적 로그라 부른다.

논리적 로그를 저장소 엔진 내부와 분리했기 때문에 하위 호환성을 더 쉽게 유지할 수 있고 리더와 팔로워에서 다른 버전의 데이터베이스 소프트웨어나 심지어 다른 저장소 엔진을 실행할 수 있다.

논리적 로그 복제는 CDC라고 부르는 기술에 유용하다. (외부 애플리케이션에 전송할 때)

#### 트리거 기반 복제

트리거나 스토어드 프로시저를 사용한다. 그런데 이 방식은 내장된 복제보다 버그나 제한 사항이 더 많지만 유연성때문에 유용하다.

### 복제 지연 문제

리더 기반 복제는 모든 쓰기가 단일 노드를 거쳐야 하지만 읽기 전용 질의는 어떤 복제 서버에서도 가능하다.

그래서 CQRS 등에 사용될 수 있다.
그래서 이런 읽기 확장 아키텍처에서는 간단히 팔로워를 더 추가함으로써 읽기 전용 요청을 처리하기 위한 용량을 늘릴 수 있다.

하지만 이 접근 방식은 실제로 비동기식 복제에서만 동작한다.

동기식으로 모든 팔로워에게 복제를 시도한다면 단일 노드 장애나 네트워크 중단으로 전체 시스템의 쓰기가 불가능해진다.

비동기 팔로워에서 데이터를 읽을 때 뒤처진다면 지난 정보를 볼 수 있다. 이 상황은 명백히 불일치가 발생한다.

이와 동시에 리더와 팔로워에 동일한 질의를 수행하면 모든 쓰기가 팔로워에 반영되지 않았기 때문에 서로 다른 결과를 얻을 수도 있다.

결국 따라잡기 때문이고 이를 최종적 일관성이라고 한다.

최종적이란 용어는 모호하다 얼마나 뒤처졌는지 대한 제한이 없다.

아주 짧거나 가용량 근처에서 동작하거나 네트워크의 문제가 있으면 수 초에서 수 분으로 증가할 수 있다.

### 5.2.1 자신이 쓴 내용 읽기

많은 애플리케이션은 사용자가 임의 데이터를 제출하고 해당 사용자에게 제출한 데이터를 볼 수 있게 한다.

비동기식 복제에서는 다음과 같은 문제가 있을 수 있다.

쓰기 직후 데이터를 본다면 새로운 데이터는 복제 서버에 반영되지 않았을 수 있다.

이것은 사용자에게 제출된 데이터가 유실된 것처럼 보이기 때문에 당연히 불만족스러울 동작이다.

이런 상황에서는 "쓰기 후 읽기 일관성"이 필요하다.

이것은 사용자가 페이지를 재로딩했을 때 항상 자신이 제출한 모든 갱신을 볼 수 있음을 보장하며 다른 사용자에게 대해서는 보장하지 않는다.

어떻게 리더 기반 복제 시스템에서 쓰기 후 읽기 일관성을 구현할까?

1. 사용자가 수정한 내용을 읽을 때는 리더에서 읽는다.

이를 위해서는 실제로 질의하지 않고 무엇이 수정됐는지 알 수 있는 방법이 필요하다.

예를 들어 사용자 정보는 프로필 소유자만 편집할 수 있다.

따라서 항상 소유자 피로필은 리더에서 읽고 다른 사용자의 프로필은 팔로워에서 읽는 간단한 규칙을 사용한다. 2. 애플리케이션 내 대부분 사용자가 편집할 가능성이 있다면 대부분 리더에서 읽기 때문에 효율적이지 않다.

이런 경우에는 리더에서 읽을지 말지 결정하기 위해 다른 기준을 사용해야 한다.

예를 들어 마지막 갱신 시간을 찾아서 마지막 갱신 후 1분 동안 리더에서 모든 읽기를 수행한다.

또한 팔로워에서 복제 지연을 모니터링해 1분 이상 늦은 모든 팔로워에 대한 질의를 금할 수 있다.

3. 클라이언트는 가장 최근 쓰기의 타임스탬프를 기억할 수 있고, 그러면 시스템은 사용자 읽기를 위한 복제 서버가 최소한 해당 타임스탬프까지 갱신을 반영할 수 있게 한다.

그러면 시스템은 사용자 읽기를 위한 복제 서버가 최소한 해당 타임스탬프까지 갱신을 반영할 수 있다.

복제 서버가 아직 최신 내용이 아닌 경우에는 다른 복제 서버가 읽기를 처리하거나 복제 서버가 따라잡을 때까지 질의를 대기 시킬 수 있다.

타임스탬프는 논리적 타임스탬프거나 실제 시스템 시간일 수 있다.

4.  복제 서버가 여러 데이터센터에 분산됐다면 복잡도가 증가한다.

리더가 제공해야 하는 모든 요청은 리더가 포함된 데이터센터로 라우팅돼야 한다.

동일한 사용자가 여러 디바이스에 접근할 때 또 다른 문제가 발생한다. 이 경우 디바이스 간 쓰기 후 읽기 일관성이 제공돼야 한다.

### 5.2.2 단조 읽기

비동기식 팔로워에게 읽을 때 발생할 수 있는 두 번째 이상 현상은 사용자가 시간이 거꾸로 흐르는 현상을 복격할 수 있다.

여러 팔로워를 가지고 있을 때 새로 고침을 반복하면 웹 서버가 각기 다르게 라우팅 될 수 있을 때 시간이 거꾸로 갈 수 있다.

단조 읽기는 이런 종류의 이상 현상이 발생하지 않음을 보장한다.

단조 읽기는 강한 일관성보다는 덜한 보장이지만 최종적 일관성보다는 더 강한 보장이다.

데이터를 읽을 때 이전 값을 볼 수 있다.

한 사용자가 여러 번 걸쳐 여러 번 읽어도 시간이 되돌아가는 현상을 보지 않는다는 의미다.

이를 달성하게 하는 방법은 각 사용자가 읽기가 항상 동일한 복제 서버에서 수행되게끔 하는 것이다.

예를 들어 임의 선택보다는 사용자 ID의 해시를 기반으로 복제 서버를 선택한다.

하지만 복제 서버가 고장나면 재라우팅할 필요가 있다.

### 5.2.3 일관된 순서로 읽기

세 번째 복제 지연 이상 현상은 인과성의 위반 우려다.

이러한 종류의 이상 현상을 방지하려면 일관된 순서로 읽기 같은 또 다른 유형의 보장이 필요하다.

일관된 순서로 읽기는 일련의 쓰기가 특정 순서로 발생한다면 이 쓰기를 읽는 모든 사용자는 같은 순서로 쓰여진 내용을 보게됨을 보장한다.

이는 파티셔닝된 데이터베이스에서 발생하는 특징이다.

한 가지 해결책은 서로 인과성이 있는 쓰기가 동일한 파티션에 기록되게끔 하는 방법이다.

하지만 일부 애플리케이션에서는 효율적이지 않다.

### 5.2.4 복제 지연을 위한 해결책

최종적 일관성 시스템으로 작업할 때 복제 지연이 몇 분이나 몇 시간으로 증가하면 애플리케이션에서 어떻게 동작할지 생각해볼 가치가 있다.

대답이 문제 없음이면 아주 좋지만 결과가 사용자에게 좋지 않은 경험이라면 쓰기 후 읽기와 같은 강한 보장을 제공하게끔 시스템을 설계해야 한다.

사실은 복제가 비동기식으로 동작하지만 동기식으로 동작하는 척 하는 것이 문제 해결 방안이다.

## 5.3 다중 리더 복제

단일 리더의 문제는 리더가 고장나면 데이터베이스에 쓰기를 할 수 없다.

그래서 리더 기반 복제 모델은 쓰기를 허용하는 노드를 하나 이상 두는 것으로 자연스럽게 확장된다.

복제는 여전히 같은 방식을 사용한다.

이를 다중 리더 설정이라 부른다.

### 5.3.1 다중 리더 복제의 사용 사례

#### 다중 데이터센터 운영

여러 다른 데이터센터에 데이터베이스 복제 서버가 있다고 상상해보자(전체 데이터 센터의 내결함성을 갖추기 위해서 또는 사용자에게 지리적으로 가까이 위치하기 위해). 일반적인 리더 기반 복제 설정은 리더가 하나의 데이터센터에 있고 모든 쓰기는 해당 데이터센터를 거쳐야 한다.

다중 리더 설정에서는 각 데이터센터마다 리더가 있을 수 있다.

- **성능**: 단일 리더 설정에서 모든 쓰기는 인터넷을 통해 리더가 있는 데이터 센터로 이동해야 한다. 이것은 쓰기에 지연 시간을 상당히 늘리는 원인이 된다. 그리고 처음에는 여러 데이터 센터를 갖추는 목적에도 위배될 수 있다.
- **데이터센터 중단 내성**: 데이터센터 중단 내성 단일리더 설정에서는 데이터센터가 고장나면 장애 복구를 위해 다른 데이터센터에서 한 팔로워를 리더로 승진시킨다. 다중 리더 설정에서는 각 데이터센터는 다른 데이터센터와 독립적으로 동작하고 고장난 데이터센터가 온라인으로 들어왔을 때 복제를 따라잡는다.
- **네트워크 문제 내성**: 데이터센터 간 트래픽은 보통 공개 인터넷을 통해 처리한다. 그래서 데이터센터 내의 로컬 네트워크보다 안정성이 떨어진다. 일시적인 네트워크 중단에도 쓰기 처리는 진행되기 때문이다.

일부 데이터베이스는 기본적으로 다중 리더 설정을 제공한다. 하지만 MySQL의 텅스텐 리플리케이터등 외부에서 구현한 도구를 사용하기도 한다.

이점이 있지만 큰 단점도 존재한다. 동일한 데이터를 다른 두 개의 데이터센터에서 동시에 변경할 수 있다.

이를 쓰기 충돌을 반드시 해소해야하는데, 이러한 문제를 이해해보자

#### 오프라인 작업을 하는 클라이언트

이 경우 모든 디바이스에는 리더처럼 동작하는 로컬 데이터베이스가 있다. (쓰기 요청을 받아야 함)

그리고 모든 디바이스 상에서 캘린더의 복제 서버 간 다중 리더 복제를 비동기 방식으로 수행하는 프로세스가 있다.

복제 지연은 사용자가 인터넷 접근이 가능해진 시점에 따라 몇 시간에서 며칠 이상도 걸릴 수 있다.

다중 리더 복제는 올바르게 동작하기 까다롭다.

#### 협업 편집

실시간 협업 편집 애플리케이션은 위 문제와 유사하다.

이 협업 모델은 리더에서 트랜잭션을 사용하는 단일 리더 복제와 동일하다.

#### 쓰기 충돌 다루기

어떤 데이터를 동시에 편집하면 서로 다른 결과가 발생할 수 있다.

#### 동기 대 비동기 충돌 감지

다중 리더에서는 두 쓰기가 모두 성공할 수 있으며, 충돌은 이후 특정 시점에서 비동기로만 감지한다.

이때 사용자에게 요청하면 너무 늦을 수 있다.

이론적으로 충돌 감지는 동기적으로 만들 수 있다.

하지만 다중 리더 복제의 주요 장점을 잃는다.

#### 충돌 회피

가장 간단한 방법이다. 특정 레코드의 모든 쓰기가 동일한 레코드를 거치도록 애플리케이션이 보장한다면 충돌은 발생하지 않는다.

이것은 자주 권장되는 방식이다.

하지만 때떄로 데이터 센터가 고장나서 트래픽을 다른 데이터센터로 다시 라우팅해야 하거나 사용자가 다른 지역으로 이동해 현재는 다른 데이터센터가 가깝다면 레코드를 위해 지정된 리더로 변경하고 싶을 수도 있다. 이런 상황에서는 충돌 회피가 실패한다.

#### 일관된 상태 수렴

단일 리더 데이터베이스는 순차적으로 쓰기를 적용한다. 동일한 필드를 여러 번 갱신한다면 마지막 쓰기가 필드의 최종값으로 결정된다.

다중 리더 설정에서는 쓰기 순서가 정해지지 않아 최종 값이 무엇인지 명확하지 않다.

데이터베이스는 수렴 방식으로 충돌을 해소해야한다. 이는 모든 변경이 복제돼 모든 복제 서버에 동일한 최종값이 전달되게 해야 한다는 의미다.

- 각 쓰기에 고유 ID를 부여하고 가장 높은 ID를 가진 쓰기를 고른다 타임스탬프를 쓰면 LWW라고 한다. 그러나 이 방식은 데이터 유실 위험이 있다.
- 각 복제 서버에 고유 ID를 부여하고 높은 숫자의 복제서버보다 항상 우선적으로 적용되게 한다 마찬가지로 데이터 유실이 발생할 수 있다.
- 어떻게든 값을 병합한다 사전순으로 병합해보면 된다.
- 명시적 데이터 구조에 충돌을 기록해 모든 정보를 보존한다. 나중에 사용자에게 메시지를 보여준다. 충돌을 해소하는 애플리케이션 코드를 작성한다.

#### 사용자 정의 충돌 해소 로직

충돌을 해소하는 적합한 방식은 애플리케이션에 따라 다르다. 대부분의 다중 리더 복제 도구는 애플리케이션 코드를 사용해 충돌을 해소하려고 한다.

- 쓰기 수행 중: 복제된 변경 사항 로그에서 데이터베이스 시스템이 충돌을 감지하자마자 충돌 핸들러를 호출한다. 예를 들어 부카르도에서는 이런 목적으로 펄코드를 작성할 수 있다.
- 읽기 수행 중: 충돌을 감지하면 모든 충돌 쓰기를 저장한다. 다음 번 데이터를 읽을 때 이런 여러 버전의 데이터가 애플리케이션에 반환된다. 카우치 DB가 이런 방식으로 작동한다.

충돌 해소는 보통 전체 트랜잭션이 아니라 개별 로우나 문서 수준에서 적용된다.

자동 충돌 복구 메커니즘

- CRDT: 셋 맵 정렬 목록, 카운터 등을 위한 데이터 구조의 집합으로 동시에 여러 사용자가 편집할 수 있고, 합리적인 방법으로 충돌을 자동해소 한다.
- 병합 가능한 영속 데이터 구조: 깃 버전 제어 시스템과 유사하게 명싲거으로 히스토리를 추적하고 삼중 병합 함수를 사용한다.(CRDT는 이중 병합을 사용한다.)
- 운영 변환(OT): 구글 독스같은 협업 편집 애플리케이션의 충돌 해소 알고리즘이다.

데이터베이스에서 여러 데이터 충돌 회피 알고리즘의 구현은 아직 성숭 단계는 아니지만 앞으로 많은 복제 데이터 시스템에 통합될 가능성이 높다.

자동 충돌 해소는 애플리케이션이 다루는 다중 리더 데이터 동기화를 훨씬 단순하게 만든다.

### 5.3.3 다중 리더 복제 토폴로지

복제 토폴리지는 쓰기를 한 노드에서 다른 노드로 전달하는 통신 경로를 설명한다.

리더1은 모든 쓰기를 리더 2로 전송해야하고 역도 마찬가지이다.

가장 일반적인 토폴로지는 전체 연결이다.

이 토폴로지는 모든 리더가 각자의 쓰기를 다른 모든 리더에서 전송한다.

하지만 이보다 제한된 토폴로지도 사용한다.

예를 들어 마이 SQL은 기본적으로 원형 토폴로지만 제공한다.

다른 대중적인 토폴로지는 별 모양 토폴로지가 있다.

별 모양 토폴로지는 지정된 루트 노드 하나가 다른 모든 노드에 쓰기를 전달한다.

별 모양 토폴로지는 트리로 일반화할 수 있다.

원형과 별 모양 토폴로지의 문제점은 SPOF 문제가 발생한다.

전체 연결같이 조금 더 빽빽하게 연결한 토폴로지의 내결함성이 훨씨;ㄴ 더 좋다.

반면 전체 연결 토폴로지의 문제점도 존재한다.

일부 네트워크 연결이 다른 연결보다 빠르면 일부 복제 메시지가 다른 메시지를 추월할 수 있다.

이때 메시지를 올바르게 전송하기 위해 타임스탬프말고 버전 벡터라고 하는 기법을 사용할 수 있다.

하지만 많은 다중 리더 복제 시스템에서 충돌 감지 기법은 제대로 구현되어있지 않다.

예를 들어 쓰기 시점에 포스트그레스큐엘의 BDR은 쓰기의 인과적 순서를 제공하지 않으며, MySQL은 텅스텐 리플리케이터는 충돌을 감지하기 위한 시도조차 하지 않는다.

## 5.4 리더 없는 복제

이번 장에서 지금까지 살펴본 복제 접근 방식은 클라이언트가 쓰기를 요청한 노드에 전송한 뒤 데이터베이스 시스템이 쓰기를 다른 복제 서버에 복사를 처리하는 아이디어를 기반으로 한다.

리더는 쓰기를 처리하는 순서를 정하고 팔로워는 동일한 순서로 리더의 쓰기를 적용한다.

아마존은 Dynamo 시스템에서 사용한 후 다시 데이터베이스용 아키텍처로 유행했다.

리악, 카산드라, 볼드모트는 다이나모에서 영감을 얻은 리더 없는 복제 모델의 오픈 소스 데이터스토어다.

이런 종류의 데이터베이스를 다이나모 스타일이라 한다.

일부 리더 없는 복제 구현에서는 클라이언트가 여러 복제 서버에 쓰기를 직접 전송하는 반면 코디네이터 노드가 클라이언트를 대신해 이를 수행하기도 한다.

하지만 리더 데이터베이스와 달리 코디네이터 노드는 특정 순서로 쓰기를 수행하지 않는다.

이후에 살펴보겠지만 설계에서 일너 차이는 데이터베이스 사용 방식에 중대한 영향을 미친다.

### 5.4.1 노드가 다운됐을 때 데이터베이스에 쓰기

세 개의 복제 서버를 가진 데이터베이스가 있고 복제 서버 중 하나를 사용할 수 없다고 가정해보자

리더 기반 설정에서는 계속하려면 장애 복구를 실행해야 한다.

반면 리더 없는 설정에서는 장애 복구가 필요하지 않다.

사용자가 복제 서버 3대에 쓰기 요청을 해서 하나의 서버가 노드 오프라인이 된다. 이때 사용할 수 없던 서버에 데이터를 요청하면 오래된 값을 얻을 수 있다.

이 문제를 해결하기 위해서는 클라이언트가 데이터베이스에서 읽을 때 하나의 복제 서버로 요청을 보내지 않고 읽기 요청을 병렬로 여러 노드에 전송한다.

이때 버전 숫자를 사용해 어떤 값이 최신 내용인지 결정한다.

#### 읽기 복구와 안티 엔트로피 처리

복제 계획은 최종적으로 모든 데이터가 모든 복제 서버에 복사된 것을 보장해야 한다.

사용 불가능한 노드가 온라인 상태가 된 후 누락된 쓰기를 어떻게 따라잡아야 할까?

다이나모 스타일 데이터 스토어는 두 가지 메커니즘을 주로 사용한다.

읽기 복구

- 클라이언트가 여러 노드에서 병렬로 읽기를 수행하면 오래된 응답을 감지할 수 있다.
- 오래된 응답을 반환하는 서버에 새로운 응답을 쓴다.
- 값을 자주 읽는 상황에서 적합하다

안티 엔트로피 처리

- 추가적으로 일부 데이터스토어는 백그라운드 프로세스를 두고 복제 서버 간 데이터 차이를 지속적으로 찾아 누락된 데이터를 하나의 복제 서버에서 다른 서버로 복사한다. 리더 기반 복제에서의 복제 로그와 달리 이 안티 엔트로피 처리는 특성 순서로 쓰기를 복사하기 때문에 데이터 복사되기까지 상당한 지연이 있을 수 있다.

#### 읽기와 쓰기를 위한 정족수

N개의 복제 서버가 있을 때 모든 쓰기는 w개의 노드에서 성공해야 쓰기가 확정되고 모든 읽기는 최소한 r개의 노드에 질의해야 한다.

w + r > n 이면 최신 값을 얻을 것으로 기대한다.

최소한 r개의 노드 중 하나에서 최신 값을 읽을 수 있기 때문이다.

이런 r과 w를 따르는 읽기와 쓰기를 정족수 읽기와 쓰기라고 부른다.

유효한 읽기와 쓰기를 위해 필요한 최소 투표수를 r과 w로 생각할 수 있다.

다이나모 스타일 데이터베이스에서 n,w,r, 파라미터는 대개 설정 가능하다.

일반적인 선택은 n을 홀수로 하고 w = r = (n+1)/2(반올림)로 설정한다.

상황에 따라 숫자를 변경할 수 있다.

예를 들어 쓰기가 적고 읽기가 많은 작업부하는 w = n, r = 1로 설정하면 좋다.

이렇게 하면 읽기는 더 빨라지지만 노드 하나가 고장나면 모든 데이터베이스 쓰기가 실패하는 단점이 있다.

정족수 조건이 w + r > n 이면 다음과 같은 사용 불가능한 노드를 용인한다.

- w < n 이면 노드 하나를 사용할 수 없어도 여전히 쓰기를 처리할 수 있다.
- r < n 이면 노드 하나를 사용할 수 없어도 여전히 읽기를 처리할 수 있다.
- n = 3, w = 2, r= 2이면 사용 불가능한 노드 하나를 용인한다.
- n = 5, w = 3, r= 3이면 사용 불가능한 노드 둘을 용인한다.
- 일반적으로 읽기와 쓰기는 항상 모든 n개의 복제 서버에 병렬로 전송한다. 파라미터 w와 r은 얼마나 많은 노드를 기다릴지 결정한다. 즉 읽기나 쓰기가 성공했다고 간주하려면 n개의 노드 중 몇 개의 노드에서 성공을 확인해야 하는지를 나타낸다.

필요한 w,r개 노드보다 사용 가능한 노드가 적다면 쓰기나 읽기는 에러를 반환한다.

#### 정족수 일관성의 한계

쓰기와 읽기 노드 셋이 겹치기 때문에 읽은 노드 중에는 최신 값을 가진 노드가 하나 이상 있어야 한다.

보통 r과 w의 값을 과반수를 선택한다.

이유는 n/2 노드 장애까지 허용해도 w + r / n 이 보장되기 때문이다.

하지만 정족수가 다수일 필요는 없다.

읽기와 쓰기 동작에서 사용하는 노드 셋 중 적어도 하나으 ㅣ노드만 겹치면 된다.

다른 정족수 할당이 가능하기 때문에 분산 알고리즘 설계에서 어느 정도 유연성을 허용한다.

w + r <= n 이 되게끔 설정할 수도 있다.

그러나 이럴 경우 오래된 값을 읽을 확률이 높다.

최신 값을 가진 노드가 읽을 노드에 포함되지 않을 가능성이 높기 때문이다.

대신 낮은 지연 시간과 높은 가용성이 가능하다.

한편, 네트워크 중단으로 많은 복제 서버가 응답하지 않는다면 읽기와 쓰기 처리가 계속 진행될 가능성이 높다.

응답할 수 있는 복제 서버의 수가 w나 r보다 아래로 떨어지면 데이터베이스는 쓰기나 읽기가 불가능하다.

하지만 w + r > n 인 경우에도 오래된 값을 반환하는 에지 케이스가 있다.

- 느슨한 정족수를 사용한다면 w개의 쓰기는 r개의 읽기와 다른 노드에서 수행될 수 있으므로 겹치는 것을 보장하지 않는다.
- 두 개의 쓰기가 동시에 발생하면 어떤 쓰기가 먼저 일어났는지 분명하지 않다. 이 경우 안전한 해결책은 동시 쓰기를 합치는 방법밖에 없다. 승자가 타임스탬프 기반으로 결정되면 시계 스큐로 인해 쓰기가 유실될 수 있다.
- 쓰기가 읽기와 동시에 발생하면 쓰기는 일부 복제 서버에만 반영될 수 있다. 이 경우 읽기가 예전 값 또는 최신 값을 반환하는지 여부가 분명하지 않다.
- 쓰기가 일부 복제 서버에서는 성공했지만 다른 복제 서버에서 실패해 전체에서 성공한 서버가 w 복제 서버보다 적다면 성공한 복제 서버에서는 롤백하지 않는다. 이는 쓰기가 실패한 것으로 보고되면 이어지는 읽기에 해당 쓰기 값이 반환될 수도 있고 아닐 수도 있다는 의미다.
- 새 값을 전달하는 노드가 고장나면 예전 값ㅇ르 가진 다른 복제 서버에서 해당 데이터가 복원되고 새로운 값을 저장한 복제 서버 수가 w보다 낮아져 정족수 조건이 깨진다.
- 모든 과정이 올바르게 동작해도 시점 문제로 에지 케이스가 있을 수 있다.

따라서 정족수가 읽기 시 최근에 쓴 값을 반환하게끔 보장하지만 실제로는 그렇게 간단하지 않다.

다이나모 스타일 데이터베이스는 일반적으로 최종적 일관성을 허용하는 사용 사례에 맞게 최적화됐다.

매개변수 w와 r로 오래된 값을 읽는 확률을 조정할 수 있지만 이를 절대적으로 보장할 수는 없다.

특히 복제 지연 문제에서 설명한 보장을 대개 받을 수 없기 때문에 앞서 언급한 이상 현상이 애플리케이션에서 발생할 수 있다.

견고한 보장은 일반적으로 트랜잭션이나 합의가 필요하다.

#### 최신성 모니터링

- 운영 관점에서 볼 때 데이터베이스가 최산 결과를 반환하는지 여부를 모니터링하는 일은 중요하다.
- 애플리케이션이 오래된 값 읽기를 허용하더라도 복제 상태에 대해 알아야 한다. 복제가 명확히 뒤처진다면 원인을 조사할 수 있게 알려줘야 한다.
- 리더 기반 복제에서 데이터베이스는 일반적으로 복제 지연에 대한 지표를 노출한다. 이 지표는 모니터링 시스템에 제공된다. 이것은 쓰기가 리더에 적용되고 같은 순서로 팔로워에도 적용되고 각 노드가 복제 로그의 위치를 가지기 때문에 가능하다. 리더의 현재 위치에서 팔로워의 현재 위치를 빼면 복제 지연량을 측정할 수 있다.
- 하지만 리더 없는 복제 시스템에서 쓰기가 적용된 순서를 고정할 수 없어 모니터링이 조금 더 어렵다. 더욱이 데이터베이스가 읽기 복구만 사용한다면 자주 읽히지 않는 값이 얼마나 오래된 것인지에 대한 제한이 없어 오래된 복제 서버에서 반환된 값은 아주 오래된 값일 수 있다.
- 리더 없는 복제 데이터베이스에서 복제 서버의 오래됨(staleness)을 측정하고 매개변수 n,w,r에 따라 오래된 값을 읽는 비율을 예측하는 연구가 있었다.

최종적 일관성은 의도적으로 모호한 보장이지만 운용성을 위해서는 최종적을 정량화할 수 있어야 한다.

#### 느슨한 정족수와 암시된 핸드오프

정족수는 내결함성이 없다.

노드가 n개 이상인 대규모 클러스터에서 클라이언트는 네트워크 장애 상화에서 일부 데이터베이스 노드에 연결될 가능성이 있다.

이 경우 데이터베이스 설계자는 트레이드오프에 직면한다.

- w나 r ㅈ노드 정족수를 만족하지 않는 모든 요청에 오류를 반환하는 편이 더 좋을까 ?
- 아니면 일단 쓰기를 받아들이고 값이 보통 저장되는 n개 노드에 속하지는 않지만 연결할 수 있는 노드에 기록할까 ?

후자를 느슨한 정족수라고 부른다.

네트워크 장애 상황이 해제되면 한 노드가 다른 노드를 위해 일시적으로 수용한 모든 쓰기를 해당 홈 노드로 전송한다. 이 방식을 암시된 핸드오프라고 부른다.

느슨한 정족수는 쓰기 가용성을 높이는 데 특히 유용하다.

모든 w개의 노드를 사용할 수 있는 동안은 데이터베이스는 쓰기를 받아들일 수 있다.

하지만 이것은 w + r > n 인 경우에도 키의 최신 값을 읽는다고 보장하지 않는다.

최신 값이 일시적으로 n 이외의 일부 노드에 기록될 수 있기 때문이다.

결국 느슨한 정족수는 전통적인 의미의 정족수가 아니다.

단지 지속성에 대한 보장으로 데이터가 w 노드 어딘가에는 저장된다는 뜻이다.

암시된 핸드오프가 완료될 때까지는 r 노드의 읽기가 저장된 데이터를 본다는 보장은 없다.

#### 다중 데이터센터 운영

이전에 다중 리더 복제의 사용 사례로 데이터 센터간 복제를 설명했다.

"다중 리더 복제" 참고 리더 없는 복제도 동시 쓰기 충돌, 네트워크 중단, 지연 시간 급증을 허용하기 때문에 다중 데이터센터 운영에 적합하다.

카산드라와 볼드모트는 일반적인 리더 없는 모델에 다중 데이터 센터 지원을 구현했다.

n개의 복제 서버 수에는 모든 데이터센터의 노드가 포함되고 설정에서 각 데이터센터마다 n개의 복제 서버 중 몇 개를 보유할지를 지정할 수 있다.

#### 동시 쓰기 감지

다이나모 스타일 데이터베이스는 여러 클라이언트가 동시에 같은 키에 쓰는 것을 허용하기 때문에 엄격한 정족수를 사용하더라도 충돌이 발생한다.
