# Kafka 구현

> 이 문서는 Apache Kafka 공식 문서의 "Implementation" 섹션을 한국어로 번역한 것입니다.
> 원본: https://kafka.apache.org/documentation/#implementation

---

## 5.1 네트워크 레이어 (Network Layer)

네트워크 레이어는 상당히 직관적인 NIO 서버로 구현되어 있으며, 여기서 자세히 설명하지는 않습니다. `sendfile` 구현은 `TransferableRecords` 인터페이스의 `writeTo` 메서드를 통해 수행됩니다. 이를 통해 파일 기반 메시지 집합이 프로세스 내 버퍼링보다 더 효율적인 `transferTo` 구현을 사용할 수 있습니다. 스레딩 모델은 단일 acceptor 스레드와 각각 고정된 수의 연결을 처리하는 N개의 프로세서 스레드로 구성됩니다. 이 설계는 다른 곳에서 충분히 테스트되었으며 구현이 간단하고 빠른 것으로 입증되었습니다. 프로토콜은 의도적으로 단순하게 유지되어 향후 다른 언어로 클라이언트를 구현할 수 있도록 합니다.

---

## 5.2 메시지 (Messages)

메시지는 가변 길이 헤더, 가변 길이 불투명(opaque) 키 바이트 배열, 그리고 가변 길이 불투명 값 바이트 배열로 구성됩니다. 헤더 형식은 다음 섹션에서 설명합니다. 키와 값을 불투명하게 유지하는 것이 올바른 결정입니다: 현재 직렬화 라이브러리 분야에서 많은 발전이 이루어지고 있으며, 특정 선택이 모든 용도에 적합할 가능성은 낮습니다. 말할 필요도 없이, Kafka를 사용하는 특정 애플리케이션은 구현의 일부로 특정 직렬화 유형을 요구할 수 있습니다.

`RecordBatch` 인터페이스는 메시지에 대한 반복자(iterator)로서 NIO `Channel`에서 대량으로 읽고 쓰기 위한 특수 메서드를 제공합니다.

---

## 5.3 메시지 형식 (Message Format)

메시지(레코드)는 항상 배치 단위로 기록됩니다. 메시지 배치(record batch)의 기술적 용어는 레코드 배치이며, 레코드 배치는 하나 이상의 레코드를 포함합니다. 이상적이지 않은 경우에는 레코드 배치가 단일 레코드만 포함할 수 있습니다.

### 5.3.1 레코드 배치 (Record Batch)

다음은 디스크 상의 RecordBatch 형식입니다:

```
baseOffset: int64
batchLength: int32
partitionLeaderEpoch: int32
magic: int8 (현재 magic 값은 2)
crc: uint32
attributes: int16
    bit 0~2:
        0: 압축 없음
        1: gzip
        2: snappy
        3: lz4
        4: zstd
    bit 3: timestampType
    bit 4: isTransactional (0은 트랜잭션이 아님을 의미)
    bit 5: isControlBatch (0은 제어 배치가 아님을 의미)
    bit 6: hasDeleteHorizonMs (0은 배치에 삭제 지평선이 있는 레코드가 없음을 의미)
    bit 7~15: 미사용
lastOffsetDelta: int32
baseTimestamp: int64
maxTimestamp: int64
producerId: int64
producerEpoch: int16
baseSequence: int32
records: [Record]
```

참고: CRC(순환 중복 검사)를 활성화하면 계산 시 magic 바이트 앞의 데이터(즉, 파티션 리더 에포크 필드 포함)가 건너뛰어집니다. 이것은 클라이언트가 이 필드에 값을 할당하지 않으므로 의도적입니다. 반면, magic 바이트에서 배치 끝까지의 모든 데이터가 CRC에 포함됩니다. 따라서 압축 후 모든 배치 수준 필드에서 CRC가 계산됩니다(예: CRC 필드 자체는 제외).

CRC-32C(Castagnoli) 다항식이 계산에 사용됩니다.

압축에 대해: 레코드 배치에서 압축이 활성화되면, 압축된 레코드 데이터는 레코드 수 직후에 바로 직렬화됩니다. 압축된 데이터를 해석하는 것은 특정 압축 코덱에 따라 다릅니다. snappy, gzip, lz4, 그리고 zstd 코덱은 여러 레코드의 연결(concatenation)을 지원하며, 이는 브로커에서 연속 배치가 함께 압축될 때 일반적으로 사용됩니다. 각 코덱의 압축 해제된 레코드 수는 레코드 수 필드로 지정됩니다. 레코드 압축에서 gzip이 사용될 때, 기본 gzip 압축 수준이 적용됩니다. zstd의 경우, 클라이언트에서 `zstd.compression.level` 구성을 통해 압축 수준을 조정할 수 있습니다.

압축에 대한 추가 참고: 타임스탬프 델타의 범위가 `Long.MAX_VALUE - baseTimestamp`를 초과하는 경우, 타임스탬프 델타는 `INT_MAX` 또는 `INT_MIN` 경계를 넘을 수 있습니다. 이러한 경우 타임스탬프 델타의 경계 초과를 피하기 위해 압축 중에 배치가 분할됩니다.

CRC 계산에 포함되는 `baseTimestamp`와 달리 `MaxTimestamp`는 압축 후 리더에 의해 업데이트됩니다. 결과적으로 CRC를 검증하지 않는 소비자는 `MaxTimestamp`를 사용해야 합니다.

#### 제어 배치 (Control Batches)

제어 배치는 제어 레코드라고 불리는 단일 레코드를 포함합니다. 제어 레코드는 애플리케이션에 전달되어서는 안 됩니다. 대신, 중단된 트랜잭션 메시지를 필터링하기 위해 소비자가 사용합니다.

제어 레코드의 키는 다음 스키마를 따릅니다:

```
version: int16 (현재 항상 0)
type: int16 (0은 중단을 나타내고, 1은 커밋을 나타냄)
```

제어 레코드의 스키마는 값의 스키마에 의존합니다:

| 버전 | 값 스키마 |
|------|-----------|
| 0 | 값이 무시됨 |

제어 레코드 값의 스키마는 위에서 다룹니다. 키와 값 버전 태그는 더 복잡한 제어 레코드 스키마가 미래에 필요할 경우 독립적인 발전을 허용합니다.

### 5.3.2 레코드 (Record)

레코드 수준 헤더는 Kafka 0.11.0에서 도입되었습니다. 헤더가 있는 레코드의 디스크 형식은 아래에 설명되어 있습니다.

```
length: varint
attributes: int8
    bit 0~7: 미사용
timestampDelta: varlong
offsetDelta: varint
keyLength: varint
key: byte[]
valueLen: varint
value: byte[]
Headers => [Header]
```

#### 레코드 헤더 (Record Header)

```
headerKeyLength: varint
headerKey: String
headerValueLength: varint
headerValue: byte[]
```

배열 필드에 대한 개별 레코드 개수 필드가 없다는 것을 참고하세요. 대신 레코드 항목 수는 레코드 배치의 레코드 개수 필드를 사용합니다.

### 5.3.3 레거시 메시지 형식

0.11 이전의 Kafka에서는 메시지가 메시지 집합(message sets) 내에서 전송되고 저장되었습니다. 메시지 집합에서 각 메시지는 고유한 메타데이터를 가집니다. 메시지 집합은 단순히 파일과 네트워크에서 동일한 형식을 갖는 메시지 배열입니다.

```
MessageSet (Version: 0) => [offset message_size message]
    offset => INT64
    message_size => INT32
    message => crc magic_byte attributes key value
        crc => INT32
        magic_byte => INT8
        attributes => INT8
            bit 0~2:
                0: 압축 없음
                1: gzip
                2: snappy
            bit 3~7: 미사용
        key => BYTES
        value => BYTES
```

```
MessageSet (Version: 1) => [offset message_size message]
    offset => INT64
    message_size => INT32
    message => crc magic_byte attributes timestamp key value
        crc => INT32
        magic_byte => INT8
        attributes => INT8
            bit 0~2:
                0: 압축 없음
                1: gzip
                2: snappy
                3: lz4
            bit 3: timestampType
                0: 생성 시간 (CreateTime)
                1: 로그 추가 시간 (LogAppendTime)
            bit 4~7: 미사용
        timestamp => INT64
        key => BYTES
        value => BYTES
```

레거시 메시지 형식에서 압축은 다르게 처리됩니다. 각 압축된 메시지의 값 필드에는 메시지 집합이 포함되어 있으며, 이 메시지 집합 내에 실제 메시지(적절한 오프셋, 키, 값 포함)와 재귀적으로 중첩된 메시지 집합(추가 압축된 메시지 포함)이 있습니다.

참고: CRC-32 IEEE 다항식은 레거시 메시지에 대해 계산됩니다.

---

## 5.4 로그 (Log)

"my_topic"이라는 이름과 두 개의 파티션을 가진 토픽의 로그는 두 개의 디렉토리(my_topic_0과 my_topic_1)로 구성되며, 해당 토픽의 메시지를 포함하는 데이터 파일로 채워집니다. 로그 파일의 형식은 "로그 항목(log entries)"의 시퀀스입니다. 각 로그 항목은 메시지의 바이트 수를 저장하는 4바이트 정수 N과 그 뒤를 따르는 N개의 메시지 바이트로 구성됩니다. 각 메시지는 64비트 정수 오프셋으로 고유하게 식별되며, 이 오프셋은 해당 토픽의 해당 파티션으로 전송된 모든 메시지 스트림에서 이 메시지의 시작 위치에 대한 바이트 위치를 제공합니다. 각 메시지의 디스크 형식은 아래에 제공됩니다. 각 로그 파일의 이름은 파일에 포함된 첫 번째 메시지의 오프셋입니다. 따라서 생성된 첫 번째 파일은 00000000000.kafka가 되고, 각 추가 파일은 대략 S바이트(S는 구성에 지정된 최대 로그 파일 크기)의 정수 오프셋 이름을 갖게 됩니다.

메시지에 대해 고유 식별자로 GUID 대신 오프셋을 사용하기로 한 것은 의도적인 설계 결정입니다. 랜덤 ID에서 메시지의 오프셋 위치로의 매핑을 유지하는 무거운 데이터 구조 대신, 간단한 단조 증가 정수를 사용할 수 있습니다. 이 정수는 파티션 외부에서 고유하지 않으므로 외부 시스템은 이 식별자를 사용할 수 없지만, 소비자 API는 이를 숨깁니다.

레코드는 항상 배치 단위로 기록됩니다. 레코드 배치의 기술적 용어는 레코드 배치이며, 레코드 배치에는 다음을 사용하여 하나 이상의 레코드가 포함됩니다. 이상적이지 않은 경우 레코드 배치에 단일 레코드만 포함됩니다. 레코드 배치와 레코드는 고유한 헤더를 가집니다. 각각의 형식은 위에서 설명되어 있습니다.

### 5.4.1 쓰기 (Writes)

로그는 마지막 파일에 순차적으로 추가될 수 있습니다. 이 파일은 구성 가능한 크기(예: 1GB)에 도달하면 새 파일로 롤오버됩니다. 로그는 두 가지 구성 매개변수를 취합니다: M은 OS가 파일을 디스크로 강제 플러시하기 전에 기록할 메시지 수를 제공하고, S는 강제 플러시가 발생하는 시간(초)을 제공합니다. 이는 시스템 충돌 시 최대 M개의 메시지 또는 S초의 데이터를 잃을 수 있다는 내구성 보장을 제공합니다.

### 5.4.2 읽기 (Reads)

읽기는 64비트 논리 오프셋 오프셋과 S바이트 최대 청크 크기 S를 제공하여 수행됩니다. 이는 S바이트 버퍼에 포함된 메시지의 반복자를 반환합니다. S는 단일 메시지보다 크도록 선택해야 하지만, 비정상적으로 큰 메시지의 경우 읽기를 여러 번 재시도하면서 최대 단일 메시지만 반환되더라도 버퍼 크기를 매번 두 배로 늘릴 수 있습니다. 최대 메시지 및 버퍼 크기를 지정하여 서버가 특정 크기까지 버퍼를 확대하도록 할 수 있으며, 클라이언트 측에서도 최대 크기까지 반복적으로 시도하도록 할 수 있습니다. 읽기 버퍼가 로그 파일의 전체 메시지 대신 부분 메시지로 끝나는 경우, 이는 크기 구분자에 의해 쉽게 감지되고 버퍼를 더 읽거나 확장하여 해결됩니다.

지정된 오프셋에서 읽는 실제 프로세스는 먼저 데이터가 저장된 로그 세그먼트 파일을 찾고, 전역 오프셋 값에서 해당 파일의 파일별 오프셋을 계산한 다음, 해당 파일 오프셋에서 읽는 것입니다. 검색은 각 파일에 대해 메모리에 유지되는 간단한 범위에 대한 이진 검색으로 수행됩니다.

로그는 미리 생성되지 않은 오프셋 검색을 허용하므로, 로그 끝을 지나서 데이터를 요청할 수 있습니다. 이 경우 메시지를 아직 사용할 수 없지만 고가용성 보장을 활성화하면 나중에 나타날 수 있는 경우에 유용합니다. 자세한 내용은 복제 섹션을 참조하세요.

### 5.4.3 삭제 (Deletes)

데이터는 한 번에 하나의 로그 세그먼트씩 삭제됩니다. 로그 관리자는 구성 가능한 방식으로 로그 tail의 세그먼트를 삭제할 수 있습니다. 현재 두 가지 정책이 있습니다: 오래된 로그를 삭제하는 보존 시간 기반 정책과 로그 크기에 따른 크기 기반 정책이 있습니다. 이 기능을 활성화하려면 구성 섹션에서 보존 정책 설정을 참조하세요. 사용 가능한 옵션은 시간 기반, 크기 기반, 압축입니다.

보존 시간 기반 정책: 보존 시간이 기록된 세그먼트 파일에서 가장 큰 타임스탬프보다 크면 세그먼트가 삭제됩니다.

크기 기반 보존 정책: 파티션의 나머지 세그먼트가 구성된 크기 미만에서 삭제될 때까지 세그먼트가 가장 오래된 것부터 삭제됩니다.

참고: 세그먼트의 시작 전에 모든 레코드가 만료된 경우 시간 기반 보존에 의해 세그먼트가 삭제되지 않습니다. 세그먼트에 만료되지 않은 레코드가 있는 경우, 해당 레코드도 만료될 때까지 세그먼트가 삭제되지 않습니다.

참고: 세그먼트는 읽기를 차단하지 않는 copy-on-write 스타일로 삭제됩니다.

### 5.4.4 보장 (Guarantees)

로그는 디스크에 플러시된 모든 레코드 배치에 대해 CRC32 체크섬을 유지합니다. 로그 복구 시 각 레코드 배치의 유효성이 검사됩니다. 기록된 각 레코드 배치에 대해 길이와 오프셋이 증가하는지 확인하는 유효성 검사가 있습니다. 로그가 손상된 것으로 감지되면 (레코드의 길이가 음수이거나 오프셋이 단조롭게 증가하지 않거나 CRC가 일치하지 않는 경우) 로그는 마지막으로 유효한 오프셋으로 잘립니다.

또한 오프셋을 점프하는 두 가지 위험 시나리오도 방지해야 합니다:

1. 이전에 커밋되지 않은 데이터를 잃는 장애 - 오프셋 5를 가진 메시지가 커밋되고 오프셋 6을 가진 메시지가 프로듀서에게 승인되었지만 복제본이 이를 기록하기 전에 실패한 시나리오
2. 데이터가 "나타나는" 장애 - 메시지 6을 수락한 후 복제본이 실패하고 클러스터에서 삭제된 후, 오프셋 6의 다른 메시지를 받은 후 다시 조인하면 원래 오프셋 6이 다시 나타나 복제본 간에 오프셋/데이터 불일치가 발생하는 시나리오

정확히 복제된 로그의 오프셋/데이터 불일치는 Kafka의 복제 프로토콜이 보장하며 아래에서 다룹니다.

---

## 5.5 분산 (Distribution)

### 소비자 오프셋 추적 (Consumer Offset Tracking)

Kafka 소비자는 소비한 파티션에서 최대 오프셋을 추적하고 서버 장애 시 해당 오프셋에서 재개할 수 있도록 오프셋을 커밋할 수 있습니다.

Kafka는 지정된 소비자 그룹에 대한 모든 오프셋을 그룹 코디네이터(group coordinator) 라고 불리는 브로커에 저장하는 옵션을 제공합니다. 즉, 해당 소비자 그룹의 모든 소비자 인스턴스는 오프셋 커밋과 페치를 코디네이터(브로커)에게 보내야 합니다. 소비자 그룹은 그룹 이름을 기반으로 코디네이터가 할당됩니다. 소비자는 임의의 Kafka 브로커에 `FindCoordinatorRequest`를 발행하고 `FindCoordinatorResponse`를 읽어 코디네이터를 찾을 수 있으며, 이 응답에는 코디네이터 세부 정보가 포함됩니다. 그런 다음 소비자는 코디네이터 브로커에서 오프셋을 커밋하거나 페치할 수 있습니다. 코디네이터가 이동하면 소비자는 코디네이터를 재발견해야 합니다. 오프셋 커밋은 자동 또는 수동으로 소비자에 의해 수행될 수 있습니다.

그룹 코디네이터가 `OffsetCommitRequest`를 받으면 요청을 `__consumer_offsets`라는 특수 압축된 Kafka 토픽 에 추가합니다. 브로커는 오프셋 토픽의 모든 복제본이 오프셋을 받은 후에만 오프셋 커밋에 대한 성공 응답을 소비자에게 보냅니다. 오프셋이 구성된 시간 내에 복제되지 않으면 오프셋 커밋이 실패하고 소비자는 백오프 후 커밋을 재시도할 수 있습니다. (이는 엔드 투 엔드 시나리오에서 자동으로 고가용성 보장에 의해 수행됩니다.)

브로커는 주기적으로 `__consumer_offsets` 토픽을 압축합니다. 압축 과정에서 오래된 오프셋 커밋은 삭제됩니다.

코디네이터는 빠른 오프셋 페치를 위해 오프셋을 메모리 테이블에 캐시합니다. 브로커가 특정 소비자 그룹의 코디네이터가 되면 (또는 시작 시 로드하면) 소비자에게 응답하기 전에 오프셋 토픽 파티션을 캐시로 읽습니다. 오프셋 페치가 오면 코디네이터는 오프셋 캐시에서 마지막으로 커밋된 오프셋 벡터를 조회하고 반환합니다.

코디네이터가 오프셋 토픽 파티션을 로딩하는 동안 요청이 도착하면 `CoordinatorLoadInProgressException`이 발생하고 소비자는 백오프 후 `OffsetFetchRequest`를 재시도할 수 있습니다.

---

## 요약

Apache Kafka의 구현은 다음과 같은 핵심 설계 원칙을 따릅니다:

1. 네트워크 레이어: NIO 기반의 효율적인 서버 구현으로 `sendfile` 시스템 콜을 활용한 제로 카피 전송 지원

2. 메시지 형식: 유연한 직렬화를 위해 불투명한 키-값 구조 사용, 레코드 배치 단위의 효율적인 처리

3. 로그 저장: 순차적 추가 방식의 로그 구조, 오프셋 기반 메시지 식별, CRC32 체크섬을 통한 데이터 무결성 보장

4. 분산 처리: 그룹 코디네이터를 통한 소비자 오프셋 관리, `__consumer_offsets` 토픽을 활용한 오프셋 저장 및 복제

---

## 참고 자료

- [Apache Kafka 공식 문서](https://kafka.apache.org/documentation/)
- [Kafka Protocol Guide](https://kafka.apache.org/protocol)
- [Kafka Design](https://kafka.apache.org/documentation/#design)
