# Kubernetes, 직접 연결, 그리고 당신

작성자: Lee Briggs
작성일: 2024년 10월 15일

---

Kubernetes 배포 환경에서는 소규모에서는 눈에 띄지 않았을 네트워킹 불규칙성이 표면화되는 경향이 있습니다. Kubernetes 클러스터에서 Tailscale을 사용하는 팀들과 대화할 때, 우리가 종종 마주치는 문제 중 하나는 특정 구성에서 노드 간 직접 연결(direct connection)을 생성하기 어렵거나 불가능하게 만든다는 것입니다. 그 결과, 트래픽이 공유 인프라를 통해 릴레이되어 대역폭 병목 현상과 지연 시간 문제가 발생합니다.

Tailscale로 연결된 클러스터를 배포하는 더 많은 사용자들과 작업하면서 — 우리의 오퍼레이터(operator)나 그들만의 매니페스트를 사용하든 — 우리는 Kubernetes 네트워킹이 실제로 어떻게 작동하는지, 그리고 그것이 Tailscale 접근 방식과 어떻게 상호작용하는지에 대한 몇 가지 요령을 배웠습니다. 이 글에서는 Kubernetes 네트워킹에 수반되는 배경 복잡성의 일부를 설명하고, 직접 연결을 보장하는 데 도움이 될 수 있는 몇 가지 새로운 모범 사례를 제시하며, 작동하지 않는 것들에 대해 논의합니다. 정말 관심이 가신다면, 맨 마지막에 몇 가지 더 해키한 접근 방식을 예고하겠습니다.

## DERP

먼저, 왜 "직접" 연결과 "릴레이" 연결이 따로 존재하는지에 대한 간단한 배경 설명입니다. Tailscale은 NAT 통과(NAT traversal)와 DERP 서버의 조합을 통해 다양한 네트워크에서 연결을 생성할 수 있습니다. DERP 서버는 Tailscale이 운영하는 전 세계적으로 분산된 공유 인프라로, 클라이언트 연결에 대한 메시지를 릴레이합니다. DERP 서버는 두 클라이언트가 서로 직접 연결을 협상할 수 없을 때도 활용됩니다. 연결을 처음 협상할 때나 릴레이 연결이 필요할 때, Tailscale 클라이언트는 왕복 지연 시간(round trip latency)이 가장 낮은 DERP 서버를 사용합니다.

Tailscale의 DERP 서버를 통해 연결이 릴레이되는 사용자들은 종종 이를 알아차리지도 못합니다. 두 클라이언트 사이에 도입되는 추가 홉은 종종 몇 밀리초 차이에 불과합니다. 그리고 모든 사람을 위한 공유 리소스의 가용성을 보장하기 위해 일부 트래픽 셰이핑을 적용하더라도, 대다수의 테일넷(tailnet)은 허용 가능한 사용량 범위 내에 머물며 소프트 대역폭이나 처리량 제한에 걸리지 않습니다.

그러나 조직 내에서 Tailscale 사용량이 증가하기 시작하면, 대역폭과 지연 시간이 사용자들에게 눈에 띄기 시작할 수 있습니다. Tailscale 솔루션 엔지니어링 팀에서는 종종 이 단계에서 고객들과 협력하여 장치 간 직접 연결을 보장하도록 Tailscale 설정을 설계합니다. 9월에 저는 웨비나를 주최하여 다양한 유형의 연결, 이를 식별하는 방법, 그리고 공용 연결을 얻기 위한 팁과 요령에 대해 광범위하게 이야기했습니다.

웨비나의 대부분은 가상 머신이나 클라우드 프로바이더 컴퓨팅 수준에서의 직접 연결에 초점을 맞추었지만, 고객들은 지속적으로 묻습니다 — Kubernetes에서도 동일한 직접 연결을 어떻게 얻을 수 있을까요?

## Kubernetes의 모든 것

모든 Kubernetes 클러스터에는 클러스터의 파드(pod)에 IP 주소를 분배하는 역할을 담당하는 CNI(Container Network Interface, 컨테이너 네트워크 인터페이스)가 있습니다. 다양한 CNI 구현체들이 있으며, 파드에 IP를 분배하는 이 문제를 다양한 방식으로 해결하지만, 모두 동일한 문제를 해결해야 합니다. Kubernetes의 핵심 원칙은 클러스터가 올바르게 기능하려면 모든 파드가 클러스터의 다른 모든 파드와 직접 연결될 수 있어야 한다는 것입니다. 대부분의 경우, 이는 서로에 대한 레이어 3 연결을 보장하는 것을 의미하므로(VXLAN 모드의 Calico와 같은 예외 사항이 있음), CNI는 일반적으로 특정 CIDR 블록에서 파드에 많은 주소를 분배합니다. 다를 수 있는 것은 CNI가 해당 CIDR 블록을 결정하는 방식입니다.

이것이 Tailscale과 어떻게 관련되는지는 꽤 간단합니다: Tailscale은 그저 또 다른 파드가 됩니다. IP 주소를 받고, 클러스터의 다른 모든 파드에 아주 잘 연결할 수 있습니다. 아래 다이어그램에서 이를 시각화하여 볼 수 있습니다.

[이미지: Kubernetes 클러스터의 파드 내 Tailscale 컨테이너가 해당 클러스터의 다른 컨테이너들과 통신합니다.]

이 모든 것은 동일한 클러스터 내의 파드 간 통신에서는 문제가 없습니다. 그리고 실제로, Kubernetes 클러스터 내부의 두 Tailscale 노드는 예를 들어 거의 항상 서로 직접 연결을 설정할 수 있습니다.

하지만 Kubernetes 클러스터에 Tailscale을 설치한다면, 거의 확실히 외부 네트워크에서 Tailscale 파드에 접근하고 싶을 것입니다. Tailscale은 NAT 통과를 사용하여 공용 인터넷의 DERP 서버에 공용 "엔드포인트"와 아웃바운드 연결에 사용하는 포트에 대한 정보를 보내며, 직접 연결을 얻기 위해서는 그 경로가 매우 중요합니다. CNI의 사용도 무시할 수 없는데, 이것이 직접 연결을 얻기 위한 추가적인 고려 사항을 만들기 때문입니다.

## 연결이 NAT 직접적이지 않다

(말장난에 대해 사과드리지 않겠습니다.)

Tailscale 클라이언트 간 직접 연결을 얻는 데 가장 큰 장벽은 NAT, 특히 아웃바운드 연결에 대해 어떤 형태의 포트 무작위화를 수행하는 "하드 NAT(hard NAT)"입니다. 이 무작위화는 Tailscale이 아웃바운드 트래픽을 보낼 때, NAT 장치가 모든 아웃바운드 연결에 대해 다른 포트를 사용한다는 것을 의미하며(웨비나나 문서에서 이에 대해 더 들을 수 있습니다), 그 결과 Tailscale은 직접 연결을 생성하기 위해 해당 포트를 재사용할 수 없습니다.

여기서 약간 대충 설명하고 있습니다. Kubernetes 네트워킹은 복잡하고, 마지막 두 단락의 대부분 문장에는 조건이 있습니다. 특히, 우리는 연결의 한쪽 끝에서의 NAT를 설명하고 있으며, 영향을 줄 수 있는 다른 쪽 끝은 넘어가고 있습니다. (실제로, 이 문제는 Tailscale이 클러스터에 설치되어 일부 클러스터 워크로드를 하드 NAT 뒤에 있을 수 있는 사용자 장치에 노출할 때 종종 나타납니다.) 일반적으로, Kubernetes 설정이 직접 Tailscale 연결을 만들지 않는다고 들을 때, 우리는 NAT부터 조사를 시작합니다.

여기서 정말 관련이 있는 것은 Kubernetes를 사용하고 모든 파드가 자체 IP 주소를 가지는 CNI를 도입할 때, 모든 아웃바운드 연결이 호스트의 네트워크 인터페이스를 통해 발생한다는 것입니다. 이 글을 읽는 분들 중 이런 종류의 연결을 다뤄보신 분들은 이것이 특정 유형의 NAT, "소스 NAT"(또는 줄여서 SNAT)임을 알아보실 것입니다.

[이미지: Kubernetes 클러스터의 모든 파드가 CNI를 사용하고 자체 IP 주소를 가질 때 SNAT가 배포됩니다.]

이것은 Tailscale에게 정말 어려운 상황을 만듭니다. 이제 네트워크 밖으로, 그리고 호스트 자체 밖으로 모든 종류의 NAT 통과를 수행해야 하기 때문입니다. 물론 연결은 여전히 되는데, Tailscale이 대부분의 네트워크를 탐색하는 마법을 부리기 때문입니다. 하지만 직접 연결 가능성은 낮아집니다.

## 직접 연결에 대한 전망은 "흐림"

(저 말장난 연속으로 잘하고 있죠?)

이제, AWS나 Azure와 같은 클라우드 프로바이더의 Kubernetes 구현에 익숙하신 분들은 "아하! CNI가 클라우드 네트워크에서 직접 IP를 분배하기 때문에 SNAT가 필요 없어!"라고 생각하실 것이고, 그렇게 생각하는 것이 맞지만, 아직 너무 흥분하지는 마세요.

SNAT가 필요하지 않고 파드가 컴퓨팅 호스트와 동일한 레이어 3 네트워크 내에 있지만, 예를 들어 AWS CNI의 기본 설정은 IPTables를 통해 SNAT를 활성화하고 포트 매핑을 완전히 무작위화하는 것입니다. Azure의 네트워킹은 훨씬 더 많은 구성 가능한 부분이 있지만, 기본 모드에서는 일반적으로 SNAT를 수행합니다. 이 모든 것이 같은 결과로 이어집니다: 통과해야 할 NAT가 많을수록 직접 연결을 얻을 가능성이 줄어듭니다.

## 이 문제에 대해 무엇을 할 수 있을까요?

직접 연결을 보장하기 위한 Tailscale 솔루션 엔지니어링의 권장 사항은 가장 많은 제어권을 가진 연결 측(대부분의 경우 인프라 측)을 Tailscale 장치 자체에 공용 IP가 연결된 "NAT 없음" 상황으로 만드는 것입니다. 일반적으로 이를 위한 방법은 다음과 같습니다:

- 노드에 공용 IP 주소 부여
- `tailscaled`가 수신 대기하는 포트에 대한 인바운드 UDP 접근 허용

Kubernetes의 경우 구체적으로 다음 3가지를 의미합니다:

- 당연히 공용 IP를 가진 노드가 있는지 확인
- 파드 스펙에 `hostnetwork:true` 설정
- `PORT` 환경 변수를 사용하여 Tailscale이 수신 대기하는 포트 지정
- 배포(deployment)에 포트 지정
- 위 포트에 대한 접근을 허용하도록 보안 그룹이나 인바운드 방화벽에 UDP 트래픽 개방

위 단계들은 클라우드 프로바이더의 관리형 NAT 게이트웨이(거의 항상 하드 NAT임)를 탐색하지 않고, 파드에서 호스트로의 SNAT도 받지 않도록 보장합니다. 특별히 매력적이지는 않지만, 작동합니다.

## 이게 마음에 들지 않는데, 다른 방법은 없나요?

안타깝게도, 할 수 있는 것이 많지 않습니다. 이 글을 쓰는 시점에서 우리의 현재 입장은 Kubernetes에서 직접 연결을 보장할 수 없다는 것입니다. 이러한 제한 사항은 일반적으로 Kubernetes 생태계의 설계 결정입니다. 이는 특히 Kubernetes 오퍼레이터를 활용할 때 그렇습니다. 오퍼레이터는 생성하는 파드에 호스트 네트워킹을 쉽게 사용할 수 없기 때문입니다.

현재로서는: 우리는 이 문제를 인지하고 있으며, 작업 중입니다. 팀에서 Tailscale과 Kubernetes를 사용하는 데 관심이 있지만 우리의 권장 접근 방식을 구현할 수 없다면, 연락해 주세요. 실제 문제점이 어디에 있는지, 그리고 우리가 제안한 수정 사항들과 어떻게 일치하는지에 대해 더 많은 사용자들의 이야기를 듣고 싶습니다. 그 사이에, 아직 공개적으로 공개할 준비가 되지 않은 몇 가지 실험적인 솔루션이 있으며, 향후 블로그 게시물에서 이에 대해 설명하겠습니다.
