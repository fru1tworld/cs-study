# 미래에 살기, 숫자로 보다

- 원문: [Living in the Future, by the Numbers](https://tailscale.com/blog/living-in-the-future)
- 작성일: 2025년 1월 8일
- 작성자: Avery Pennarun (Tailscale CEO 겸 공동 창립자)
- 카테고리: 인사이트

---

새해가 되었고, 며칠간의 휴가를 보냈기에 미래에 대해 생각해 왔습니다. 전통적인 새해 예측을 하는 대신, 우리가 살고 있는 아름다운 기술적 미래에 대해 이야기합시다: 지금 바로 존재하지만 항상 알아차리지 못하는 것입니다.

## 계산은 20년 전보다 200,000배 빠릅니다

2004년에 일반적인 CPU는 초당 3-5 Gflops 정도를 수행할 수 있었습니다. 오늘날, 멀티코어 서버 CPU는 최대 4 Tflops/sec(SIMD 만세)까지 할 수 있다고 하며, 대략 1000배 빠릅니다.

2004년에 서버에는 GPU가 거의 없었으므로, 3-5 Gflops가 전부였습니다. 요즘에는 RTX 4090을 추가하면 약 80 Tflops를 추가로 얻을 수 있습니다(16,000배 빠름).

하지만 정말로 (어, 낮은 정밀도로) 숫자를 곱해야 한다면, 이제 TPU가 있습니다. Google TPUv4는 1.1 Pflops/sec을 주장하므로, 다시 14배 빠릅니다. 따라서 한 머신에서의 수치 계산은 2004년 한 머신보다 대략 220,000배 빠릅니다.

## 웹 서버는 최소 100배 빠릅니다

그 숫자 곱셈 성능이 일상 생활에서 중요한가요? AI 관련 작업을 하지 않는 한 아마도 그렇지 않습니다(그래서 하드웨어 산업이 AI 관련 작업에 관심을 가지도록 그렇게 긴급하게 필요로 하는 것입니다).

GPU나 TPU에서 부동 소수점 숫자를 곱할 수 있다고 해서 웹 서버나 (대부분의 종류의) SQL 쿼리가 정확히 빨라지지는 않습니다. 하지만 일반 CPU도 이제 클럭 사이클당 더 많이 처리하고, AMD EPYC와 같은 멋진 워크스테이션 CPU는 128코어 이상에 도달하고 있습니다. 각 코어가 더 적은 코어 프로세서보다 조금 느리게 실행되더라도 코어가 많습니다.

그리고 기억하세요, 2004년에는 Perl, PHP, Python으로 서버를 만들고 있었습니다. (Ruby on Rails는 아직 유행하지 않았습니다.) Chrome이 2008년에 V8을 출시할 때까지 JavaScript JIT조차 일어나지 않았습니다. 이제 Go나 Rust와 같은 괜찮은 컴파일 언어로 서버 측을 훨씬 더 쉽게 작성할 수 있습니다—또는 적어도 JIT 컴파일된 Node.js로.

소프트웨어 전통에서 드문 예외로, 서버에서는 하드웨어와 관계없이 소프트웨어 개선만으로 50x-100x 속도 향상을 볼 수 있습니다. (농담이 아닙니다: 제 경험칙은 "Python은 코드 줄당 컴파일 언어보다 약 50배 느립니다"입니다.)

하드웨어와 소프트웨어 개선을 함께하면, 일반적인 서버 사용 사례에 대해 최소 100x—아마도 훨씬 더—라고 말하겠습니다.

## RAM은 16배에서 750배 더 큽니다

계산 속도는 하나의 요소이지만, 공간은 어떨까요?

2004년 일반적인 노트북의 최대 RAM은 2GB였습니다. 오늘날 일반적인 최대는 약 32GB입니다(16배 더 큼).

고급 사양에서 서버는 당시 약 16GB가 최대였다고 합니다. 오늘날 제가 찾은 가장 큰 서버는 12TB의 RAM을 가지고 있습니다(750배 더 큼).

흥미롭게도, 바이트당 가격은 20년 동안 아마도 6-10배 정도만 개선되었습니다—컴퓨팅의 대부분보다 훨씬 느립니다. 따라서 그 12TB 서버는 많은 비용이 들 것입니다. 하지만 모든 계산을 한 컴퓨터에서 하고 싶다면, 이전에는 어떤 가격에서도 불가능했던 것을 할 수 있습니다.

그리고 모든 것을 한 컴퓨터에 넣으면 엄청난 분산 시스템 오버헤드를 절약하여 또 다른 성능(및 디버깅 용이성) 이점을 얻을 수 있습니다.

## 하드 디스크는 약 100배 더 큽니다

영구 스토리지는 어떨까요?

잠시 SSD를 무시하면, 2004년에는 제가 찾은 어떤 랜덤 웹사이트에 따르면 약 $95에 일반적인 160GB 소비자 하드 디스크를 살 수 있었습니다—TB당 $1684. 오늘날 디스크는 TB당 약 $14이므로, 바이트당 100배 저렴합니다.

이것을 관점에서 보면, 2016년 Netflix의 전체 카탈로그가 약 100TB라고 추정한 사람을 찾았습니다. 오늘날 그것은 디스크에 약 $1400가 들 것입니다—꽤 좋은 노트북 가격의 약 절반입니다. 그리고 이제 최소 14TB 디스크를 살 수 있으므로, 그 전체 카탈로그는 약 7개의 디스크에 불과합니다. Raspberry Pi의 USB 허브 체인에 꽂으세요.

(AWS S3가 여전히 TB당 월 $23를 청구하고—매달 물리적 디스크를 완전히 구매하는 가격의 1.6배—그 위에 실제로 다운로드하는 모든 바이트에 대해 이그레스 비용을 청구하는 것은 무시합시다. 하지만 이것은 컴퓨팅의 최첨단에 대한 기사이지, 돈을 불태우는 최첨단에 대한 것이 아닙니다.)

## SSD는 초당 10,000배 더 많은 트랜잭션을 수행할 수 있습니다

2004년에 우리는 모든 것에 회전 디스크를 사용했습니다. 시크 타임 때문에 단순한 소비자급 회전 디스크는 초당 약 50 트랜잭션을 수행할 수 있었습니다. (서버에서는 고RPM 디스크를 구매하면 아마도 100에 도달할 수 있었습니다. 또는 거대한 디스크 어레이와 배터리 백업 RAM을 포함한 다양한 비싼 하드웨어가 트랜잭션 지연 시간을 줄이기 위해 도입되었습니다.)

현대 NVMe 디스크는 초당 500,000 트랜잭션 이상을 수행할 수 있습니다. 이것은 10,000배 속도 향상입니다.

얼마나 빠른가요? CapitalOne에 따르면, "전 세계적으로 초당 약 23,000건의 신용 카드 거래가 있습니다". 따라서 한 대의 게이머 PC에서 세계 신용 카드 거래 처리의 20배를 할 수 있을 것 같습니다.

## SSD는 (대부분) 죽지 않습니다

이제, Visa는 아마도 단 한 대의 컴퓨터에서 전체 서비스를 실제로 운영하지 않습니다. 왜냐하면 신뢰성 때문입니다. ...맞죠?

2004년의 나쁜 옛날을 기억하기 어렵지만, 그때는 거의 독점적으로 회전 디스크를 사용했고, 회전 디스크는 그냥... 결국 작동을 멈추는 경향이 있었습니다. 움직이는 부품은 모든 산업에서 큰 신뢰성 문제입니다. (게다가, 컴퓨터를 강한 자석과 함께 가방에 넣고 학교에 도착했을 때 더 이상 작동하지 않고 신용 카드도 지워졌던 때를 기억하시나요? ...아마도 저만 그랬을 수도 있습니다.)

SSD의 신뢰성에 대한 의견은 다양하지만, 일반적으로 정상적인 사용에서 더 오래 지속되며, 죽을 때 보통 완전한 데이터 손실이 아닙니다(컨트롤러의 제조 결함이 있어 일찍 죽지 않는 한, 아이고). Backblaze에는 신뢰성 통계를 포함한 SSD 보고서가 있습니다: 일부 모델은 4년 이상의 운영에서 0건의 실패를 보여줍니다.

디스크 실패는 발생하면 좌절스럽고, 실패의 낮은 확률도 꽤 용납할 수 없습니다. 그래서 AWS S3는 스토리지를 "11개의 9"의 내구성으로 만들기 위해 고생합니다. 이것은 스토리지가 때때로 일시적으로 오프라인이 될 수 있지만(가용성), 다시 돌아오면 데이터가 여전히 있을 것입니다(내구성).

그래도. 예전에는 컴퓨터를 소유하면 데이터를 잃게 될 것이었고, 그것이 그냥 그런 것이었습니다. 평균적인 소비자라면, 인생에서 적어도 한 번의 주요 데이터 손실을 경험했을 것입니다. 전문가라면, 오프사이트 백업을 만들고 RAID를 조작하고 죽기 전에 디스크를 주기적으로 교체하여 이를 처리했습니다(그리고 아마도 여전히 인생에서 적어도 한 번의 주요 데이터 손실을 경험했을 것입니다).

요즘 대부분의 일반인들은 더 이상 디스크 실패에 대해 생각하지 않습니다. 지난 10년 동안 노트북 스토리지가 그냥 끊긴 사람을 몇 명이나 아시나요? 저는 개인적으로 한 명도 모릅니다. 정말 큰 차이입니다.

## "c10k" 문제는 이제 "c10000k" 문제입니다

2004년 제 주변에서는 c10k 문제에 대해 많이 이야기했습니다: 단일 서버에 동시에 10,000개의 클라이언트를 연결하는 것입니다.

요즘에는 그것을 지나쳐, 최소한 c10000k 문제까지 왔습니다: 한 번에 천만 개의 연결. Tailscale 프로덕션에서는 올해 백만 개의 동시 연결 노드를 통과한 서버가 적어도 하나 있습니다. 이제, 아마도 그렇게 하지 말았어야 했습니다; 우리의 미래에 또 다른 4월 1일 블로그 포스트가 느껴집니다. 하지만 어쨌든 우리는 여기 있습니다. 그리고 올해 200만을 달성하려고 해서는 안 됩니다. 아마도.

요점은, 그 수십 배의 개선이 실제라는 것입니다. 우리는 그것에 의존할 수 있습니다. 한 컴퓨터가 예전에 1000대의 컴퓨터가 했던 일을 할 수 있다는 것을 알기 때문에 예전과는 완전히 다르게 설계할 수 있습니다.

## 미래에 오신 것을 환영합니다

거의 모든 사람에게, 우리의 도구는 문제보다 훨씬 빠르게 성장하고 있습니다. 오늘날 우리가 사용하는 분산형, 하이퍼스케일 아키텍처의 많은 부분은 1998년과 2000년대 초반 Google에서 유래했습니다... 위의 모든 속도 향상 이전에. 오늘날 우리는 필요 때문이 아니라 습관 때문에 같은 설계를 사용합니다.

Tailscale이라는 이름을 지을 때, 다층적인 너드 농담이었습니다. 한 층은 Jeff Dean과 Luiz André Barroso의 Tail at Scale 논문의 반대라는 것입니다. 그들의 논문은 백만 대의 컴퓨터로 확장할 때 처리해야 하는 모든 문제에 대한 것이었습니다. 저는 그 논문을 좋아하고, 정말 멋집니다. 하지만 Tailscale은 음, 더 적은 것으로 더 많이 할 때 처리할 필요가 없는 모든 문제에 대한 것입니다.

미래에 오신 것을 환영합니다. 최대한 활용하세요. 재미있을 것입니다.
