# Aperture: 안전한 AI와 빠른 AI 사이에서 선택하지 마세요

- 원문: [Aperture: Stop choosing between safe AI and fast AI](https://tailscale.com/blog/aperture-partners-update)
- 작성일: 2026년 2월 17일
- 작성자: David Carney
- 기여자: Remy Guercio, Avery Pennarun, Benson Wong, Luke Kosewski, Larah Vasquez

---

"게이트웨이를 구축하는 것은 당연한 선택이다"라고 어떤 기술 창업자가 지난 여름 저에게 무심코 말했습니다. 우리는 MCP 서버의 확산, AI 네트워크 보안과 ID 관리를 느슨하게 다루는 사람들 등에 대해 이야기하고 있었습니다. 그들이 맞았지만, 저는 세상이 또 다른 게이트웨이를 필요로 한다고 생각하지 않았습니다. 대신, 저와 제 팀은 다른 사람들이 Tailscale 위에 구축하도록 격려하는 데 시간을 보냈습니다. 왜냐하면 연결성, 보안, ID를 기본으로 얻을 수 있기 때문입니다.

하지만 많은 게이트웨이 제품이 시장에 출시되었음에도 불구하고, CISO와 CTO로부터 같은 이야기를 계속 들었습니다: 화려한 기능은 좋지만, API 키 관리는 여전히 큰 골칫거리입니다. 키가 거래되고, 도난당하고, 실수로 저장소에 체크인되거나 공유됩니다. 보안 팀은 누가 어떤 AI 제품을 얼마나 사용하고 있는지 볼 수 없지만, 그렇다고 무언가를 망가뜨리지 않고 키를 단순히 폐기할 수도 없습니다. 어려운 상황입니다.

그래서 지난 11월에 우리는 테일넷 내부에서 실행되는 게이트웨이를 구축하여 이 급성 문제를 해결하는 한 가지 방법을 보여주기로 결정했습니다: Aperture입니다. tsnet을 사용하여 Tailscale 네트워크(테일넷)의 노드로 나타납니다. Aperture는 연결되는 모든 것의 ID를 암묵적으로 알고 있으므로, 모든 API 키를 내부에 넣고 모든 사람에게 LLM에 접근하기 위해 코딩 에이전트를 Aperture로 지정하라고 말할 수 있습니다. 모든 API 호출은 ID가 첨부된 상태로 로깅될 수 있습니다. 이는 보안, 가시성, 사용 편의성을 향상시킵니다: 윈-윈-윈입니다.

"Aperture는 GenAI 워크플로우에서 마찰을 제거하여 API 키 관리를 없앱니다"라고 Corelight의 보안, 인프라 및 IT 디렉터인 Louis Gardner가 언급했습니다.

우리는 Tailscale에서 Aperture를 사용하고 있으며 이미 워크플로우가 개선되고 있습니다. 예를 들어, 한 제품 리더가 LLM 기반 내부 도구를 더 빠르게 만들고 구현할 수 있었습니다. API 키를 요청할 필요가 없고, 코딩 에이전트 구성은 단 두 줄의 설정 변경에 불과합니다. 그들의 말로는 "거대한 잠금 해제"였습니다.

우리의 목표는 AI를 사용하는 것을 너무 쉽고 안전하게 만들어서 팀이 빠르게 움직이는 것과 안전하게 유지하는 것 사이에서 다시는 선택할 필요가 없게 하는 것입니다. 우리의 초기 고객들은 Aperture를 좋아하고 커버리지와 기능을 확장하도록 우리를 밀어붙이고 있습니다.

## 고객 주도 업그레이드

Aperture를 구축하고 직접 사용하는 것이 너무 재미있어서 사용자들에게 전달하고 싶어 참을 수 없었습니다. 1월 초에 우리는 일부 고객을 초대하여 재미를 공유하기 시작했습니다. 그 달 말, 우리는 조용히 대기자 명단을 시작했습니다. 이 얼리 어답터들은 우리를 세 가지 큰 방향으로 밀어붙였습니다:

## 더 많은 제공자: Bedrock과 Vertex 지원

최근 AWS Bedrock과 Google Vertex 지원을 추가했음을 발표하게 되어 기쁩니다. 이러한 엔터프라이즈급 제공자들은 Tailscale의 많은 대기업 고객들에 의해 많이 사용되며, 당연히 설정하고 배포하기가 까다로울 수 있습니다. Aperture를 사용하면 많은 복잡성을 캡슐화하여 인증 프로세스를 획기적으로 단순화할 수 있습니다(솔직히 저도 놀랐습니다).

Aperture는 이미 지원합니다: 모든 주요 LLM 제공자를 네이티브로; OpenAI의 v1 API를 준수하는 LLM 추론 제공자; 자체 호스팅 LLM; 그리고 대부분의 주요 클라우드 AI 엔드포인트. 우리는 Aperture가 복잡성을 관리하고 사용자에게 단순하고 깨끗한 인터페이스를 제공하면서 더 많은 제공자를 계속 추가할 것입니다.

## 더 많은 통합: 파트너와의 실시간 분석

S3 통합은 우리가 구축한 첫 번째 기능 요청 중 하나였습니다. 결국, 코딩 에이전트는 많은 로그를 생성할 수 있으며, 보안 팀은 PII, 키, 부적절하게 공유되는 기타 자격 증명과 같은 것들을 분석하고 싶어합니다. 이를 위한 풍부한 도구와 서비스가 있으며, 사후 로그 분석에서 시작하여 CISO들이 요청해 온 것, 즉 실시간 분석과 동적 접근 정책 관리로 이어집니다.

Aperture는 이러한 많은 서비스의 자연스러운 통합 지점이므로, Cribl, Oso, Apollo Research, Cerbos와 같은 회사들과 API 및 통합을 적극적으로 구축하고 있습니다. Tailscale과 함께 사용하면, 이러한 도구들은 동적 네트워크 보안 및 접근 제어를 위한 피드백 루프의 기회를 만들어내며, 이는 AI가 확산됨에 따라 보안에 점점 더 중요해질 것입니다.

Cribl의 CEO인 Clint Sharp는 Aperture 통합이 데이터 엔진 모델을 어떻게 지원하는지 설명했습니다: "기본으로 상세한 감사 로그를 얻고, Cribl Stream을 통해 라우팅하고, 가장 유용한 곳에 저장합니다."

Oso는 Aperture와 통합한 최초의 파트너 중 하나로, 보안 감독을 유지하면서 엔지니어에게 코딩 에이전트에 대한 자유를 제공합니다. Oso의 공동 창립자이자 CEO인 Graham Neray는 조직이 "가시성, 위험 점수, 알림으로 시작할 수 있다—예를 들어, 그 로컬 MCP 서버가 어디서 왔나?"라고 말했습니다.

AI 안전 회사 Apollo Research는 Aperture 데이터를 Watcher 도구에 통합하여, CISO/CTO를 위한 개요와 개발자를 위한 실시간 데이터를 제공하기 위해 코딩 에이전트 로그를 스캔합니다. Apollo Research의 CEO이자 공동 창립자인 Marius Hobbhahn은 "Aperture와 Watcher의 조합이 그것을 완벽하게 허용합니다"라고 강조했습니다.

엔터프라이즈 권한 부여 관리 플랫폼인 Cerbos는 Aperture가 가로챈 도구 호출을 평가합니다. Aperture의 ID 및 기능과 실시간 컨텍스트 신호를 결합하여, Cerbos는 호출이 실행되어야 하는지 신속하게 결정합니다. Cerbos의 CEO인 Emre Baran은 "Cerbos는 실행 전에 모든 요청을 평가합니다"라고 언급했습니다.

더 많은 파트너와 통합을 가능하게 하기 위해 훨씬 더 많은 작업을 할 것으로 기대해 주세요.

## 더 많은 가시성과 제어: 토큰이 어디로 가는지 파악

비주얼 에디터를 출시했을 때 Tailscale 접근 정책 구성이 훨씬 좋아졌으므로, Aperture에서도 같은 작업을 하기로 쉽게 결정했습니다. 더 보기 좋아진 것 외에도, 이제 사용자별 및 역할별로 모델에 대한 접근을 구성할 수 있습니다.

또한 팀이 토큰을 어떻게 소비하고 있는지 한눈에 이해할 수 있도록 더 많은 시각화를 추가했습니다(예: 사용자별, 사용자 에이전트별, 모델별). 여기서 얻을 수 있는 통찰이 많아, 가까운 미래에 동적 비용 최적화 및 기타 기능과 같은 것들을 탐구할 기회를 만듭니다.

---

Tailscale 위에서 많은 견인력을 가지고, 많은 실제 AI 과제를 빠르게 해결하는 제품을 구축하는 것은 스릴 넘쳤습니다. 아직 초기이지만, Aperture는 이미 우리 내부 인프라의 중요한 부분이며 초기 사용자들에게 빠르게 필수적인 것이 되어가고 있습니다. 비용 제어, 더 깊은 파트너 통합, 보안 팀에게 그들이 부족했던 AI 사용에 대한 실시간 제어를 제공하는 것에 대해 훨씬 더 많은 것이 다가오고 있습니다.

Aperture는 AI 배포를 더 안전하고, 쉽고, 빠르게 만들며, 그렇게 하면서 비용을 절약할 수 있습니다. 코딩 에이전트와 작업하는 보안, 플랫폼 또는 엔지니어링 팀이라면 가입하세요. 기꺼이 시작하도록 도와드리겠습니다. 그리고 이미 Aperture를 사용하고 계시다면, 다음에 무엇을 보고 싶은지 듣고 싶습니다.
